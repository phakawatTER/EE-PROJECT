{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import model\n",
    "import argparse\n",
    "from tensorflow.keras.callbacks import History, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"training_set.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "data = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>order_in_month</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  order_in_month  month  hour  minute   load\n",
       "0    0             2.0      0   0.0     0.0  81.24\n",
       "1    0             3.0      0   0.0     0.0  81.24\n",
       "2    0             0.0      0   0.0     0.0  66.32\n",
       "3    0             0.0      0   0.0     0.0  88.86\n",
       "4    0             3.0      0   0.0    15.0  80.99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"load\"].values.reshape(-1,1) # training label\n",
    "X = df[df.columns[:-1]].values.reshape(-1,5)  # training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81.24],\n",
       "       [81.24],\n",
       "       [66.32],\n",
       "       ...,\n",
       "       [80.32],\n",
       "       [92.37],\n",
       "       [80.99]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  0.,  0.,  0.],\n",
       "       [ 0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 6.,  3., 11., 23., 45.],\n",
       "       [ 6.,  0., 11., 23., 45.],\n",
       "       [ 6.,  2., 11., 23., 45.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300,\n",
    "                activation='relu',\n",
    "                input_shape = X_train.shape[1:]))\n",
    "\n",
    "model.add(Dense(90,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(30,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,\n",
    "                activation='linear'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2300\n",
    "checkpoint_file = \"checkpoint/c.hdf5\"\n",
    "model_file = \"model/m.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0005)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_file,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17948 samples, validate on 3168 samples\n",
      "Epoch 1/2300\n",
      "17948/17948 [==============================] - 1s 54us/sample - loss: 92.8360 - val_loss: 99.2341\n",
      "Epoch 2/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.2037 - val_loss: 98.6081\n",
      "Epoch 3/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.1034 - val_loss: 95.1986\n",
      "Epoch 4/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.1123 - val_loss: 95.1572\n",
      "Epoch 5/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.2280 - val_loss: 95.3227\n",
      "Epoch 6/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 91.7662 - val_loss: 95.5969\n",
      "Epoch 7/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.2918 - val_loss: 93.8660\n",
      "Epoch 8/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.2157 - val_loss: 94.2598\n",
      "Epoch 9/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.7248 - val_loss: 95.0155\n",
      "Epoch 10/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.0630 - val_loss: 96.7934\n",
      "Epoch 11/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 92.2294 - val_loss: 95.3928\n",
      "Epoch 12/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.7335 - val_loss: 95.9955\n",
      "Epoch 13/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.9416 - val_loss: 96.0691\n",
      "Epoch 14/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.8987 - val_loss: 94.7123\n",
      "Epoch 15/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.0969 - val_loss: 99.0294\n",
      "Epoch 16/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.4266 - val_loss: 98.1991\n",
      "Epoch 17/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.9596 - val_loss: 95.9285\n",
      "Epoch 18/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 92.1796 - val_loss: 95.3802\n",
      "Epoch 19/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.7986 - val_loss: 95.3997\n",
      "Epoch 20/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.1215 - val_loss: 95.5155\n",
      "Epoch 21/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.5312 - val_loss: 97.7928\n",
      "Epoch 22/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.2608 - val_loss: 100.1909\n",
      "Epoch 23/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.8139 - val_loss: 94.1290\n",
      "Epoch 24/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.6040 - val_loss: 96.1836\n",
      "Epoch 25/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.1644 - val_loss: 95.1278\n",
      "Epoch 26/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.0608 - val_loss: 95.1534\n",
      "Epoch 27/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 92.1394 - val_loss: 95.2015\n",
      "Epoch 28/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.8357 - val_loss: 102.0209\n",
      "Epoch 29/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.9659 - val_loss: 94.6863\n",
      "Epoch 30/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.5032 - val_loss: 95.2754\n",
      "Epoch 31/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.9975 - val_loss: 95.1902\n",
      "Epoch 32/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 92.1812 - val_loss: 95.6315\n",
      "Epoch 33/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.8490 - val_loss: 96.2967\n",
      "Epoch 34/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.7172 - val_loss: 96.3988\n",
      "Epoch 35/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.2642 - val_loss: 94.6425\n",
      "Epoch 36/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.2919 - val_loss: 95.7788\n",
      "Epoch 37/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 92.1201 - val_loss: 95.7753\n",
      "Epoch 38/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.5171 - val_loss: 96.3895\n",
      "Epoch 39/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.2225 - val_loss: 95.7241\n",
      "Epoch 40/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.3206 - val_loss: 94.5240\n",
      "Epoch 41/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 92.1426 - val_loss: 95.9500\n",
      "Epoch 42/2300\n",
      "17948/17948 [==============================] - 1s 48us/sample - loss: 91.2674 - val_loss: 96.7721\n",
      "Epoch 43/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 91.8022 - val_loss: 98.5026\n",
      "Epoch 44/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 91.6685 - val_loss: 94.2244\n",
      "Epoch 45/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 92.1287 - val_loss: 97.3090\n",
      "Epoch 46/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.3438 - val_loss: 97.3109\n",
      "Epoch 47/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.7706 - val_loss: 96.0564\n",
      "Epoch 48/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.7778 - val_loss: 97.2345\n",
      "Epoch 49/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.9987 - val_loss: 95.4483\n",
      "Epoch 50/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.7211 - val_loss: 98.3763\n",
      "Epoch 51/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 92.1607 - val_loss: 99.2635\n",
      "Epoch 52/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.5999 - val_loss: 95.7538\n",
      "Epoch 53/2300\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 91.9418 - val_loss: 97.0919\n",
      "Epoch 54/2300\n",
      "17948/17948 [==============================] - 1s 46us/sample - loss: 92.6469 - val_loss: 94.7019\n",
      "Epoch 55/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.4664 - val_loss: 94.8931\n",
      "Epoch 56/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.3391 - val_loss: 96.2317\n",
      "Epoch 57/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.6603 - val_loss: 99.4811\n",
      "Epoch 58/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 91.6306 - val_loss: 97.2586\n",
      "Epoch 59/2300\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 91.5233 - val_loss: 94.9835\n",
      "Epoch 60/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.4060 - val_loss: 94.6541\n",
      "Epoch 61/2300\n",
      "17948/17948 [==============================] - 1s 48us/sample - loss: 92.1420 - val_loss: 96.1327\n",
      "Epoch 62/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 91.7352 - val_loss: 95.2419\n",
      "Epoch 63/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.1083 - val_loss: 95.3969\n",
      "Epoch 64/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.7068 - val_loss: 96.0048\n",
      "Epoch 65/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 92.0666 - val_loss: 96.1788\n",
      "Epoch 66/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.3000 - val_loss: 97.0710\n",
      "Epoch 67/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 91.6440 - val_loss: 96.4001\n",
      "Epoch 68/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 92.1228 - val_loss: 95.7155\n",
      "Epoch 69/2300\n",
      "17948/17948 [==============================] - 1s 48us/sample - loss: 91.3057 - val_loss: 99.3470\n",
      "Epoch 70/2300\n",
      "17948/17948 [==============================] - 1s 48us/sample - loss: 91.7989 - val_loss: 95.0812\n",
      "Epoch 71/2300\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 91.8781 - val_loss: 96.3111\n",
      "Epoch 72/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.3272 - val_loss: 96.4043\n",
      "Epoch 73/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.1268 - val_loss: 95.3247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 91.4759 - val_loss: 94.4347\n",
      "Epoch 75/2300\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 91.7595 - val_loss: 95.6809\n",
      "Epoch 76/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.5518 - val_loss: 96.9502\n",
      "Epoch 77/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.7909 - val_loss: 97.2195\n",
      "Epoch 78/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.5134 - val_loss: 95.5530\n",
      "Epoch 79/2300\n",
      "17948/17948 [==============================] - 1s 45us/sample - loss: 91.1141 - val_loss: 96.0682\n",
      "Epoch 80/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 92.0900 - val_loss: 98.0023\n",
      "Epoch 81/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.0058 - val_loss: 97.5001\n",
      "Epoch 82/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.5674 - val_loss: 97.4776\n",
      "Epoch 83/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 91.3026 - val_loss: 96.8118\n",
      "Epoch 84/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.5341 - val_loss: 95.6861\n",
      "Epoch 85/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 92.0117 - val_loss: 96.2320\n",
      "Epoch 86/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.3048 - val_loss: 95.2015\n",
      "Epoch 87/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.6720 - val_loss: 98.4579\n",
      "Epoch 88/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.4236 - val_loss: 95.4875\n",
      "Epoch 89/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.7880 - val_loss: 96.6200\n",
      "Epoch 90/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.2386 - val_loss: 95.7224\n",
      "Epoch 91/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.5133 - val_loss: 95.9632\n",
      "Epoch 92/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.4170 - val_loss: 96.0923\n",
      "Epoch 93/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.7484 - val_loss: 96.4959\n",
      "Epoch 94/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 91.1585 - val_loss: 97.8057\n",
      "Epoch 95/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 92.0125 - val_loss: 96.4348\n",
      "Epoch 96/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.6579 - val_loss: 97.6269\n",
      "Epoch 97/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.9817 - val_loss: 97.5789\n",
      "Epoch 98/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.2473 - val_loss: 98.2080\n",
      "Epoch 99/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.8127 - val_loss: 98.5828\n",
      "Epoch 100/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.2568 - val_loss: 96.9751\n",
      "Epoch 101/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 91.5540 - val_loss: 95.6099\n",
      "Epoch 102/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.7397 - val_loss: 95.1765\n",
      "Epoch 103/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.9148 - val_loss: 95.5814\n",
      "Epoch 104/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.1241 - val_loss: 96.2477\n",
      "Epoch 105/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 92.1474 - val_loss: 96.0923\n",
      "Epoch 106/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.7293 - val_loss: 96.5443\n",
      "Epoch 107/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.1374 - val_loss: 95.5558\n",
      "Epoch 108/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.0566 - val_loss: 95.3010\n",
      "Epoch 109/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.9611 - val_loss: 97.8351\n",
      "Epoch 110/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.2231 - val_loss: 96.8528\n",
      "Epoch 111/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.6518 - val_loss: 95.4774\n",
      "Epoch 112/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.2497 - val_loss: 97.5856\n",
      "Epoch 113/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.1478 - val_loss: 96.3107\n",
      "Epoch 114/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.3516 - val_loss: 96.3479\n",
      "Epoch 115/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.1552 - val_loss: 102.3629\n",
      "Epoch 116/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.3785 - val_loss: 97.0193\n",
      "Epoch 117/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.0642 - val_loss: 95.3511\n",
      "Epoch 118/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.1931 - val_loss: 96.6672\n",
      "Epoch 119/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.7781 - val_loss: 96.5584\n",
      "Epoch 120/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.7551 - val_loss: 95.0581\n",
      "Epoch 121/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.6962 - val_loss: 97.3325\n",
      "Epoch 122/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 91.7551 - val_loss: 100.7307\n",
      "Epoch 123/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.8022 - val_loss: 97.3551\n",
      "Epoch 124/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.9849 - val_loss: 96.5548\n",
      "Epoch 125/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.3426 - val_loss: 95.5438\n",
      "Epoch 126/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8081 - val_loss: 96.8216\n",
      "Epoch 127/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.7559 - val_loss: 96.1863\n",
      "Epoch 128/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8177 - val_loss: 101.3555\n",
      "Epoch 129/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.9534 - val_loss: 94.9671\n",
      "Epoch 130/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.3329 - val_loss: 98.3688\n",
      "Epoch 131/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.9681 - val_loss: 96.5592\n",
      "Epoch 132/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 90.9395 - val_loss: 97.5329\n",
      "Epoch 133/2300\n",
      "17948/17948 [==============================] - 1s 50us/sample - loss: 91.2967 - val_loss: 95.0618\n",
      "Epoch 134/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.7338 - val_loss: 96.9460\n",
      "Epoch 135/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.6615 - val_loss: 95.8270\n",
      "Epoch 136/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.5316 - val_loss: 95.6699\n",
      "Epoch 137/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.1208 - val_loss: 96.1272\n",
      "Epoch 138/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.3641 - val_loss: 95.9433\n",
      "Epoch 139/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.8816 - val_loss: 96.4981\n",
      "Epoch 140/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.3361 - val_loss: 96.6191\n",
      "Epoch 141/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.5758 - val_loss: 95.8097\n",
      "Epoch 142/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.3625 - val_loss: 97.0862\n",
      "Epoch 143/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7149 - val_loss: 95.1705\n",
      "Epoch 144/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.2561 - val_loss: 96.0557\n",
      "Epoch 145/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.7173 - val_loss: 96.1991\n",
      "Epoch 146/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.7364 - val_loss: 96.1373\n",
      "Epoch 147/2300\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 90.9274 - val_loss: 101.9269\n",
      "Epoch 148/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 91.4677 - val_loss: 95.9990\n",
      "Epoch 149/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.8367 - val_loss: 95.9995\n",
      "Epoch 150/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.9181 - val_loss: 97.0408\n",
      "Epoch 151/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.0693 - val_loss: 97.1025\n",
      "Epoch 152/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.0297 - val_loss: 96.4842\n",
      "Epoch 153/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.6975 - val_loss: 97.2928\n",
      "Epoch 154/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 91.3364 - val_loss: 95.9269\n",
      "Epoch 155/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6988 - val_loss: 98.0589\n",
      "Epoch 156/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.3838 - val_loss: 98.4238\n",
      "Epoch 157/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.8999 - val_loss: 96.4004\n",
      "Epoch 158/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.8087 - val_loss: 97.6643\n",
      "Epoch 159/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.5473 - val_loss: 95.5492\n",
      "Epoch 160/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 91.3506 - val_loss: 96.0466\n",
      "Epoch 161/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 90.6892 - val_loss: 96.1851\n",
      "Epoch 162/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.8406 - val_loss: 96.3469\n",
      "Epoch 163/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.0355 - val_loss: 96.3447\n",
      "Epoch 164/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8705 - val_loss: 96.0206\n",
      "Epoch 165/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8080 - val_loss: 97.0117\n",
      "Epoch 166/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.1954 - val_loss: 96.2169\n",
      "Epoch 167/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8872 - val_loss: 95.7347\n",
      "Epoch 168/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6459 - val_loss: 103.5384\n",
      "Epoch 169/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.9719 - val_loss: 96.4727\n",
      "Epoch 170/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.0769 - val_loss: 96.2593\n",
      "Epoch 171/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8140 - val_loss: 96.5262\n",
      "Epoch 172/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7612 - val_loss: 97.1283\n",
      "Epoch 173/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7874 - val_loss: 98.3025\n",
      "Epoch 174/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.1674 - val_loss: 96.6976\n",
      "Epoch 175/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6950 - val_loss: 96.9516\n",
      "Epoch 176/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2122 - val_loss: 96.5516\n",
      "Epoch 177/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7341 - val_loss: 101.8805\n",
      "Epoch 178/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.1976 - val_loss: 96.5650\n",
      "Epoch 179/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.0397 - val_loss: 96.5813\n",
      "Epoch 180/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.1671 - val_loss: 96.3340\n",
      "Epoch 181/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6696 - val_loss: 95.8384\n",
      "Epoch 182/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.8237 - val_loss: 96.4023\n",
      "Epoch 183/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2233 - val_loss: 99.3735\n",
      "Epoch 184/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.9088 - val_loss: 97.5426\n",
      "Epoch 185/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6279 - val_loss: 96.8030\n",
      "Epoch 186/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.7042 - val_loss: 96.7264\n",
      "Epoch 187/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6772 - val_loss: 96.1333\n",
      "Epoch 188/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.3292 - val_loss: 99.2873\n",
      "Epoch 189/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6139 - val_loss: 97.4711\n",
      "Epoch 190/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.3401 - val_loss: 96.6422\n",
      "Epoch 191/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.9125 - val_loss: 96.8094\n",
      "Epoch 192/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.1494 - val_loss: 96.4739\n",
      "Epoch 193/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2863 - val_loss: 97.5171\n",
      "Epoch 194/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.3428 - val_loss: 98.2702\n",
      "Epoch 195/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1805 - val_loss: 99.0952\n",
      "Epoch 196/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 91.0721 - val_loss: 98.0245\n",
      "Epoch 197/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6780 - val_loss: 97.8887\n",
      "Epoch 198/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2545 - val_loss: 98.9427\n",
      "Epoch 199/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.4308 - val_loss: 98.7188\n",
      "Epoch 200/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.6904 - val_loss: 97.9413\n",
      "Epoch 201/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 90.2312 - val_loss: 95.8176\n",
      "Epoch 202/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 91.0853 - val_loss: 97.4250\n",
      "Epoch 203/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7134 - val_loss: 97.0075\n",
      "Epoch 204/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.3560 - val_loss: 96.7679\n",
      "Epoch 205/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.4523 - val_loss: 98.5751\n",
      "Epoch 206/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.7330 - val_loss: 97.7024\n",
      "Epoch 207/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.3238 - val_loss: 97.2230\n",
      "Epoch 208/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.4213 - val_loss: 97.5741\n",
      "Epoch 209/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8834 - val_loss: 97.7159\n",
      "Epoch 210/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.0361 - val_loss: 97.6177\n",
      "Epoch 211/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.5388 - val_loss: 95.5474\n",
      "Epoch 212/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.1167 - val_loss: 97.2545\n",
      "Epoch 213/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.4728 - val_loss: 97.4267\n",
      "Epoch 214/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 91.1231 - val_loss: 97.0775\n",
      "Epoch 215/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.4061 - val_loss: 98.2898\n",
      "Epoch 216/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.5755 - val_loss: 101.4506\n",
      "Epoch 217/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1975 - val_loss: 97.9645\n",
      "Epoch 218/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.2586 - val_loss: 98.8444\n",
      "Epoch 219/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.9049 - val_loss: 97.0043\n",
      "Epoch 220/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.3666 - val_loss: 96.0184\n",
      "Epoch 221/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.6642 - val_loss: 98.5320\n",
      "Epoch 222/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.9907 - val_loss: 97.1844\n",
      "Epoch 223/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.5572 - val_loss: 97.7326\n",
      "Epoch 224/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.6955 - val_loss: 96.4923\n",
      "Epoch 225/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1864 - val_loss: 98.0163\n",
      "Epoch 226/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 91.0475 - val_loss: 95.5144\n",
      "Epoch 227/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.0313 - val_loss: 98.1048\n",
      "Epoch 228/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.5651 - val_loss: 96.5292\n",
      "Epoch 229/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1337 - val_loss: 97.4607\n",
      "Epoch 230/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6576 - val_loss: 96.6404\n",
      "Epoch 231/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.7683 - val_loss: 96.7408\n",
      "Epoch 232/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.9538 - val_loss: 96.9719\n",
      "Epoch 233/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.4161 - val_loss: 97.1486\n",
      "Epoch 234/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2372 - val_loss: 97.2226\n",
      "Epoch 235/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.7486 - val_loss: 97.5529\n",
      "Epoch 236/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 90.0764 - val_loss: 96.6969\n",
      "Epoch 237/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.9700 - val_loss: 97.7879\n",
      "Epoch 238/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.2658 - val_loss: 97.1829\n",
      "Epoch 239/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.0828 - val_loss: 97.1944\n",
      "Epoch 240/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.9283 - val_loss: 99.1232\n",
      "Epoch 241/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.0154 - val_loss: 98.2818\n",
      "Epoch 242/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.6066 - val_loss: 97.5646\n",
      "Epoch 243/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2867 - val_loss: 98.7574\n",
      "Epoch 244/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2971 - val_loss: 97.8126\n",
      "Epoch 245/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.0365 - val_loss: 97.0036\n",
      "Epoch 246/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2236 - val_loss: 95.9602\n",
      "Epoch 247/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9047 - val_loss: 98.8794\n",
      "Epoch 248/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8045 - val_loss: 96.6768\n",
      "Epoch 249/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7919 - val_loss: 98.1492\n",
      "Epoch 250/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.4916 - val_loss: 96.8179\n",
      "Epoch 251/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 89.8344 - val_loss: 97.5350\n",
      "Epoch 252/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 90.0088 - val_loss: 97.0993\n",
      "Epoch 253/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.4364 - val_loss: 97.7303\n",
      "Epoch 254/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.4857 - val_loss: 100.1376\n",
      "Epoch 255/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 90.1763 - val_loss: 99.2609\n",
      "Epoch 256/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 90.7493 - val_loss: 98.1186\n",
      "Epoch 257/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 90.3171 - val_loss: 96.7647\n",
      "Epoch 258/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.3068 - val_loss: 97.2156\n",
      "Epoch 259/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.5567 - val_loss: 96.5424\n",
      "Epoch 260/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.0273 - val_loss: 96.2727\n",
      "Epoch 261/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.1494 - val_loss: 98.4133\n",
      "Epoch 262/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2258 - val_loss: 97.5009\n",
      "Epoch 263/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.1008 - val_loss: 97.6296\n",
      "Epoch 264/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2949 - val_loss: 103.4904\n",
      "Epoch 265/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.1239 - val_loss: 98.9590\n",
      "Epoch 266/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.5160 - val_loss: 96.4524\n",
      "Epoch 267/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.3504 - val_loss: 97.3618\n",
      "Epoch 268/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.2393 - val_loss: 98.6644\n",
      "Epoch 269/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 90.3490 - val_loss: 97.0505\n",
      "Epoch 270/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 89.7257 - val_loss: 100.9778\n",
      "Epoch 271/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.4400 - val_loss: 97.2291\n",
      "Epoch 272/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1938 - val_loss: 97.3166\n",
      "Epoch 273/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.0685 - val_loss: 97.7040\n",
      "Epoch 274/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2676 - val_loss: 97.7712\n",
      "Epoch 275/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1482 - val_loss: 98.2991\n",
      "Epoch 276/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2808 - val_loss: 97.3544\n",
      "Epoch 277/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 90.3106 - val_loss: 100.2025\n",
      "Epoch 278/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.9904 - val_loss: 96.4491\n",
      "Epoch 279/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.0734 - val_loss: 97.8355\n",
      "Epoch 280/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.4782 - val_loss: 97.9834\n",
      "Epoch 281/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.9077 - val_loss: 97.5264\n",
      "Epoch 282/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9503 - val_loss: 96.9556\n",
      "Epoch 283/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1745 - val_loss: 96.6014\n",
      "Epoch 284/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.9851 - val_loss: 96.1550\n",
      "Epoch 285/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.4579 - val_loss: 97.6198\n",
      "Epoch 286/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1210 - val_loss: 100.1839\n",
      "Epoch 287/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8691 - val_loss: 97.6556\n",
      "Epoch 288/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2746 - val_loss: 98.9905\n",
      "Epoch 289/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.0471 - val_loss: 98.0886\n",
      "Epoch 290/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8875 - val_loss: 98.1239\n",
      "Epoch 291/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.6508 - val_loss: 97.2261\n",
      "Epoch 292/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2008 - val_loss: 97.4855\n",
      "Epoch 293/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.8794 - val_loss: 97.3977\n",
      "Epoch 294/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.1704 - val_loss: 98.9232\n",
      "Epoch 295/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 90.4000 - val_loss: 97.5807\n",
      "Epoch 296/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.9920 - val_loss: 97.0240\n",
      "Epoch 297/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.9300 - val_loss: 99.0544\n",
      "Epoch 298/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.0400 - val_loss: 96.4748\n",
      "Epoch 299/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.3070 - val_loss: 98.4803\n",
      "Epoch 300/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.3854 - val_loss: 97.9454\n",
      "Epoch 301/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.0597 - val_loss: 97.6808\n",
      "Epoch 302/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6838 - val_loss: 98.0851\n",
      "Epoch 303/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.9748 - val_loss: 96.7510\n",
      "Epoch 304/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2960 - val_loss: 96.0977\n",
      "Epoch 305/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.4625 - val_loss: 96.4614\n",
      "Epoch 306/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8257 - val_loss: 96.6708\n",
      "Epoch 307/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8524 - val_loss: 96.5949\n",
      "Epoch 308/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.1849 - val_loss: 97.9457\n",
      "Epoch 309/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2759 - val_loss: 98.4456\n",
      "Epoch 310/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.2009 - val_loss: 98.4585\n",
      "Epoch 311/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8478 - val_loss: 97.9700\n",
      "Epoch 312/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.1437 - val_loss: 97.9247\n",
      "Epoch 313/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.1615 - val_loss: 98.3637\n",
      "Epoch 314/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.5110 - val_loss: 100.9446\n",
      "Epoch 315/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.7743 - val_loss: 99.5709\n",
      "Epoch 316/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.4950 - val_loss: 98.9110\n",
      "Epoch 317/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 90.1231 - val_loss: 97.9325\n",
      "Epoch 318/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8817 - val_loss: 97.6893\n",
      "Epoch 319/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8733 - val_loss: 96.8524\n",
      "Epoch 320/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6737 - val_loss: 100.1784\n",
      "Epoch 321/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.7911 - val_loss: 97.1251\n",
      "Epoch 322/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.9326 - val_loss: 99.9265\n",
      "Epoch 323/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.7721 - val_loss: 97.1419\n",
      "Epoch 324/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6408 - val_loss: 97.0989\n",
      "Epoch 325/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.4563 - val_loss: 97.1065\n",
      "Epoch 326/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6728 - val_loss: 97.3331\n",
      "Epoch 327/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.4519 - val_loss: 99.6665\n",
      "Epoch 328/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.0938 - val_loss: 99.9951\n",
      "Epoch 329/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8972 - val_loss: 98.5780\n",
      "Epoch 330/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7198 - val_loss: 97.0871\n",
      "Epoch 331/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6780 - val_loss: 97.6631\n",
      "Epoch 332/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.8300 - val_loss: 99.7744\n",
      "Epoch 333/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.2950 - val_loss: 97.5416\n",
      "Epoch 334/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.9566 - val_loss: 97.3799\n",
      "Epoch 335/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 90.9713 - val_loss: 100.4741\n",
      "Epoch 336/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.5706 - val_loss: 97.6186\n",
      "Epoch 337/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1423 - val_loss: 98.6703\n",
      "Epoch 338/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1042 - val_loss: 97.8473\n",
      "Epoch 339/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.8183 - val_loss: 98.7567\n",
      "Epoch 340/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8438 - val_loss: 96.9114\n",
      "Epoch 341/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.4094 - val_loss: 105.3716\n",
      "Epoch 342/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.8426 - val_loss: 99.0962\n",
      "Epoch 343/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 90.0702 - val_loss: 102.7072\n",
      "Epoch 344/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.7907 - val_loss: 96.6647\n",
      "Epoch 345/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.7244 - val_loss: 97.9395\n",
      "Epoch 346/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9271 - val_loss: 98.7299\n",
      "Epoch 347/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8707 - val_loss: 96.6164\n",
      "Epoch 348/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.3409 - val_loss: 98.1469\n",
      "Epoch 349/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.3802 - val_loss: 98.9978\n",
      "Epoch 350/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8308 - val_loss: 98.1841\n",
      "Epoch 351/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.0644 - val_loss: 98.2658\n",
      "Epoch 352/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5373 - val_loss: 98.0286\n",
      "Epoch 353/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.4738 - val_loss: 98.3369\n",
      "Epoch 354/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5247 - val_loss: 96.6293\n",
      "Epoch 355/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.2711 - val_loss: 97.2379\n",
      "Epoch 356/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9436 - val_loss: 96.9527\n",
      "Epoch 357/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.3695 - val_loss: 99.0327\n",
      "Epoch 358/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9229 - val_loss: 97.3371\n",
      "Epoch 359/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.6514 - val_loss: 98.3889\n",
      "Epoch 360/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2593 - val_loss: 100.9548\n",
      "Epoch 361/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6508 - val_loss: 97.5007\n",
      "Epoch 362/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8714 - val_loss: 99.9484\n",
      "Epoch 363/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6339 - val_loss: 97.1221\n",
      "Epoch 364/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6397 - val_loss: 99.9555\n",
      "Epoch 365/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6877 - val_loss: 97.2546\n",
      "Epoch 366/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8537 - val_loss: 97.6857\n",
      "Epoch 367/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9983 - val_loss: 98.6952\n",
      "Epoch 368/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5467 - val_loss: 97.4683\n",
      "Epoch 369/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9043 - val_loss: 96.4432\n",
      "Epoch 370/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.4476 - val_loss: 98.0508\n",
      "Epoch 371/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6298 - val_loss: 97.6779\n",
      "Epoch 372/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 90.1112 - val_loss: 98.4211\n",
      "Epoch 373/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.4578 - val_loss: 97.2978\n",
      "Epoch 374/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2460 - val_loss: 98.5765\n",
      "Epoch 375/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.9295 - val_loss: 98.2853\n",
      "Epoch 376/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.2195 - val_loss: 97.2552\n",
      "Epoch 377/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.3820 - val_loss: 99.9972\n",
      "Epoch 378/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.8854 - val_loss: 97.3732\n",
      "Epoch 379/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.5762 - val_loss: 99.6443\n",
      "Epoch 380/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6984 - val_loss: 98.0394\n",
      "Epoch 381/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5182 - val_loss: 99.7040\n",
      "Epoch 382/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5910 - val_loss: 98.3187\n",
      "Epoch 383/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5440 - val_loss: 97.5636\n",
      "Epoch 384/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8174 - val_loss: 100.1697\n",
      "Epoch 385/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8694 - val_loss: 100.6248\n",
      "Epoch 386/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9289 - val_loss: 96.8465\n",
      "Epoch 387/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8268 - val_loss: 98.2510\n",
      "Epoch 388/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.8827 - val_loss: 97.2085\n",
      "Epoch 389/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.6744 - val_loss: 100.6237\n",
      "Epoch 390/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.5935 - val_loss: 98.1197\n",
      "Epoch 391/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.3637 - val_loss: 99.1720\n",
      "Epoch 392/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.5475 - val_loss: 97.8309\n",
      "Epoch 393/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 90.1108 - val_loss: 97.6815\n",
      "Epoch 394/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.9814 - val_loss: 101.1967\n",
      "Epoch 395/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6543 - val_loss: 98.6471\n",
      "Epoch 396/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.7869 - val_loss: 98.2737\n",
      "Epoch 397/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6554 - val_loss: 99.0718\n",
      "Epoch 398/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.6246 - val_loss: 98.1185\n",
      "Epoch 399/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6288 - val_loss: 98.2310\n",
      "Epoch 400/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0766 - val_loss: 99.8973\n",
      "Epoch 401/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.4002 - val_loss: 98.8074\n",
      "Epoch 402/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.3918 - val_loss: 103.6383\n",
      "Epoch 403/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.5607 - val_loss: 98.2368\n",
      "Epoch 404/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5124 - val_loss: 98.3110\n",
      "Epoch 405/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.5785 - val_loss: 99.0089\n",
      "Epoch 406/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.4504 - val_loss: 97.5359\n",
      "Epoch 407/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.7672 - val_loss: 98.3026\n",
      "Epoch 408/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.9639 - val_loss: 96.9654\n",
      "Epoch 409/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.7744 - val_loss: 101.3928\n",
      "Epoch 410/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.1520 - val_loss: 98.1364\n",
      "Epoch 411/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.4316 - val_loss: 97.6262\n",
      "Epoch 412/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.6831 - val_loss: 98.4741\n",
      "Epoch 413/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.9691 - val_loss: 98.7386\n",
      "Epoch 414/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.2283 - val_loss: 99.2506\n",
      "Epoch 415/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.6415 - val_loss: 96.8964\n",
      "Epoch 416/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.8955 - val_loss: 99.0565\n",
      "Epoch 417/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.0945 - val_loss: 99.4557\n",
      "Epoch 418/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.4568 - val_loss: 98.2398\n",
      "Epoch 419/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.5465 - val_loss: 103.4973\n",
      "Epoch 420/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.2054 - val_loss: 100.1568\n",
      "Epoch 421/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 89.4267 - val_loss: 101.2673\n",
      "Epoch 422/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.5448 - val_loss: 99.0201\n",
      "Epoch 423/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 89.4899 - val_loss: 99.0343\n",
      "Epoch 424/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 89.4032 - val_loss: 97.9692\n",
      "Epoch 425/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.5618 - val_loss: 100.1449\n",
      "Epoch 426/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.9783 - val_loss: 98.2554\n",
      "Epoch 427/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.8784 - val_loss: 99.1873\n",
      "Epoch 428/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 89.5237 - val_loss: 100.3333\n",
      "Epoch 429/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 89.6137 - val_loss: 97.5917\n",
      "Epoch 430/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6737 - val_loss: 100.9957\n",
      "Epoch 431/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3285 - val_loss: 100.0229\n",
      "Epoch 432/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.1395 - val_loss: 98.1963\n",
      "Epoch 433/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.1227 - val_loss: 99.8339\n",
      "Epoch 434/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.7963 - val_loss: 100.0571\n",
      "Epoch 435/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2383 - val_loss: 100.2760\n",
      "Epoch 436/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.1178 - val_loss: 98.7627\n",
      "Epoch 437/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.3000 - val_loss: 98.5974\n",
      "Epoch 438/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9077 - val_loss: 103.1223\n",
      "Epoch 439/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.7513 - val_loss: 98.0587\n",
      "Epoch 440/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.2929 - val_loss: 99.9698\n",
      "Epoch 441/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6921 - val_loss: 99.1327\n",
      "Epoch 442/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.3468 - val_loss: 98.6052\n",
      "Epoch 443/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2518 - val_loss: 97.6272\n",
      "Epoch 444/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8838 - val_loss: 98.9842\n",
      "Epoch 445/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.8322 - val_loss: 97.1158\n",
      "Epoch 446/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3487 - val_loss: 97.9824\n",
      "Epoch 447/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9991 - val_loss: 100.6992\n",
      "Epoch 448/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1850 - val_loss: 98.6746\n",
      "Epoch 449/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3097 - val_loss: 98.3755\n",
      "Epoch 450/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9351 - val_loss: 99.9103\n",
      "Epoch 451/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0415 - val_loss: 99.4448\n",
      "Epoch 452/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.3462 - val_loss: 98.2346\n",
      "Epoch 453/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.4729 - val_loss: 100.4668\n",
      "Epoch 454/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1722 - val_loss: 97.8978\n",
      "Epoch 455/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9274 - val_loss: 100.8657\n",
      "Epoch 456/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3126 - val_loss: 98.8329\n",
      "Epoch 457/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.5015 - val_loss: 99.0143\n",
      "Epoch 458/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9497 - val_loss: 100.3729\n",
      "Epoch 459/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3472 - val_loss: 98.5796\n",
      "Epoch 460/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3382 - val_loss: 98.3567\n",
      "Epoch 461/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9933 - val_loss: 98.2547\n",
      "Epoch 462/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1797 - val_loss: 101.9406\n",
      "Epoch 463/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1197 - val_loss: 101.6179\n",
      "Epoch 464/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.5920 - val_loss: 98.2791\n",
      "Epoch 465/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1618 - val_loss: 99.9907\n",
      "Epoch 466/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.8369 - val_loss: 98.8625\n",
      "Epoch 467/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7889 - val_loss: 98.1080\n",
      "Epoch 468/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.4795 - val_loss: 99.9663\n",
      "Epoch 469/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1627 - val_loss: 100.6774\n",
      "Epoch 470/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.5333 - val_loss: 100.2748\n",
      "Epoch 471/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4379 - val_loss: 102.1703\n",
      "Epoch 472/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3540 - val_loss: 99.6115\n",
      "Epoch 473/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9897 - val_loss: 98.9944\n",
      "Epoch 474/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.1098 - val_loss: 96.9478\n",
      "Epoch 475/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.8872 - val_loss: 98.6076\n",
      "Epoch 476/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8803 - val_loss: 100.0812\n",
      "Epoch 477/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3595 - val_loss: 99.3353\n",
      "Epoch 478/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 90.0790 - val_loss: 99.0274\n",
      "Epoch 479/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8868 - val_loss: 100.1984\n",
      "Epoch 480/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.2277 - val_loss: 98.6866\n",
      "Epoch 481/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9806 - val_loss: 99.8344\n",
      "Epoch 482/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.4125 - val_loss: 99.1633\n",
      "Epoch 483/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0216 - val_loss: 97.9300\n",
      "Epoch 484/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7053 - val_loss: 101.7118\n",
      "Epoch 485/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.2252 - val_loss: 99.7532\n",
      "Epoch 486/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3143 - val_loss: 101.1883\n",
      "Epoch 487/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9864 - val_loss: 100.3031\n",
      "Epoch 488/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.4839 - val_loss: 99.7620\n",
      "Epoch 489/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8872 - val_loss: 98.2809\n",
      "Epoch 490/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8317 - val_loss: 99.0701\n",
      "Epoch 491/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 89.3305 - val_loss: 100.0410\n",
      "Epoch 492/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.9246 - val_loss: 98.7492\n",
      "Epoch 493/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.4799 - val_loss: 98.9016\n",
      "Epoch 494/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.9658 - val_loss: 99.4143\n",
      "Epoch 495/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.1704 - val_loss: 102.9148\n",
      "Epoch 496/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.6123 - val_loss: 100.8793\n",
      "Epoch 497/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0427 - val_loss: 99.5725\n",
      "Epoch 498/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.7913 - val_loss: 97.6164\n",
      "Epoch 499/2300\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 89.0896 - val_loss: 99.0128\n",
      "Epoch 500/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 89.4531 - val_loss: 99.2782\n",
      "Epoch 501/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 89.0043 - val_loss: 99.6458\n",
      "Epoch 502/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.8889 - val_loss: 100.0104\n",
      "Epoch 503/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 89.2353 - val_loss: 98.6177\n",
      "Epoch 504/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 89.0963 - val_loss: 99.9013\n",
      "Epoch 505/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 89.7606 - val_loss: 98.1787\n",
      "Epoch 506/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9204 - val_loss: 100.4771\n",
      "Epoch 507/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 88.9044 - val_loss: 101.0277\n",
      "Epoch 508/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.6194 - val_loss: 99.3190\n",
      "Epoch 509/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0927 - val_loss: 98.5898\n",
      "Epoch 510/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2993 - val_loss: 97.8628\n",
      "Epoch 511/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3424 - val_loss: 98.4593\n",
      "Epoch 512/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0696 - val_loss: 99.4484\n",
      "Epoch 513/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.1153 - val_loss: 99.8090\n",
      "Epoch 514/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 89.4528 - val_loss: 101.9494\n",
      "Epoch 515/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.9014 - val_loss: 100.4078\n",
      "Epoch 516/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.8065 - val_loss: 100.1227\n",
      "Epoch 517/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0984 - val_loss: 99.0146\n",
      "Epoch 518/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8152 - val_loss: 99.2678\n",
      "Epoch 519/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8049 - val_loss: 99.7994\n",
      "Epoch 520/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1651 - val_loss: 99.9758\n",
      "Epoch 521/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1947 - val_loss: 100.3524\n",
      "Epoch 522/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1107 - val_loss: 105.5051\n",
      "Epoch 523/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.5638 - val_loss: 98.9733\n",
      "Epoch 524/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.8959 - val_loss: 101.6517\n",
      "Epoch 525/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.3414 - val_loss: 99.0520\n",
      "Epoch 526/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8340 - val_loss: 99.1296\n",
      "Epoch 527/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6626 - val_loss: 101.9788\n",
      "Epoch 528/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9871 - val_loss: 100.2985\n",
      "Epoch 529/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.4959 - val_loss: 102.6507\n",
      "Epoch 530/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2129 - val_loss: 98.9954\n",
      "Epoch 531/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.3975 - val_loss: 99.2601\n",
      "Epoch 532/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8048 - val_loss: 99.1965\n",
      "Epoch 533/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.2096 - val_loss: 99.3208\n",
      "Epoch 534/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7367 - val_loss: 99.2572\n",
      "Epoch 535/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9470 - val_loss: 99.2950\n",
      "Epoch 536/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7068 - val_loss: 100.1220\n",
      "Epoch 537/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6023 - val_loss: 100.9840\n",
      "Epoch 538/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0685 - val_loss: 100.4966\n",
      "Epoch 539/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.4514 - val_loss: 104.2063\n",
      "Epoch 540/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 88.6597 - val_loss: 99.6220\n",
      "Epoch 541/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.5916 - val_loss: 99.4335\n",
      "Epoch 542/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.4373 - val_loss: 99.6307\n",
      "Epoch 543/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.6847 - val_loss: 98.8861\n",
      "Epoch 544/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.4656 - val_loss: 104.0092\n",
      "Epoch 545/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.9282 - val_loss: 98.8838\n",
      "Epoch 546/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8608 - val_loss: 103.6691\n",
      "Epoch 547/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0115 - val_loss: 98.8783\n",
      "Epoch 548/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.3249 - val_loss: 98.9234\n",
      "Epoch 549/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.8329 - val_loss: 99.0492\n",
      "Epoch 550/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.7228 - val_loss: 101.0242\n",
      "Epoch 551/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6589 - val_loss: 100.0080\n",
      "Epoch 552/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9752 - val_loss: 99.2535\n",
      "Epoch 553/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0224 - val_loss: 98.7994\n",
      "Epoch 554/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.8232 - val_loss: 99.0233\n",
      "Epoch 555/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6938 - val_loss: 99.7091\n",
      "Epoch 556/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.2422 - val_loss: 100.3936\n",
      "Epoch 557/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6764 - val_loss: 100.7853\n",
      "Epoch 558/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0484 - val_loss: 100.1547\n",
      "Epoch 559/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9547 - val_loss: 104.3176\n",
      "Epoch 560/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.9293 - val_loss: 99.1395\n",
      "Epoch 561/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.8740 - val_loss: 103.6668\n",
      "Epoch 562/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0354 - val_loss: 99.6007\n",
      "Epoch 563/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6115 - val_loss: 101.1635\n",
      "Epoch 564/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7601 - val_loss: 99.4316\n",
      "Epoch 565/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7213 - val_loss: 101.6467\n",
      "Epoch 566/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.5508 - val_loss: 99.2171\n",
      "Epoch 567/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.4125 - val_loss: 99.1799\n",
      "Epoch 568/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5751 - val_loss: 103.7169\n",
      "Epoch 569/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9868 - val_loss: 101.9719\n",
      "Epoch 570/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.6390 - val_loss: 98.8466\n",
      "Epoch 571/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0397 - val_loss: 100.6603\n",
      "Epoch 572/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9295 - val_loss: 98.6569\n",
      "Epoch 573/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3029 - val_loss: 99.5522\n",
      "Epoch 574/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0712 - val_loss: 100.2247\n",
      "Epoch 575/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7723 - val_loss: 100.6062\n",
      "Epoch 576/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1254 - val_loss: 98.3795\n",
      "Epoch 577/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.5336 - val_loss: 98.8910\n",
      "Epoch 578/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.4778 - val_loss: 100.2291\n",
      "Epoch 579/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.4015 - val_loss: 101.0481\n",
      "Epoch 580/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7957 - val_loss: 99.7387\n",
      "Epoch 581/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.3772 - val_loss: 99.1476\n",
      "Epoch 582/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.6915 - val_loss: 98.9879\n",
      "Epoch 583/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8692 - val_loss: 99.3167\n",
      "Epoch 584/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9789 - val_loss: 99.4882\n",
      "Epoch 585/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3536 - val_loss: 101.8542\n",
      "Epoch 586/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6455 - val_loss: 104.7560\n",
      "Epoch 587/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8093 - val_loss: 99.1737\n",
      "Epoch 588/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8902 - val_loss: 100.3645\n",
      "Epoch 589/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.1080 - val_loss: 99.6134\n",
      "Epoch 590/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6031 - val_loss: 99.7584\n",
      "Epoch 591/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.8687 - val_loss: 98.7949\n",
      "Epoch 592/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8575 - val_loss: 98.5101\n",
      "Epoch 593/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0104 - val_loss: 98.9175\n",
      "Epoch 594/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9631 - val_loss: 99.6713\n",
      "Epoch 595/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3453 - val_loss: 101.5508\n",
      "Epoch 596/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4897 - val_loss: 103.4923\n",
      "Epoch 597/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6881 - val_loss: 98.6281\n",
      "Epoch 598/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.5432 - val_loss: 101.3026\n",
      "Epoch 599/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.2856 - val_loss: 101.4918\n",
      "Epoch 600/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8197 - val_loss: 99.5107\n",
      "Epoch 601/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.6193 - val_loss: 98.4677\n",
      "Epoch 602/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.4825 - val_loss: 101.5308\n",
      "Epoch 603/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9768 - val_loss: 100.4148\n",
      "Epoch 604/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3013 - val_loss: 99.9825\n",
      "Epoch 605/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1346 - val_loss: 98.6817\n",
      "Epoch 606/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9960 - val_loss: 100.4894\n",
      "Epoch 607/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8161 - val_loss: 99.8193\n",
      "Epoch 608/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8477 - val_loss: 99.2543\n",
      "Epoch 609/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.7557 - val_loss: 101.5331\n",
      "Epoch 610/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.4389 - val_loss: 100.8894\n",
      "Epoch 611/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.5880 - val_loss: 99.1489\n",
      "Epoch 612/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9962 - val_loss: 100.8863\n",
      "Epoch 613/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5141 - val_loss: 99.5917\n",
      "Epoch 614/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3317 - val_loss: 101.3551\n",
      "Epoch 615/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3647 - val_loss: 100.9484\n",
      "Epoch 616/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6107 - val_loss: 98.8808\n",
      "Epoch 617/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.0143 - val_loss: 99.0903\n",
      "Epoch 618/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 89.1949 - val_loss: 100.6864\n",
      "Epoch 619/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.5642 - val_loss: 98.9429\n",
      "Epoch 620/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 89.1895 - val_loss: 100.1992\n",
      "Epoch 621/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3207 - val_loss: 99.5411\n",
      "Epoch 622/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3362 - val_loss: 99.2422\n",
      "Epoch 623/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.5338 - val_loss: 99.6414\n",
      "Epoch 624/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.5535 - val_loss: 100.0640\n",
      "Epoch 625/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3246 - val_loss: 100.3968\n",
      "Epoch 626/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.4837 - val_loss: 100.1222\n",
      "Epoch 627/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1979 - val_loss: 99.8593\n",
      "Epoch 628/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.7472 - val_loss: 101.9072\n",
      "Epoch 629/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.5681 - val_loss: 99.7710\n",
      "Epoch 630/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.1656 - val_loss: 100.3153\n",
      "Epoch 631/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3674 - val_loss: 99.6758\n",
      "Epoch 632/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.4016 - val_loss: 100.2346\n",
      "Epoch 633/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.2333 - val_loss: 101.7229\n",
      "Epoch 634/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9421 - val_loss: 99.4928\n",
      "Epoch 635/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6563 - val_loss: 100.0981\n",
      "Epoch 636/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.8740 - val_loss: 100.7789\n",
      "Epoch 637/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.2217 - val_loss: 103.8396\n",
      "Epoch 638/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1472 - val_loss: 105.4671\n",
      "Epoch 639/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6807 - val_loss: 99.7844\n",
      "Epoch 640/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5403 - val_loss: 99.8594\n",
      "Epoch 641/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3147 - val_loss: 98.5657\n",
      "Epoch 642/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5559 - val_loss: 99.0653\n",
      "Epoch 643/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2480 - val_loss: 99.4716\n",
      "Epoch 644/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.2648 - val_loss: 99.9588\n",
      "Epoch 645/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1702 - val_loss: 99.2394\n",
      "Epoch 646/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2220 - val_loss: 99.1871\n",
      "Epoch 647/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4747 - val_loss: 101.4149\n",
      "Epoch 648/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3472 - val_loss: 100.4075\n",
      "Epoch 649/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.5888 - val_loss: 100.8351\n",
      "Epoch 650/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3700 - val_loss: 99.2709\n",
      "Epoch 651/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.7838 - val_loss: 101.4064\n",
      "Epoch 652/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0619 - val_loss: 99.3697\n",
      "Epoch 653/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.6231 - val_loss: 99.6025\n",
      "Epoch 654/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.4704 - val_loss: 99.2810\n",
      "Epoch 655/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1851 - val_loss: 99.9805\n",
      "Epoch 656/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3739 - val_loss: 99.9632\n",
      "Epoch 657/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3519 - val_loss: 101.2058\n",
      "Epoch 658/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8800 - val_loss: 103.2764\n",
      "Epoch 659/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.6282 - val_loss: 101.3925\n",
      "Epoch 660/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2604 - val_loss: 99.6333\n",
      "Epoch 661/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.9889 - val_loss: 100.8661\n",
      "Epoch 662/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.4090 - val_loss: 99.7163\n",
      "Epoch 663/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7294 - val_loss: 100.1157\n",
      "Epoch 664/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3289 - val_loss: 99.6245\n",
      "Epoch 665/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4666 - val_loss: 100.4658\n",
      "Epoch 666/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1264 - val_loss: 98.9401\n",
      "Epoch 667/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3273 - val_loss: 99.1551\n",
      "Epoch 668/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.8785 - val_loss: 106.2179\n",
      "Epoch 669/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4427 - val_loss: 100.9429\n",
      "Epoch 670/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1499 - val_loss: 101.7506\n",
      "Epoch 671/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2474 - val_loss: 100.4078\n",
      "Epoch 672/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4247 - val_loss: 100.2118\n",
      "Epoch 673/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1415 - val_loss: 99.1719\n",
      "Epoch 674/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0932 - val_loss: 100.9863\n",
      "Epoch 675/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.9832 - val_loss: 102.0398\n",
      "Epoch 676/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2860 - val_loss: 102.1116\n",
      "Epoch 677/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 89.0009 - val_loss: 99.8539\n",
      "Epoch 678/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9785 - val_loss: 101.2257\n",
      "Epoch 679/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4901 - val_loss: 100.3580\n",
      "Epoch 680/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.9088 - val_loss: 101.1679\n",
      "Epoch 681/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4856 - val_loss: 100.5552\n",
      "Epoch 682/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5238 - val_loss: 99.2505\n",
      "Epoch 683/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4450 - val_loss: 101.4266\n",
      "Epoch 684/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0347 - val_loss: 102.1179\n",
      "Epoch 685/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5238 - val_loss: 101.1739\n",
      "Epoch 686/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0660 - val_loss: 99.9860\n",
      "Epoch 687/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4698 - val_loss: 100.9801\n",
      "Epoch 688/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0935 - val_loss: 103.3095\n",
      "Epoch 689/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4386 - val_loss: 101.5355\n",
      "Epoch 690/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0665 - val_loss: 102.7524\n",
      "Epoch 691/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2749 - val_loss: 101.1826\n",
      "Epoch 692/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2668 - val_loss: 100.5645\n",
      "Epoch 693/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1537 - val_loss: 103.0412\n",
      "Epoch 694/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3133 - val_loss: 100.8953\n",
      "Epoch 695/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5718 - val_loss: 100.3624\n",
      "Epoch 696/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 87.9857 - val_loss: 99.0875\n",
      "Epoch 697/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4357 - val_loss: 100.1488\n",
      "Epoch 698/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3714 - val_loss: 101.8230\n",
      "Epoch 699/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3252 - val_loss: 100.8682\n",
      "Epoch 700/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 88.4926 - val_loss: 101.0504\n",
      "Epoch 701/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.5452 - val_loss: 99.4876\n",
      "Epoch 702/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.7080 - val_loss: 101.5582\n",
      "Epoch 703/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.9360 - val_loss: 101.6862\n",
      "Epoch 704/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.1723 - val_loss: 101.1405\n",
      "Epoch 705/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.1664 - val_loss: 101.2382\n",
      "Epoch 706/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 88.9143 - val_loss: 99.5540\n",
      "Epoch 707/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 87.7575 - val_loss: 100.0556\n",
      "Epoch 708/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 88.6054 - val_loss: 101.6591\n",
      "Epoch 709/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.4888 - val_loss: 101.1830\n",
      "Epoch 710/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.4688 - val_loss: 99.9722\n",
      "Epoch 711/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 88.2165 - val_loss: 99.4458\n",
      "Epoch 712/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.5748 - val_loss: 99.7894\n",
      "Epoch 713/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.6065 - val_loss: 99.6446\n",
      "Epoch 714/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.0218 - val_loss: 99.7762\n",
      "Epoch 715/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.8750 - val_loss: 100.2250\n",
      "Epoch 716/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.3058 - val_loss: 101.5691\n",
      "Epoch 717/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.2616 - val_loss: 101.7546\n",
      "Epoch 718/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0822 - val_loss: 103.7560\n",
      "Epoch 719/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.7953 - val_loss: 101.7081\n",
      "Epoch 720/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3739 - val_loss: 99.9482\n",
      "Epoch 721/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0923 - val_loss: 100.4356\n",
      "Epoch 722/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9834 - val_loss: 103.9414\n",
      "Epoch 723/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0348 - val_loss: 106.3534\n",
      "Epoch 724/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1570 - val_loss: 101.4682\n",
      "Epoch 725/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.6220 - val_loss: 101.1808\n",
      "Epoch 726/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.2700 - val_loss: 101.5389\n",
      "Epoch 727/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9445 - val_loss: 102.4602\n",
      "Epoch 728/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9831 - val_loss: 100.3217\n",
      "Epoch 729/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.9947 - val_loss: 103.7258\n",
      "Epoch 730/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0589 - val_loss: 99.4058\n",
      "Epoch 731/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.3304 - val_loss: 101.2327\n",
      "Epoch 732/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.4001 - val_loss: 102.2568\n",
      "Epoch 733/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3460 - val_loss: 101.5239\n",
      "Epoch 734/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3909 - val_loss: 99.2305\n",
      "Epoch 735/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.2268 - val_loss: 99.6497\n",
      "Epoch 736/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.9754 - val_loss: 101.6452\n",
      "Epoch 737/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1703 - val_loss: 100.1728\n",
      "Epoch 738/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1439 - val_loss: 101.4180\n",
      "Epoch 739/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.9431 - val_loss: 100.5155\n",
      "Epoch 740/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5711 - val_loss: 103.8350\n",
      "Epoch 741/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9020 - val_loss: 100.2036\n",
      "Epoch 742/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1398 - val_loss: 100.5088\n",
      "Epoch 743/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.5906 - val_loss: 100.8586\n",
      "Epoch 744/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3093 - val_loss: 101.5715\n",
      "Epoch 745/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1725 - val_loss: 100.8020\n",
      "Epoch 746/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.7134 - val_loss: 101.1120\n",
      "Epoch 747/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.9077 - val_loss: 101.5625\n",
      "Epoch 748/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 88.3634 - val_loss: 105.4006\n",
      "Epoch 749/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.0405 - val_loss: 100.8823\n",
      "Epoch 750/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.2008 - val_loss: 102.9186\n",
      "Epoch 751/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.3601 - val_loss: 99.8256\n",
      "Epoch 752/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.9029 - val_loss: 100.8691\n",
      "Epoch 753/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.2894 - val_loss: 101.3017\n",
      "Epoch 754/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.6716 - val_loss: 101.8336\n",
      "Epoch 755/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 88.2877 - val_loss: 103.5386\n",
      "Epoch 756/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 87.6982 - val_loss: 103.6931\n",
      "Epoch 757/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.3027 - val_loss: 101.3557\n",
      "Epoch 758/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2728 - val_loss: 102.1160\n",
      "Epoch 759/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4454 - val_loss: 99.6245\n",
      "Epoch 760/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.3252 - val_loss: 101.5593\n",
      "Epoch 761/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8544 - val_loss: 101.8747\n",
      "Epoch 762/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.9455 - val_loss: 100.2644\n",
      "Epoch 763/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7263 - val_loss: 101.7062\n",
      "Epoch 764/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.4085 - val_loss: 100.9038\n",
      "Epoch 765/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.5569 - val_loss: 101.9529\n",
      "Epoch 766/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2520 - val_loss: 100.7414\n",
      "Epoch 767/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.9769 - val_loss: 100.3653\n",
      "Epoch 768/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8954 - val_loss: 101.7228\n",
      "Epoch 769/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3573 - val_loss: 100.1353\n",
      "Epoch 770/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2718 - val_loss: 99.6392\n",
      "Epoch 771/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.9751 - val_loss: 102.3302\n",
      "Epoch 772/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.5084 - val_loss: 101.2999\n",
      "Epoch 773/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.1379 - val_loss: 102.4729\n",
      "Epoch 774/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1417 - val_loss: 101.9419\n",
      "Epoch 775/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.9408 - val_loss: 101.4268\n",
      "Epoch 776/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.6894 - val_loss: 99.9035\n",
      "Epoch 777/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.8077 - val_loss: 103.4519\n",
      "Epoch 778/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.2527 - val_loss: 100.0989\n",
      "Epoch 779/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1865 - val_loss: 103.7756\n",
      "Epoch 780/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9718 - val_loss: 100.5951\n",
      "Epoch 781/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8329 - val_loss: 101.2972\n",
      "Epoch 782/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9719 - val_loss: 101.8019\n",
      "Epoch 783/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7852 - val_loss: 101.8725\n",
      "Epoch 784/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1988 - val_loss: 100.8874\n",
      "Epoch 785/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.7918 - val_loss: 100.9969\n",
      "Epoch 786/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7196 - val_loss: 101.1201\n",
      "Epoch 787/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7712 - val_loss: 101.4729\n",
      "Epoch 788/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7429 - val_loss: 103.9299\n",
      "Epoch 789/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0763 - val_loss: 102.7777\n",
      "Epoch 790/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8688 - val_loss: 101.7714\n",
      "Epoch 791/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1842 - val_loss: 101.2396\n",
      "Epoch 792/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1461 - val_loss: 100.6956\n",
      "Epoch 793/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6855 - val_loss: 101.4847\n",
      "Epoch 794/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8616 - val_loss: 101.9086\n",
      "Epoch 795/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 88.2067 - val_loss: 101.0846\n",
      "Epoch 796/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 87.5480 - val_loss: 100.2436\n",
      "Epoch 797/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.7152 - val_loss: 100.3047\n",
      "Epoch 798/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.9072 - val_loss: 101.0687\n",
      "Epoch 799/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7449 - val_loss: 102.2411\n",
      "Epoch 800/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7409 - val_loss: 103.5209\n",
      "Epoch 801/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9272 - val_loss: 100.2460\n",
      "Epoch 802/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 88.4690 - val_loss: 104.8713\n",
      "Epoch 803/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 88.2400 - val_loss: 103.5973\n",
      "Epoch 804/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.7354 - val_loss: 100.9821\n",
      "Epoch 805/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.0459 - val_loss: 103.4605\n",
      "Epoch 806/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4496 - val_loss: 101.5115\n",
      "Epoch 807/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.2589 - val_loss: 101.3403\n",
      "Epoch 808/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1226 - val_loss: 102.6169\n",
      "Epoch 809/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.9934 - val_loss: 99.8109\n",
      "Epoch 810/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.8381 - val_loss: 103.2956\n",
      "Epoch 811/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.0353 - val_loss: 100.6689\n",
      "Epoch 812/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6360 - val_loss: 103.2532\n",
      "Epoch 813/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6470 - val_loss: 100.4068\n",
      "Epoch 814/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7469 - val_loss: 100.8922\n",
      "Epoch 815/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.8322 - val_loss: 100.3690\n",
      "Epoch 816/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.7096 - val_loss: 100.5142\n",
      "Epoch 817/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1360 - val_loss: 101.8239\n",
      "Epoch 818/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.2573 - val_loss: 101.8567\n",
      "Epoch 819/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.1129 - val_loss: 101.9865\n",
      "Epoch 820/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0581 - val_loss: 101.8853\n",
      "Epoch 821/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6143 - val_loss: 102.1312\n",
      "Epoch 822/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8366 - val_loss: 102.0776\n",
      "Epoch 823/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.5709 - val_loss: 101.6369\n",
      "Epoch 824/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.7148 - val_loss: 101.8537\n",
      "Epoch 825/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.6049 - val_loss: 103.6722\n",
      "Epoch 826/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0141 - val_loss: 100.9139\n",
      "Epoch 827/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8664 - val_loss: 101.8688\n",
      "Epoch 828/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7837 - val_loss: 102.0314\n",
      "Epoch 829/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.9683 - val_loss: 102.7652\n",
      "Epoch 830/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.0673 - val_loss: 101.7956\n",
      "Epoch 831/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6613 - val_loss: 101.0968\n",
      "Epoch 832/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.3480 - val_loss: 105.5551\n",
      "Epoch 833/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3689 - val_loss: 100.6808\n",
      "Epoch 834/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.1895 - val_loss: 101.6514\n",
      "Epoch 835/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.8353 - val_loss: 103.3753\n",
      "Epoch 836/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.1149 - val_loss: 102.2033\n",
      "Epoch 837/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.9664 - val_loss: 100.6344\n",
      "Epoch 838/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.5653 - val_loss: 102.1883\n",
      "Epoch 839/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.9484 - val_loss: 101.2477\n",
      "Epoch 840/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8123 - val_loss: 101.1256\n",
      "Epoch 841/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.5862 - val_loss: 101.6174\n",
      "Epoch 842/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2448 - val_loss: 101.4271\n",
      "Epoch 843/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.6273 - val_loss: 101.9225\n",
      "Epoch 844/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.2038 - val_loss: 100.7930\n",
      "Epoch 845/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.0261 - val_loss: 103.4134\n",
      "Epoch 846/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8017 - val_loss: 102.6912\n",
      "Epoch 847/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8620 - val_loss: 101.9686\n",
      "Epoch 848/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.1061 - val_loss: 101.3981\n",
      "Epoch 849/2300\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 87.2935 - val_loss: 101.0890\n",
      "Epoch 850/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3944 - val_loss: 101.5101\n",
      "Epoch 851/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7299 - val_loss: 103.1799\n",
      "Epoch 852/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8671 - val_loss: 102.3877\n",
      "Epoch 853/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.5976 - val_loss: 100.5627\n",
      "Epoch 854/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0618 - val_loss: 100.7754\n",
      "Epoch 855/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.7962 - val_loss: 102.0783\n",
      "Epoch 856/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5676 - val_loss: 101.2501\n",
      "Epoch 857/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5212 - val_loss: 103.0456\n",
      "Epoch 858/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4724 - val_loss: 101.2623\n",
      "Epoch 859/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.6633 - val_loss: 101.0861\n",
      "Epoch 860/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8792 - val_loss: 100.7675\n",
      "Epoch 861/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.7738 - val_loss: 103.7252\n",
      "Epoch 862/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.7755 - val_loss: 102.6544\n",
      "Epoch 863/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7583 - val_loss: 101.4702\n",
      "Epoch 864/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4709 - val_loss: 101.0326\n",
      "Epoch 865/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3657 - val_loss: 101.9922\n",
      "Epoch 866/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3956 - val_loss: 101.6406\n",
      "Epoch 867/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7368 - val_loss: 101.7733\n",
      "Epoch 868/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.5889 - val_loss: 102.4009\n",
      "Epoch 869/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7466 - val_loss: 105.7912\n",
      "Epoch 870/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 88.0426 - val_loss: 107.1035\n",
      "Epoch 871/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.6297 - val_loss: 102.9738\n",
      "Epoch 872/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7239 - val_loss: 102.6723\n",
      "Epoch 873/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.4712 - val_loss: 102.0839\n",
      "Epoch 874/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.4652 - val_loss: 100.7233\n",
      "Epoch 875/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.3559 - val_loss: 101.0995\n",
      "Epoch 876/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0599 - val_loss: 102.1520\n",
      "Epoch 877/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2760 - val_loss: 103.1017\n",
      "Epoch 878/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.7017 - val_loss: 101.1107\n",
      "Epoch 879/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8296 - val_loss: 101.4271\n",
      "Epoch 880/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4932 - val_loss: 100.9070\n",
      "Epoch 881/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7852 - val_loss: 101.9622\n",
      "Epoch 882/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4863 - val_loss: 101.1321\n",
      "Epoch 883/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.9592 - val_loss: 102.8460\n",
      "Epoch 884/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 87.1932 - val_loss: 101.3239\n",
      "Epoch 885/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.7986 - val_loss: 103.4480\n",
      "Epoch 886/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4487 - val_loss: 103.6969\n",
      "Epoch 887/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6309 - val_loss: 101.2890\n",
      "Epoch 888/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 88.0617 - val_loss: 102.5358\n",
      "Epoch 889/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.8117 - val_loss: 101.9733\n",
      "Epoch 890/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4941 - val_loss: 101.1930\n",
      "Epoch 891/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.9408 - val_loss: 102.5001\n",
      "Epoch 892/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.4083 - val_loss: 101.2393\n",
      "Epoch 893/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 87.7917 - val_loss: 101.3682\n",
      "Epoch 894/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.4919 - val_loss: 101.4946\n",
      "Epoch 895/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.4349 - val_loss: 101.6604\n",
      "Epoch 896/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.3591 - val_loss: 101.4999\n",
      "Epoch 897/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4181 - val_loss: 103.0057\n",
      "Epoch 898/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4608 - val_loss: 101.1077\n",
      "Epoch 899/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3024 - val_loss: 101.2507\n",
      "Epoch 900/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.6464 - val_loss: 101.8266\n",
      "Epoch 901/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4828 - val_loss: 101.4068\n",
      "Epoch 902/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.8437 - val_loss: 103.2777\n",
      "Epoch 903/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2277 - val_loss: 102.0846\n",
      "Epoch 904/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3678 - val_loss: 101.5352\n",
      "Epoch 905/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.7519 - val_loss: 101.4725\n",
      "Epoch 906/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4139 - val_loss: 101.7332\n",
      "Epoch 907/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2839 - val_loss: 104.8009\n",
      "Epoch 908/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.8615 - val_loss: 105.7046\n",
      "Epoch 909/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1382 - val_loss: 101.3391\n",
      "Epoch 910/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.8270 - val_loss: 100.4062\n",
      "Epoch 911/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.2173 - val_loss: 103.1289\n",
      "Epoch 912/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.2556 - val_loss: 101.9568\n",
      "Epoch 913/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.2751 - val_loss: 106.9545\n",
      "Epoch 914/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8028 - val_loss: 103.4572\n",
      "Epoch 915/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.3824 - val_loss: 103.2470\n",
      "Epoch 916/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.6989 - val_loss: 101.8285\n",
      "Epoch 917/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.1262 - val_loss: 102.5853\n",
      "Epoch 918/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0809 - val_loss: 102.5509\n",
      "Epoch 919/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 88.1271 - val_loss: 102.1634\n",
      "Epoch 920/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.4642 - val_loss: 101.7181\n",
      "Epoch 921/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.5232 - val_loss: 103.6905\n",
      "Epoch 922/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7100 - val_loss: 101.9290\n",
      "Epoch 923/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5731 - val_loss: 102.6928\n",
      "Epoch 924/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2116 - val_loss: 102.8465\n",
      "Epoch 925/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.2529 - val_loss: 101.4641\n",
      "Epoch 926/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3615 - val_loss: 102.6308\n",
      "Epoch 927/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3744 - val_loss: 101.2532\n",
      "Epoch 928/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4810 - val_loss: 101.9691\n",
      "Epoch 929/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2771 - val_loss: 102.8808\n",
      "Epoch 930/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3399 - val_loss: 102.4050\n",
      "Epoch 931/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4727 - val_loss: 101.4769\n",
      "Epoch 932/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.6563 - val_loss: 102.2753\n",
      "Epoch 933/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.6126 - val_loss: 101.8103\n",
      "Epoch 934/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.1802 - val_loss: 101.9931\n",
      "Epoch 935/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.4925 - val_loss: 103.0819\n",
      "Epoch 936/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 88.0133 - val_loss: 102.3348\n",
      "Epoch 937/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 87.4553 - val_loss: 102.1480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 87.1464 - val_loss: 101.7166\n",
      "Epoch 939/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.2529 - val_loss: 101.7065\n",
      "Epoch 940/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6131 - val_loss: 102.8916\n",
      "Epoch 941/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4579 - val_loss: 106.2962\n",
      "Epoch 942/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.3350 - val_loss: 102.5426\n",
      "Epoch 943/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.6120 - val_loss: 101.6334\n",
      "Epoch 944/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3521 - val_loss: 101.9647\n",
      "Epoch 945/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4528 - val_loss: 102.3174\n",
      "Epoch 946/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7238 - val_loss: 102.6948\n",
      "Epoch 947/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5322 - val_loss: 103.7606\n",
      "Epoch 948/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0223 - val_loss: 102.9699\n",
      "Epoch 949/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.8853 - val_loss: 102.2276\n",
      "Epoch 950/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2737 - val_loss: 101.2418\n",
      "Epoch 951/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.5268 - val_loss: 101.8898\n",
      "Epoch 952/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1971 - val_loss: 103.2506\n",
      "Epoch 953/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.1519 - val_loss: 102.8022\n",
      "Epoch 954/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.6650 - val_loss: 103.1531\n",
      "Epoch 955/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2569 - val_loss: 101.7412\n",
      "Epoch 956/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.3793 - val_loss: 102.3986\n",
      "Epoch 957/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.0822 - val_loss: 102.1971\n",
      "Epoch 958/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.5880 - val_loss: 101.5665\n",
      "Epoch 959/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.3789 - val_loss: 102.5460\n",
      "Epoch 960/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4376 - val_loss: 102.7700\n",
      "Epoch 961/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1430 - val_loss: 102.8337\n",
      "Epoch 962/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9156 - val_loss: 102.4663\n",
      "Epoch 963/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5040 - val_loss: 103.0744\n",
      "Epoch 964/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.4163 - val_loss: 102.7136\n",
      "Epoch 965/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.7367 - val_loss: 101.9226\n",
      "Epoch 966/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.4111 - val_loss: 106.2930\n",
      "Epoch 967/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4034 - val_loss: 102.1182\n",
      "Epoch 968/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.4113 - val_loss: 102.1659\n",
      "Epoch 969/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.5745 - val_loss: 102.8973\n",
      "Epoch 970/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.0296 - val_loss: 103.7917\n",
      "Epoch 971/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.6757 - val_loss: 101.8117\n",
      "Epoch 972/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2193 - val_loss: 102.1584\n",
      "Epoch 973/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.3841 - val_loss: 103.6084\n",
      "Epoch 974/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.9272 - val_loss: 103.3333\n",
      "Epoch 975/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8631 - val_loss: 101.4930\n",
      "Epoch 976/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8526 - val_loss: 102.3914\n",
      "Epoch 977/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.8535 - val_loss: 104.3455\n",
      "Epoch 978/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3286 - val_loss: 102.0399\n",
      "Epoch 979/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0745 - val_loss: 101.6562\n",
      "Epoch 980/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4170 - val_loss: 103.6528\n",
      "Epoch 981/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.3096 - val_loss: 101.9269\n",
      "Epoch 982/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 87.3202 - val_loss: 102.1279\n",
      "Epoch 983/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.4598 - val_loss: 102.2499\n",
      "Epoch 984/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 87.0750 - val_loss: 101.4497\n",
      "Epoch 985/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.9414 - val_loss: 102.2652\n",
      "Epoch 986/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.3249 - val_loss: 106.8536\n",
      "Epoch 987/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.2610 - val_loss: 105.0800\n",
      "Epoch 988/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.1881 - val_loss: 103.8987\n",
      "Epoch 989/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.5461 - val_loss: 104.5447\n",
      "Epoch 990/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.6802 - val_loss: 103.4166\n",
      "Epoch 991/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.0519 - val_loss: 102.4540\n",
      "Epoch 992/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4097 - val_loss: 103.6738\n",
      "Epoch 993/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1802 - val_loss: 102.4366\n",
      "Epoch 994/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.2426 - val_loss: 102.9376\n",
      "Epoch 995/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 87.3215 - val_loss: 103.6095\n",
      "Epoch 996/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.2495 - val_loss: 103.3232\n",
      "Epoch 997/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.3799 - val_loss: 103.5104\n",
      "Epoch 998/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.4000 - val_loss: 103.4425\n",
      "Epoch 999/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1589 - val_loss: 103.7628\n",
      "Epoch 1000/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5207 - val_loss: 104.4115\n",
      "Epoch 1001/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2691 - val_loss: 102.0000\n",
      "Epoch 1002/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2837 - val_loss: 109.8308\n",
      "Epoch 1003/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2386 - val_loss: 102.6500\n",
      "Epoch 1004/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0846 - val_loss: 106.0504\n",
      "Epoch 1005/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7633 - val_loss: 101.8266\n",
      "Epoch 1006/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0252 - val_loss: 109.1016\n",
      "Epoch 1007/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2425 - val_loss: 104.1505\n",
      "Epoch 1008/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9866 - val_loss: 104.5262\n",
      "Epoch 1009/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3685 - val_loss: 105.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1010/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2603 - val_loss: 103.4808\n",
      "Epoch 1011/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.5892 - val_loss: 102.7314\n",
      "Epoch 1012/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3507 - val_loss: 103.7047\n",
      "Epoch 1013/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0741 - val_loss: 103.3212\n",
      "Epoch 1014/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2198 - val_loss: 105.1645\n",
      "Epoch 1015/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1126 - val_loss: 103.2503\n",
      "Epoch 1016/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5006 - val_loss: 103.1610\n",
      "Epoch 1017/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3863 - val_loss: 102.3005\n",
      "Epoch 1018/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2607 - val_loss: 102.8274\n",
      "Epoch 1019/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.6835 - val_loss: 102.7263\n",
      "Epoch 1020/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1626 - val_loss: 106.5107\n",
      "Epoch 1021/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2505 - val_loss: 102.8343\n",
      "Epoch 1022/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2552 - val_loss: 104.3859\n",
      "Epoch 1023/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0022 - val_loss: 102.7314\n",
      "Epoch 1024/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2268 - val_loss: 102.9273\n",
      "Epoch 1025/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2516 - val_loss: 104.3040\n",
      "Epoch 1026/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.1255 - val_loss: 103.0839\n",
      "Epoch 1027/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.3021 - val_loss: 102.9702\n",
      "Epoch 1028/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0981 - val_loss: 103.7322\n",
      "Epoch 1029/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.7649 - val_loss: 102.9759\n",
      "Epoch 1030/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.7413 - val_loss: 104.0852\n",
      "Epoch 1031/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8920 - val_loss: 103.1414\n",
      "Epoch 1032/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4171 - val_loss: 103.3326\n",
      "Epoch 1033/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.5121 - val_loss: 103.2074\n",
      "Epoch 1034/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1620 - val_loss: 103.5172\n",
      "Epoch 1035/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7967 - val_loss: 102.2172\n",
      "Epoch 1036/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.0045 - val_loss: 102.6044\n",
      "Epoch 1037/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.2170 - val_loss: 104.7055\n",
      "Epoch 1038/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.1655 - val_loss: 102.0491\n",
      "Epoch 1039/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9921 - val_loss: 103.2894\n",
      "Epoch 1040/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.9387 - val_loss: 103.1630\n",
      "Epoch 1041/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.0842 - val_loss: 102.7252\n",
      "Epoch 1042/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2705 - val_loss: 103.4826\n",
      "Epoch 1043/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0400 - val_loss: 104.9133\n",
      "Epoch 1044/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1486 - val_loss: 103.1951\n",
      "Epoch 1045/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2165 - val_loss: 102.9619\n",
      "Epoch 1046/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9272 - val_loss: 102.5362\n",
      "Epoch 1047/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2774 - val_loss: 103.5184\n",
      "Epoch 1048/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0535 - val_loss: 102.8016\n",
      "Epoch 1049/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9309 - val_loss: 103.3235\n",
      "Epoch 1050/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.5824 - val_loss: 102.2431\n",
      "Epoch 1051/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.3688 - val_loss: 103.4785\n",
      "Epoch 1052/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0289 - val_loss: 103.6148\n",
      "Epoch 1053/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4803 - val_loss: 105.2446\n",
      "Epoch 1054/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.4105 - val_loss: 105.9150\n",
      "Epoch 1055/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0937 - val_loss: 104.1943\n",
      "Epoch 1056/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9992 - val_loss: 102.5098\n",
      "Epoch 1057/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.3572 - val_loss: 103.3987\n",
      "Epoch 1058/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2402 - val_loss: 102.9661\n",
      "Epoch 1059/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8925 - val_loss: 102.8440\n",
      "Epoch 1060/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0852 - val_loss: 104.6348\n",
      "Epoch 1061/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1968 - val_loss: 102.5268\n",
      "Epoch 1062/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.1312 - val_loss: 102.2246\n",
      "Epoch 1063/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.9410 - val_loss: 102.5074\n",
      "Epoch 1064/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.9947 - val_loss: 104.5105\n",
      "Epoch 1065/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1385 - val_loss: 103.2301\n",
      "Epoch 1066/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 86.8232 - val_loss: 103.2038\n",
      "Epoch 1067/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.5502 - val_loss: 102.9962\n",
      "Epoch 1068/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9850 - val_loss: 109.6718\n",
      "Epoch 1069/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.1074 - val_loss: 104.5820\n",
      "Epoch 1070/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.2141 - val_loss: 105.3048\n",
      "Epoch 1071/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.5198 - val_loss: 104.9028\n",
      "Epoch 1072/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.3845 - val_loss: 103.4342\n",
      "Epoch 1073/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.1606 - val_loss: 104.5331\n",
      "Epoch 1074/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.0336 - val_loss: 103.0764\n",
      "Epoch 1075/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.0503 - val_loss: 103.4577\n",
      "Epoch 1076/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.1921 - val_loss: 103.4066\n",
      "Epoch 1077/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9291 - val_loss: 106.4660\n",
      "Epoch 1078/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9181 - val_loss: 103.3326\n",
      "Epoch 1079/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.8136 - val_loss: 102.3150\n",
      "Epoch 1080/2300\n",
      "17948/17948 [==============================] - 1s 46us/sample - loss: 87.4863 - val_loss: 108.0675\n",
      "Epoch 1081/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 56us/sample - loss: 86.9346 - val_loss: 103.2631\n",
      "Epoch 1082/2300\n",
      "17948/17948 [==============================] - 1s 50us/sample - loss: 86.6761 - val_loss: 102.7027\n",
      "Epoch 1083/2300\n",
      "17948/17948 [==============================] - 1s 51us/sample - loss: 86.8853 - val_loss: 103.6491\n",
      "Epoch 1084/2300\n",
      "17948/17948 [==============================] - 1s 46us/sample - loss: 87.1252 - val_loss: 103.7998\n",
      "Epoch 1085/2300\n",
      "17948/17948 [==============================] - 1s 45us/sample - loss: 86.9183 - val_loss: 104.4056\n",
      "Epoch 1086/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9939 - val_loss: 106.3497\n",
      "Epoch 1087/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1010 - val_loss: 104.1370\n",
      "Epoch 1088/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0976 - val_loss: 102.8932\n",
      "Epoch 1089/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0152 - val_loss: 102.8998\n",
      "Epoch 1090/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0553 - val_loss: 102.9857\n",
      "Epoch 1091/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3561 - val_loss: 102.6745\n",
      "Epoch 1092/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6744 - val_loss: 107.1710\n",
      "Epoch 1093/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 88.2993 - val_loss: 104.5443\n",
      "Epoch 1094/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2076 - val_loss: 101.9322\n",
      "Epoch 1095/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1107 - val_loss: 105.7825\n",
      "Epoch 1096/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1170 - val_loss: 104.2055\n",
      "Epoch 1097/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.6542 - val_loss: 104.2204\n",
      "Epoch 1098/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9311 - val_loss: 104.4885\n",
      "Epoch 1099/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7228 - val_loss: 105.0045\n",
      "Epoch 1100/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8618 - val_loss: 103.5134\n",
      "Epoch 1101/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0642 - val_loss: 105.2463\n",
      "Epoch 1102/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.3152 - val_loss: 103.5494\n",
      "Epoch 1103/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2133 - val_loss: 103.8585\n",
      "Epoch 1104/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6261 - val_loss: 103.1574\n",
      "Epoch 1105/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9907 - val_loss: 102.1315\n",
      "Epoch 1106/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0126 - val_loss: 102.6191\n",
      "Epoch 1107/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0185 - val_loss: 102.7026\n",
      "Epoch 1108/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7710 - val_loss: 103.3647\n",
      "Epoch 1109/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.4938 - val_loss: 102.6543\n",
      "Epoch 1110/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8190 - val_loss: 102.8132\n",
      "Epoch 1111/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6707 - val_loss: 103.3613\n",
      "Epoch 1112/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6913 - val_loss: 107.3340\n",
      "Epoch 1113/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1438 - val_loss: 103.0377\n",
      "Epoch 1114/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8960 - val_loss: 104.6166\n",
      "Epoch 1115/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0507 - val_loss: 104.7090\n",
      "Epoch 1116/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2131 - val_loss: 102.7217\n",
      "Epoch 1117/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.5558 - val_loss: 104.5311\n",
      "Epoch 1118/2300\n",
      "17948/17948 [==============================] - 1s 54us/sample - loss: 86.6279 - val_loss: 103.6100\n",
      "Epoch 1119/2300\n",
      "17948/17948 [==============================] - 1s 56us/sample - loss: 86.7885 - val_loss: 103.2511\n",
      "Epoch 1120/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.9279 - val_loss: 102.6062\n",
      "Epoch 1121/2300\n",
      "17948/17948 [==============================] - 1s 51us/sample - loss: 86.7379 - val_loss: 105.9735\n",
      "Epoch 1122/2300\n",
      "17948/17948 [==============================] - 1s 52us/sample - loss: 86.6202 - val_loss: 103.4756\n",
      "Epoch 1123/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.0491 - val_loss: 103.0487\n",
      "Epoch 1124/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9024 - val_loss: 103.5874\n",
      "Epoch 1125/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.8363 - val_loss: 104.0664\n",
      "Epoch 1126/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.6459 - val_loss: 104.8045\n",
      "Epoch 1127/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.6806 - val_loss: 104.2938\n",
      "Epoch 1128/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.9194 - val_loss: 103.8383\n",
      "Epoch 1129/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 87.0468 - val_loss: 102.9721\n",
      "Epoch 1130/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9029 - val_loss: 102.8839\n",
      "Epoch 1131/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.7742 - val_loss: 103.3748\n",
      "Epoch 1132/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9912 - val_loss: 103.8499\n",
      "Epoch 1133/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2944 - val_loss: 105.7698\n",
      "Epoch 1134/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0256 - val_loss: 103.7426\n",
      "Epoch 1135/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.9842 - val_loss: 106.0857\n",
      "Epoch 1136/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.1076 - val_loss: 103.0474\n",
      "Epoch 1137/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5095 - val_loss: 105.2853\n",
      "Epoch 1138/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1050 - val_loss: 103.0950\n",
      "Epoch 1139/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9095 - val_loss: 104.6493\n",
      "Epoch 1140/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.6295 - val_loss: 104.9133\n",
      "Epoch 1141/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.7002 - val_loss: 102.7514\n",
      "Epoch 1142/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.4987 - val_loss: 106.7689\n",
      "Epoch 1143/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.8784 - val_loss: 105.0010\n",
      "Epoch 1144/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.2498 - val_loss: 103.1525\n",
      "Epoch 1145/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 87.0206 - val_loss: 103.3203\n",
      "Epoch 1146/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.7436 - val_loss: 102.8663\n",
      "Epoch 1147/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 87.2586 - val_loss: 103.2068\n",
      "Epoch 1148/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.6413 - val_loss: 104.1737\n",
      "Epoch 1149/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.5501 - val_loss: 102.9368\n",
      "Epoch 1150/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8636 - val_loss: 106.2666\n",
      "Epoch 1151/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7456 - val_loss: 103.6993\n",
      "Epoch 1152/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1256 - val_loss: 104.0682\n",
      "Epoch 1153/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7581 - val_loss: 102.7279\n",
      "Epoch 1154/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7070 - val_loss: 103.5992\n",
      "Epoch 1155/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1146 - val_loss: 103.8797\n",
      "Epoch 1156/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8564 - val_loss: 104.5759\n",
      "Epoch 1157/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1227 - val_loss: 110.3161\n",
      "Epoch 1158/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5495 - val_loss: 103.3616\n",
      "Epoch 1159/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7861 - val_loss: 103.3737\n",
      "Epoch 1160/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9404 - val_loss: 103.3105\n",
      "Epoch 1161/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.0601 - val_loss: 105.7337\n",
      "Epoch 1162/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7514 - val_loss: 103.8263\n",
      "Epoch 1163/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5666 - val_loss: 103.4477\n",
      "Epoch 1164/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9297 - val_loss: 104.7436\n",
      "Epoch 1165/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5712 - val_loss: 104.0652\n",
      "Epoch 1166/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8057 - val_loss: 104.5868\n",
      "Epoch 1167/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.5505 - val_loss: 105.4120\n",
      "Epoch 1168/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3424 - val_loss: 102.5256\n",
      "Epoch 1169/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.6387 - val_loss: 104.4415\n",
      "Epoch 1170/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.9097 - val_loss: 104.3445\n",
      "Epoch 1171/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.2559 - val_loss: 105.6975\n",
      "Epoch 1172/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0541 - val_loss: 104.1551\n",
      "Epoch 1173/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8001 - val_loss: 107.0899\n",
      "Epoch 1174/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6958 - val_loss: 103.4802\n",
      "Epoch 1175/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6039 - val_loss: 103.4173\n",
      "Epoch 1176/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6534 - val_loss: 104.6743\n",
      "Epoch 1177/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.1192 - val_loss: 104.4904\n",
      "Epoch 1178/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.8484 - val_loss: 103.9681\n",
      "Epoch 1179/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.5665 - val_loss: 104.0455\n",
      "Epoch 1180/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.5583 - val_loss: 104.1949\n",
      "Epoch 1181/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.7217 - val_loss: 106.1310\n",
      "Epoch 1182/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.0917 - val_loss: 103.2390\n",
      "Epoch 1183/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.9403 - val_loss: 102.4978\n",
      "Epoch 1184/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.1202 - val_loss: 104.6873\n",
      "Epoch 1185/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5986 - val_loss: 109.3523\n",
      "Epoch 1186/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0958 - val_loss: 104.1945\n",
      "Epoch 1187/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4884 - val_loss: 106.2797\n",
      "Epoch 1188/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0153 - val_loss: 107.4108\n",
      "Epoch 1189/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.7204 - val_loss: 105.7744\n",
      "Epoch 1190/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.8696 - val_loss: 104.5547\n",
      "Epoch 1191/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.8296 - val_loss: 107.0676\n",
      "Epoch 1192/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9611 - val_loss: 103.9877\n",
      "Epoch 1193/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.4691 - val_loss: 105.4519\n",
      "Epoch 1194/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4032 - val_loss: 104.9062\n",
      "Epoch 1195/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5475 - val_loss: 103.4804\n",
      "Epoch 1196/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 87.1925 - val_loss: 104.7015\n",
      "Epoch 1197/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9707 - val_loss: 104.7440\n",
      "Epoch 1198/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2460 - val_loss: 103.3871\n",
      "Epoch 1199/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8429 - val_loss: 104.7787\n",
      "Epoch 1200/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5133 - val_loss: 104.4133\n",
      "Epoch 1201/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6227 - val_loss: 103.5491\n",
      "Epoch 1202/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8407 - val_loss: 107.8910\n",
      "Epoch 1203/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.7129 - val_loss: 105.6621\n",
      "Epoch 1204/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 86.5387 - val_loss: 105.2859\n",
      "Epoch 1205/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.8552 - val_loss: 105.7043\n",
      "Epoch 1206/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.9156 - val_loss: 104.6445\n",
      "Epoch 1207/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.5276 - val_loss: 104.5050\n",
      "Epoch 1208/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.9179 - val_loss: 106.1299\n",
      "Epoch 1209/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5308 - val_loss: 104.2429\n",
      "Epoch 1210/2300\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 86.8776 - val_loss: 102.9248\n",
      "Epoch 1211/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.6134 - val_loss: 104.7182\n",
      "Epoch 1212/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7652 - val_loss: 103.8974\n",
      "Epoch 1213/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6313 - val_loss: 105.6705\n",
      "Epoch 1214/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 87.0735 - val_loss: 103.1901\n",
      "Epoch 1215/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6290 - val_loss: 104.7903\n",
      "Epoch 1216/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.8701 - val_loss: 104.5480\n",
      "Epoch 1217/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.7988 - val_loss: 103.9590\n",
      "Epoch 1218/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6751 - val_loss: 104.6203\n",
      "Epoch 1219/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6294 - val_loss: 104.1401\n",
      "Epoch 1220/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.4861 - val_loss: 105.1750\n",
      "Epoch 1221/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.5564 - val_loss: 104.0314\n",
      "Epoch 1222/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7833 - val_loss: 106.8804\n",
      "Epoch 1223/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5257 - val_loss: 103.5059\n",
      "Epoch 1224/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5461 - val_loss: 105.2322\n",
      "Epoch 1225/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0895 - val_loss: 106.0318\n",
      "Epoch 1226/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9177 - val_loss: 103.7576\n",
      "Epoch 1227/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7815 - val_loss: 104.1261\n",
      "Epoch 1228/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6258 - val_loss: 105.8587\n",
      "Epoch 1229/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3717 - val_loss: 103.4283\n",
      "Epoch 1230/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4187 - val_loss: 104.4394\n",
      "Epoch 1231/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3969 - val_loss: 106.5937\n",
      "Epoch 1232/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.5464 - val_loss: 104.5276\n",
      "Epoch 1233/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.7447 - val_loss: 104.8374\n",
      "Epoch 1234/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.7343 - val_loss: 104.4336\n",
      "Epoch 1235/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2754 - val_loss: 103.8200\n",
      "Epoch 1236/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.3919 - val_loss: 105.1904\n",
      "Epoch 1237/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 87.0693 - val_loss: 104.3266\n",
      "Epoch 1238/2300\n",
      "17948/17948 [==============================] - 1s 42us/sample - loss: 86.9175 - val_loss: 105.7095\n",
      "Epoch 1239/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.2944 - val_loss: 105.4097\n",
      "Epoch 1240/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.7335 - val_loss: 105.2261\n",
      "Epoch 1241/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.4022 - val_loss: 105.8640\n",
      "Epoch 1242/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6368 - val_loss: 105.0783\n",
      "Epoch 1243/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3801 - val_loss: 104.3256\n",
      "Epoch 1244/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.0097 - val_loss: 107.2181\n",
      "Epoch 1245/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.7978 - val_loss: 104.8957\n",
      "Epoch 1246/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5855 - val_loss: 104.7671\n",
      "Epoch 1247/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5512 - val_loss: 104.9646\n",
      "Epoch 1248/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1998 - val_loss: 104.5884\n",
      "Epoch 1249/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7559 - val_loss: 106.9482\n",
      "Epoch 1250/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.8563 - val_loss: 105.9363\n",
      "Epoch 1251/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7041 - val_loss: 105.0172\n",
      "Epoch 1252/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7035 - val_loss: 105.0457\n",
      "Epoch 1253/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7730 - val_loss: 105.5518\n",
      "Epoch 1254/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4893 - val_loss: 103.4583\n",
      "Epoch 1255/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.8249 - val_loss: 105.2210\n",
      "Epoch 1256/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 86.6414 - val_loss: 106.9401\n",
      "Epoch 1257/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7603 - val_loss: 107.2012\n",
      "Epoch 1258/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4744 - val_loss: 104.0466\n",
      "Epoch 1259/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8261 - val_loss: 105.0481\n",
      "Epoch 1260/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7439 - val_loss: 105.1684\n",
      "Epoch 1261/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.2991 - val_loss: 103.8027\n",
      "Epoch 1262/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.4351 - val_loss: 103.6637\n",
      "Epoch 1263/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.8852 - val_loss: 106.4961\n",
      "Epoch 1264/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0041 - val_loss: 104.6555\n",
      "Epoch 1265/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5479 - val_loss: 104.4472\n",
      "Epoch 1266/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2320 - val_loss: 104.7971\n",
      "Epoch 1267/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.8211 - val_loss: 104.1178\n",
      "Epoch 1268/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 87.0939 - val_loss: 105.0490\n",
      "Epoch 1269/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.9429 - val_loss: 103.5597\n",
      "Epoch 1270/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.4430 - val_loss: 105.4850\n",
      "Epoch 1271/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.4784 - val_loss: 105.7778\n",
      "Epoch 1272/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4417 - val_loss: 104.0979\n",
      "Epoch 1273/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8053 - val_loss: 105.4692\n",
      "Epoch 1274/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2873 - val_loss: 106.4764\n",
      "Epoch 1275/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 87.2321 - val_loss: 104.1084\n",
      "Epoch 1276/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3566 - val_loss: 105.7582\n",
      "Epoch 1277/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.4384 - val_loss: 109.1241\n",
      "Epoch 1278/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7036 - val_loss: 107.1493\n",
      "Epoch 1279/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.8013 - val_loss: 105.3261\n",
      "Epoch 1280/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8320 - val_loss: 106.5970\n",
      "Epoch 1281/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6465 - val_loss: 104.8118\n",
      "Epoch 1282/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.6330 - val_loss: 104.3723\n",
      "Epoch 1283/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.1671 - val_loss: 103.3776\n",
      "Epoch 1284/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1659 - val_loss: 105.5319\n",
      "Epoch 1285/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4860 - val_loss: 106.2919\n",
      "Epoch 1286/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.2209 - val_loss: 105.1741\n",
      "Epoch 1287/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4297 - val_loss: 106.0113\n",
      "Epoch 1288/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.4521 - val_loss: 105.8627\n",
      "Epoch 1289/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5502 - val_loss: 105.1234\n",
      "Epoch 1290/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5977 - val_loss: 108.0245\n",
      "Epoch 1291/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6848 - val_loss: 106.1837\n",
      "Epoch 1292/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1533 - val_loss: 104.4366\n",
      "Epoch 1293/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4715 - val_loss: 105.1016\n",
      "Epoch 1294/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6592 - val_loss: 107.0857\n",
      "Epoch 1295/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.7769 - val_loss: 104.9780\n",
      "Epoch 1296/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3085 - val_loss: 104.5848\n",
      "Epoch 1297/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0473 - val_loss: 103.8004\n",
      "Epoch 1298/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5103 - val_loss: 104.5760\n",
      "Epoch 1299/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4034 - val_loss: 106.9333\n",
      "Epoch 1300/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.7116 - val_loss: 107.1009\n",
      "Epoch 1301/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3300 - val_loss: 106.7332\n",
      "Epoch 1302/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7980 - val_loss: 103.4766\n",
      "Epoch 1303/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5314 - val_loss: 104.1510\n",
      "Epoch 1304/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2255 - val_loss: 105.6312\n",
      "Epoch 1305/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1551 - val_loss: 108.8003\n",
      "Epoch 1306/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4960 - val_loss: 104.6058\n",
      "Epoch 1307/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.6672 - val_loss: 104.0028\n",
      "Epoch 1308/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7473 - val_loss: 105.0930\n",
      "Epoch 1309/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.2466 - val_loss: 110.7495\n",
      "Epoch 1310/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7266 - val_loss: 103.6919\n",
      "Epoch 1311/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5383 - val_loss: 104.5574\n",
      "Epoch 1312/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.3151 - val_loss: 104.2196\n",
      "Epoch 1313/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4988 - val_loss: 104.7079\n",
      "Epoch 1314/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9828 - val_loss: 104.7479\n",
      "Epoch 1315/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0390 - val_loss: 104.3878\n",
      "Epoch 1316/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.9402 - val_loss: 104.6019\n",
      "Epoch 1317/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.6527 - val_loss: 105.1372\n",
      "Epoch 1318/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.1875 - val_loss: 105.1178\n",
      "Epoch 1319/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2767 - val_loss: 106.4941\n",
      "Epoch 1320/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3716 - val_loss: 106.6693\n",
      "Epoch 1321/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3059 - val_loss: 106.8535\n",
      "Epoch 1322/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6066 - val_loss: 107.2076\n",
      "Epoch 1323/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5172 - val_loss: 105.5038\n",
      "Epoch 1324/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4845 - val_loss: 106.6221\n",
      "Epoch 1325/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5616 - val_loss: 104.4899\n",
      "Epoch 1326/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4524 - val_loss: 105.8358\n",
      "Epoch 1327/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9680 - val_loss: 104.6873\n",
      "Epoch 1328/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5226 - val_loss: 108.4532\n",
      "Epoch 1329/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.4375 - val_loss: 105.0477\n",
      "Epoch 1330/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.5068 - val_loss: 105.6601\n",
      "Epoch 1331/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8595 - val_loss: 104.9184\n",
      "Epoch 1332/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.2368 - val_loss: 104.6041\n",
      "Epoch 1333/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1637 - val_loss: 105.0869\n",
      "Epoch 1334/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.1500 - val_loss: 105.1784\n",
      "Epoch 1335/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3794 - val_loss: 106.6800\n",
      "Epoch 1336/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1810 - val_loss: 107.4496\n",
      "Epoch 1337/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2853 - val_loss: 104.6475\n",
      "Epoch 1338/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.1924 - val_loss: 104.4925\n",
      "Epoch 1339/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.8866 - val_loss: 106.1309\n",
      "Epoch 1340/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2561 - val_loss: 104.9971\n",
      "Epoch 1341/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.4481 - val_loss: 110.1083\n",
      "Epoch 1342/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.2881 - val_loss: 105.3341\n",
      "Epoch 1343/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2249 - val_loss: 106.7144\n",
      "Epoch 1344/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.7011 - val_loss: 104.8979\n",
      "Epoch 1345/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2736 - val_loss: 105.7230\n",
      "Epoch 1346/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5600 - val_loss: 104.8200\n",
      "Epoch 1347/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.5696 - val_loss: 112.1385\n",
      "Epoch 1348/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3640 - val_loss: 108.3214\n",
      "Epoch 1349/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2440 - val_loss: 106.3460\n",
      "Epoch 1350/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.2065 - val_loss: 107.0427\n",
      "Epoch 1351/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1491 - val_loss: 105.5796\n",
      "Epoch 1352/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2910 - val_loss: 105.5970\n",
      "Epoch 1353/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5201 - val_loss: 104.7135\n",
      "Epoch 1354/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.7262 - val_loss: 106.1182\n",
      "Epoch 1355/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4753 - val_loss: 105.4205\n",
      "Epoch 1356/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3677 - val_loss: 105.4013\n",
      "Epoch 1357/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3313 - val_loss: 105.6759\n",
      "Epoch 1358/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.5642 - val_loss: 109.5599\n",
      "Epoch 1359/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4743 - val_loss: 106.7230\n",
      "Epoch 1360/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.1182 - val_loss: 104.6460\n",
      "Epoch 1361/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0150 - val_loss: 105.3931\n",
      "Epoch 1362/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4177 - val_loss: 105.0761\n",
      "Epoch 1363/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.2649 - val_loss: 109.2563\n",
      "Epoch 1364/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.7747 - val_loss: 104.9634\n",
      "Epoch 1365/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.3503 - val_loss: 105.7800\n",
      "Epoch 1366/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.8430 - val_loss: 104.6371\n",
      "Epoch 1367/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.1528 - val_loss: 105.1701\n",
      "Epoch 1368/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.5791 - val_loss: 106.4717\n",
      "Epoch 1369/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.8435 - val_loss: 105.5917\n",
      "Epoch 1370/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9112 - val_loss: 106.0006\n",
      "Epoch 1371/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.3493 - val_loss: 104.5498\n",
      "Epoch 1372/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.2404 - val_loss: 106.2174\n",
      "Epoch 1373/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.0347 - val_loss: 107.7194\n",
      "Epoch 1374/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5006 - val_loss: 106.1999\n",
      "Epoch 1375/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2196 - val_loss: 107.3214\n",
      "Epoch 1376/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2044 - val_loss: 106.3920\n",
      "Epoch 1377/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.4050 - val_loss: 105.8343\n",
      "Epoch 1378/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.2747 - val_loss: 104.8968\n",
      "Epoch 1379/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4299 - val_loss: 105.9054\n",
      "Epoch 1380/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.3672 - val_loss: 105.4985\n",
      "Epoch 1381/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4401 - val_loss: 106.2721\n",
      "Epoch 1382/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1347 - val_loss: 105.5566\n",
      "Epoch 1383/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0779 - val_loss: 107.1151\n",
      "Epoch 1384/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0895 - val_loss: 104.9074\n",
      "Epoch 1385/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1591 - val_loss: 104.9744\n",
      "Epoch 1386/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3265 - val_loss: 106.4050\n",
      "Epoch 1387/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3454 - val_loss: 104.2636\n",
      "Epoch 1388/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2087 - val_loss: 105.1724\n",
      "Epoch 1389/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3692 - val_loss: 104.3084\n",
      "Epoch 1390/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0926 - val_loss: 105.9069\n",
      "Epoch 1391/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0750 - val_loss: 104.3412\n",
      "Epoch 1392/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4249 - val_loss: 105.4253\n",
      "Epoch 1393/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0783 - val_loss: 105.8938\n",
      "Epoch 1394/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9651 - val_loss: 105.8628\n",
      "Epoch 1395/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3170 - val_loss: 106.1766\n",
      "Epoch 1396/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.4366 - val_loss: 108.7421\n",
      "Epoch 1397/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.2768 - val_loss: 105.9641\n",
      "Epoch 1398/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9737 - val_loss: 106.4212\n",
      "Epoch 1399/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.5013 - val_loss: 107.1764\n",
      "Epoch 1400/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4095 - val_loss: 105.2158\n",
      "Epoch 1401/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6524 - val_loss: 105.1197\n",
      "Epoch 1402/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.7528 - val_loss: 104.7564\n",
      "Epoch 1403/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1789 - val_loss: 105.1974\n",
      "Epoch 1404/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.8660 - val_loss: 105.1903\n",
      "Epoch 1405/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3211 - val_loss: 104.8778\n",
      "Epoch 1406/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.4581 - val_loss: 107.4153\n",
      "Epoch 1407/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.3198 - val_loss: 107.5109\n",
      "Epoch 1408/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.3273 - val_loss: 108.7967\n",
      "Epoch 1409/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.1045 - val_loss: 104.8842\n",
      "Epoch 1410/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1579 - val_loss: 109.8872\n",
      "Epoch 1411/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0623 - val_loss: 105.1111\n",
      "Epoch 1412/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0215 - val_loss: 108.5138\n",
      "Epoch 1413/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.7270 - val_loss: 105.9646\n",
      "Epoch 1414/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.6165 - val_loss: 105.7645\n",
      "Epoch 1415/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.0855 - val_loss: 105.7485\n",
      "Epoch 1416/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.4329 - val_loss: 105.0008\n",
      "Epoch 1417/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.0309 - val_loss: 104.5173\n",
      "Epoch 1418/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1615 - val_loss: 106.3677\n",
      "Epoch 1419/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.4549 - val_loss: 106.6206\n",
      "Epoch 1420/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0994 - val_loss: 106.8831\n",
      "Epoch 1421/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.0146 - val_loss: 105.3445\n",
      "Epoch 1422/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0332 - val_loss: 106.4106\n",
      "Epoch 1423/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.8557 - val_loss: 105.6868\n",
      "Epoch 1424/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1643 - val_loss: 106.1080\n",
      "Epoch 1425/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.0937 - val_loss: 105.1702\n",
      "Epoch 1426/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.2726 - val_loss: 106.8348\n",
      "Epoch 1427/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0418 - val_loss: 105.8625\n",
      "Epoch 1428/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0470 - val_loss: 105.6637\n",
      "Epoch 1429/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.6775 - val_loss: 108.4498\n",
      "Epoch 1430/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.2359 - val_loss: 105.8397\n",
      "Epoch 1431/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9370 - val_loss: 106.9438\n",
      "Epoch 1432/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0174 - val_loss: 106.0126\n",
      "Epoch 1433/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2587 - val_loss: 106.3362\n",
      "Epoch 1434/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.0301 - val_loss: 108.2790\n",
      "Epoch 1435/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7704 - val_loss: 106.4855\n",
      "Epoch 1436/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9715 - val_loss: 106.8520\n",
      "Epoch 1437/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.8648 - val_loss: 105.9303\n",
      "Epoch 1438/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.3068 - val_loss: 105.8312\n",
      "Epoch 1439/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.3935 - val_loss: 105.5262\n",
      "Epoch 1440/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 85.5829 - val_loss: 108.1087\n",
      "Epoch 1441/2300\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 86.2759 - val_loss: 107.0875\n",
      "Epoch 1442/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.2751 - val_loss: 107.8909\n",
      "Epoch 1443/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 86.0140 - val_loss: 105.7283\n",
      "Epoch 1444/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.3542 - val_loss: 106.0964\n",
      "Epoch 1445/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4188 - val_loss: 106.3899\n",
      "Epoch 1446/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.2467 - val_loss: 105.5292\n",
      "Epoch 1447/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9540 - val_loss: 105.2404\n",
      "Epoch 1448/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.8619 - val_loss: 105.5045\n",
      "Epoch 1449/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.0611 - val_loss: 105.8688\n",
      "Epoch 1450/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9930 - val_loss: 107.5449\n",
      "Epoch 1451/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9541 - val_loss: 105.4895\n",
      "Epoch 1452/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.0865 - val_loss: 105.8974\n",
      "Epoch 1453/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9523 - val_loss: 105.9574\n",
      "Epoch 1454/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.8192 - val_loss: 106.4509\n",
      "Epoch 1455/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.3183 - val_loss: 105.2826\n",
      "Epoch 1456/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.6644 - val_loss: 105.9947\n",
      "Epoch 1457/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.2331 - val_loss: 106.2651\n",
      "Epoch 1458/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.1401 - val_loss: 106.5137\n",
      "Epoch 1459/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.7658 - val_loss: 106.4121\n",
      "Epoch 1460/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.0564 - val_loss: 106.7631\n",
      "Epoch 1461/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.1124 - val_loss: 105.1706\n",
      "Epoch 1462/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 86.5042 - val_loss: 106.0812\n",
      "Epoch 1463/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 86.1452 - val_loss: 107.3747\n",
      "Epoch 1464/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.3038 - val_loss: 105.6741\n",
      "Epoch 1465/2300\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 86.2707 - val_loss: 105.7730\n",
      "Epoch 1466/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 85.9674 - val_loss: 106.0566\n",
      "Epoch 1467/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.8073 - val_loss: 106.3604\n",
      "Epoch 1468/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.1358 - val_loss: 108.0894\n",
      "Epoch 1469/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.7593 - val_loss: 105.1570\n",
      "Epoch 1470/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.6461 - val_loss: 107.0736\n",
      "Epoch 1471/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.1292 - val_loss: 106.1181\n",
      "Epoch 1472/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 86.1089 - val_loss: 105.8369\n",
      "Epoch 1473/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9816 - val_loss: 106.1078\n",
      "Epoch 1474/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2763 - val_loss: 106.7092\n",
      "Epoch 1475/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.9229 - val_loss: 106.2497\n",
      "Epoch 1476/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0813 - val_loss: 107.0013\n",
      "Epoch 1477/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.1182 - val_loss: 105.5522\n",
      "Epoch 1478/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.1985 - val_loss: 105.2148\n",
      "Epoch 1479/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.9826 - val_loss: 105.9068\n",
      "Epoch 1480/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0566 - val_loss: 108.6682\n",
      "Epoch 1481/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.0713 - val_loss: 106.3149\n",
      "Epoch 1482/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.8578 - val_loss: 109.1551\n",
      "Epoch 1483/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.1336 - val_loss: 105.8208\n",
      "Epoch 1484/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.1103 - val_loss: 106.3246\n",
      "Epoch 1485/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.2967 - val_loss: 110.1835\n",
      "Epoch 1486/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8921 - val_loss: 106.5934\n",
      "Epoch 1487/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.6972 - val_loss: 105.9506\n",
      "Epoch 1488/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.3360 - val_loss: 108.4762\n",
      "Epoch 1489/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6598 - val_loss: 106.0408\n",
      "Epoch 1490/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.8772 - val_loss: 108.4387\n",
      "Epoch 1491/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.9118 - val_loss: 106.0775\n",
      "Epoch 1492/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8270 - val_loss: 107.4919\n",
      "Epoch 1493/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9946 - val_loss: 106.3182\n",
      "Epoch 1494/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8544 - val_loss: 107.1049\n",
      "Epoch 1495/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1219 - val_loss: 105.7693\n",
      "Epoch 1496/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6868 - val_loss: 106.7431\n",
      "Epoch 1497/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7423 - val_loss: 106.2961\n",
      "Epoch 1498/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1613 - val_loss: 106.0049\n",
      "Epoch 1499/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5379 - val_loss: 106.0257\n",
      "Epoch 1500/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 86.1896 - val_loss: 107.0582\n",
      "Epoch 1501/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.3412 - val_loss: 107.1636\n",
      "Epoch 1502/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0638 - val_loss: 107.7635\n",
      "Epoch 1503/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.2694 - val_loss: 107.0240\n",
      "Epoch 1504/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7375 - val_loss: 107.9654\n",
      "Epoch 1505/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9332 - val_loss: 106.3986\n",
      "Epoch 1506/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8517 - val_loss: 106.7686\n",
      "Epoch 1507/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.3128 - val_loss: 105.8224\n",
      "Epoch 1508/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.3083 - val_loss: 110.2693\n",
      "Epoch 1509/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 85.8076 - val_loss: 106.5206\n",
      "Epoch 1510/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.6113 - val_loss: 107.2343\n",
      "Epoch 1511/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.0382 - val_loss: 107.2426\n",
      "Epoch 1512/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2419 - val_loss: 105.3045\n",
      "Epoch 1513/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.9432 - val_loss: 108.5681\n",
      "Epoch 1514/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9287 - val_loss: 106.7855\n",
      "Epoch 1515/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6865 - val_loss: 108.5744\n",
      "Epoch 1516/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7971 - val_loss: 106.1846\n",
      "Epoch 1517/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7251 - val_loss: 106.3160\n",
      "Epoch 1518/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9477 - val_loss: 107.8249\n",
      "Epoch 1519/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8891 - val_loss: 107.7761\n",
      "Epoch 1520/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9379 - val_loss: 106.8743\n",
      "Epoch 1521/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0399 - val_loss: 106.6837\n",
      "Epoch 1522/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.3018 - val_loss: 105.4823\n",
      "Epoch 1523/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7455 - val_loss: 107.4712\n",
      "Epoch 1524/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.7680 - val_loss: 107.4200\n",
      "Epoch 1525/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.0545 - val_loss: 106.5752\n",
      "Epoch 1526/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 85.6877 - val_loss: 108.8488\n",
      "Epoch 1527/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 86.1971 - val_loss: 109.7702\n",
      "Epoch 1528/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.7406 - val_loss: 106.4607\n",
      "Epoch 1529/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.9644 - val_loss: 106.3219\n",
      "Epoch 1530/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6770 - val_loss: 106.9852\n",
      "Epoch 1531/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 86.0656 - val_loss: 107.7317\n",
      "Epoch 1532/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1379 - val_loss: 106.1883\n",
      "Epoch 1533/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7672 - val_loss: 104.9954\n",
      "Epoch 1534/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6519 - val_loss: 105.2907\n",
      "Epoch 1535/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9811 - val_loss: 105.9304\n",
      "Epoch 1536/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6884 - val_loss: 107.9490\n",
      "Epoch 1537/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7102 - val_loss: 106.5400\n",
      "Epoch 1538/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4802 - val_loss: 107.1876\n",
      "Epoch 1539/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7253 - val_loss: 106.5321\n",
      "Epoch 1540/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.4707 - val_loss: 106.9817\n",
      "Epoch 1541/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8452 - val_loss: 105.5970\n",
      "Epoch 1542/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.9536 - val_loss: 106.8875\n",
      "Epoch 1543/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.5029 - val_loss: 107.5823\n",
      "Epoch 1544/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.5307 - val_loss: 105.9073\n",
      "Epoch 1545/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.9732 - val_loss: 108.2283\n",
      "Epoch 1546/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6465 - val_loss: 108.4115\n",
      "Epoch 1547/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7062 - val_loss: 108.2395\n",
      "Epoch 1548/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4206 - val_loss: 108.2541\n",
      "Epoch 1549/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4832 - val_loss: 110.5772\n",
      "Epoch 1550/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9817 - val_loss: 106.3759\n",
      "Epoch 1551/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9608 - val_loss: 107.6599\n",
      "Epoch 1552/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6103 - val_loss: 107.4885\n",
      "Epoch 1553/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.2751 - val_loss: 111.0767\n",
      "Epoch 1554/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0692 - val_loss: 105.7001\n",
      "Epoch 1555/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7568 - val_loss: 107.9728\n",
      "Epoch 1556/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9156 - val_loss: 108.9486\n",
      "Epoch 1557/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6860 - val_loss: 107.0414\n",
      "Epoch 1558/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6413 - val_loss: 106.4685\n",
      "Epoch 1559/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4720 - val_loss: 107.5089\n",
      "Epoch 1560/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0058 - val_loss: 106.8500\n",
      "Epoch 1561/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.1085 - val_loss: 108.3569\n",
      "Epoch 1562/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9716 - val_loss: 107.3616\n",
      "Epoch 1563/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.9466 - val_loss: 106.8482\n",
      "Epoch 1564/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9904 - val_loss: 109.3013\n",
      "Epoch 1565/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.5584 - val_loss: 107.4825\n",
      "Epoch 1566/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.1067 - val_loss: 107.3647\n",
      "Epoch 1567/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9088 - val_loss: 107.0554\n",
      "Epoch 1568/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6412 - val_loss: 107.2239\n",
      "Epoch 1569/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8240 - val_loss: 108.4903\n",
      "Epoch 1570/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7053 - val_loss: 106.6854\n",
      "Epoch 1571/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5451 - val_loss: 108.6794\n",
      "Epoch 1572/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3617 - val_loss: 107.6177\n",
      "Epoch 1573/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8360 - val_loss: 108.5694\n",
      "Epoch 1574/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5362 - val_loss: 108.9668\n",
      "Epoch 1575/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7162 - val_loss: 107.3933\n",
      "Epoch 1576/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.1619 - val_loss: 107.4951\n",
      "Epoch 1577/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.6215 - val_loss: 107.2593\n",
      "Epoch 1578/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.4768 - val_loss: 107.0010\n",
      "Epoch 1579/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6844 - val_loss: 107.8656\n",
      "Epoch 1580/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4612 - val_loss: 107.6816\n",
      "Epoch 1581/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6158 - val_loss: 108.5646\n",
      "Epoch 1582/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7280 - val_loss: 107.1379\n",
      "Epoch 1583/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5940 - val_loss: 107.2420\n",
      "Epoch 1584/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 86.1331 - val_loss: 107.1300\n",
      "Epoch 1585/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.7843 - val_loss: 107.1173\n",
      "Epoch 1586/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 85.8052 - val_loss: 108.1060\n",
      "Epoch 1587/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.5039 - val_loss: 107.9997\n",
      "Epoch 1588/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4849 - val_loss: 107.7184\n",
      "Epoch 1589/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7797 - val_loss: 107.7607\n",
      "Epoch 1590/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7155 - val_loss: 107.2108\n",
      "Epoch 1591/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.5103 - val_loss: 105.9246\n",
      "Epoch 1592/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.0093 - val_loss: 108.4903\n",
      "Epoch 1593/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.5747 - val_loss: 106.8562\n",
      "Epoch 1594/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.9188 - val_loss: 109.5649\n",
      "Epoch 1595/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.5624 - val_loss: 107.4485\n",
      "Epoch 1596/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9887 - val_loss: 107.6901\n",
      "Epoch 1597/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 86.5712 - val_loss: 106.2746\n",
      "Epoch 1598/2300\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 85.3036 - val_loss: 108.3022\n",
      "Epoch 1599/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 86.0308 - val_loss: 108.5331\n",
      "Epoch 1600/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.4152 - val_loss: 107.0873\n",
      "Epoch 1601/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6684 - val_loss: 107.3787\n",
      "Epoch 1602/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3285 - val_loss: 106.2584\n",
      "Epoch 1603/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 86.0095 - val_loss: 107.4709\n",
      "Epoch 1604/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7348 - val_loss: 106.8626\n",
      "Epoch 1605/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2387 - val_loss: 108.4622\n",
      "Epoch 1606/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4356 - val_loss: 107.3580\n",
      "Epoch 1607/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7705 - val_loss: 111.3155\n",
      "Epoch 1608/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4496 - val_loss: 107.2143\n",
      "Epoch 1609/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6070 - val_loss: 107.7091\n",
      "Epoch 1610/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 85.6886 - val_loss: 109.2949\n",
      "Epoch 1611/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 85.6377 - val_loss: 107.2232\n",
      "Epoch 1612/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7463 - val_loss: 107.4719\n",
      "Epoch 1613/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3380 - val_loss: 108.2642\n",
      "Epoch 1614/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8038 - val_loss: 108.2650\n",
      "Epoch 1615/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4134 - val_loss: 107.4083\n",
      "Epoch 1616/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7552 - val_loss: 107.6978\n",
      "Epoch 1617/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2918 - val_loss: 106.7837\n",
      "Epoch 1618/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8733 - val_loss: 106.6419\n",
      "Epoch 1619/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5704 - val_loss: 108.1395\n",
      "Epoch 1620/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4648 - val_loss: 110.0000\n",
      "Epoch 1621/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7719 - val_loss: 107.2131\n",
      "Epoch 1622/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7603 - val_loss: 107.8335\n",
      "Epoch 1623/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.6570 - val_loss: 107.9781\n",
      "Epoch 1624/2300\n",
      "17948/17948 [==============================] - 1s 46us/sample - loss: 85.4143 - val_loss: 106.9136\n",
      "Epoch 1625/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.2457 - val_loss: 108.0300\n",
      "Epoch 1626/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5154 - val_loss: 107.2325\n",
      "Epoch 1627/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.3739 - val_loss: 106.3981\n",
      "Epoch 1628/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6700 - val_loss: 107.0653\n",
      "Epoch 1629/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5893 - val_loss: 107.0754\n",
      "Epoch 1630/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6537 - val_loss: 106.6946\n",
      "Epoch 1631/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 85.7421 - val_loss: 109.9312\n",
      "Epoch 1632/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5704 - val_loss: 107.3424\n",
      "Epoch 1633/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6998 - val_loss: 107.3637\n",
      "Epoch 1634/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7128 - val_loss: 106.4938\n",
      "Epoch 1635/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9124 - val_loss: 106.7297\n",
      "Epoch 1636/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5346 - val_loss: 107.1781\n",
      "Epoch 1637/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6290 - val_loss: 106.9691\n",
      "Epoch 1638/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5997 - val_loss: 106.5982\n",
      "Epoch 1639/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.7037 - val_loss: 106.7703\n",
      "Epoch 1640/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5955 - val_loss: 107.4539\n",
      "Epoch 1641/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6994 - val_loss: 107.6612\n",
      "Epoch 1642/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6078 - val_loss: 107.1100\n",
      "Epoch 1643/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7768 - val_loss: 108.5850\n",
      "Epoch 1644/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4597 - val_loss: 108.0027\n",
      "Epoch 1645/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.3111 - val_loss: 106.5392\n",
      "Epoch 1646/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.6972 - val_loss: 110.3753\n",
      "Epoch 1647/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8462 - val_loss: 107.1723\n",
      "Epoch 1648/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4730 - val_loss: 108.0368\n",
      "Epoch 1649/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9533 - val_loss: 108.1983\n",
      "Epoch 1650/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2105 - val_loss: 106.8929\n",
      "Epoch 1651/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7517 - val_loss: 107.8246\n",
      "Epoch 1652/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.8221 - val_loss: 107.9476\n",
      "Epoch 1653/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6339 - val_loss: 107.2845\n",
      "Epoch 1654/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4867 - val_loss: 109.2571\n",
      "Epoch 1655/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5431 - val_loss: 110.6849\n",
      "Epoch 1656/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8965 - val_loss: 107.1696\n",
      "Epoch 1657/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5757 - val_loss: 110.1885\n",
      "Epoch 1658/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.9501 - val_loss: 106.8308\n",
      "Epoch 1659/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4847 - val_loss: 109.6223\n",
      "Epoch 1660/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5147 - val_loss: 107.2152\n",
      "Epoch 1661/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6309 - val_loss: 108.7558\n",
      "Epoch 1662/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3327 - val_loss: 105.8684\n",
      "Epoch 1663/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.9557 - val_loss: 107.5978\n",
      "Epoch 1664/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4947 - val_loss: 107.9315\n",
      "Epoch 1665/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.2594 - val_loss: 107.5072\n",
      "Epoch 1666/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7789 - val_loss: 108.8567\n",
      "Epoch 1667/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1598 - val_loss: 107.3568\n",
      "Epoch 1668/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6832 - val_loss: 108.4796\n",
      "Epoch 1669/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3694 - val_loss: 109.0391\n",
      "Epoch 1670/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7400 - val_loss: 109.7183\n",
      "Epoch 1671/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5149 - val_loss: 108.0711\n",
      "Epoch 1672/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6380 - val_loss: 106.6786\n",
      "Epoch 1673/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4963 - val_loss: 107.9497\n",
      "Epoch 1674/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4230 - val_loss: 107.6762\n",
      "Epoch 1675/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6945 - val_loss: 107.1000\n",
      "Epoch 1676/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0261 - val_loss: 107.2708\n",
      "Epoch 1677/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2107 - val_loss: 109.8272\n",
      "Epoch 1678/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3114 - val_loss: 109.1699\n",
      "Epoch 1679/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0161 - val_loss: 107.4244\n",
      "Epoch 1680/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4927 - val_loss: 108.2820\n",
      "Epoch 1681/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1193 - val_loss: 108.1233\n",
      "Epoch 1682/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4843 - val_loss: 107.5158\n",
      "Epoch 1683/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3400 - val_loss: 110.8230\n",
      "Epoch 1684/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7449 - val_loss: 109.6461\n",
      "Epoch 1685/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7274 - val_loss: 108.5553\n",
      "Epoch 1686/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2882 - val_loss: 108.1259\n",
      "Epoch 1687/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3535 - val_loss: 106.8435\n",
      "Epoch 1688/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7980 - val_loss: 113.1611\n",
      "Epoch 1689/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7630 - val_loss: 107.0292\n",
      "Epoch 1690/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7940 - val_loss: 108.4123\n",
      "Epoch 1691/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4661 - val_loss: 110.6147\n",
      "Epoch 1692/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8731 - val_loss: 108.1356\n",
      "Epoch 1693/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4290 - val_loss: 107.3295\n",
      "Epoch 1694/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6119 - val_loss: 107.7133\n",
      "Epoch 1695/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4693 - val_loss: 108.6584\n",
      "Epoch 1696/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7652 - val_loss: 108.1132\n",
      "Epoch 1697/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 86.0800 - val_loss: 109.0479\n",
      "Epoch 1698/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1408 - val_loss: 107.2988\n",
      "Epoch 1699/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6773 - val_loss: 108.7683\n",
      "Epoch 1700/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3140 - val_loss: 107.6619\n",
      "Epoch 1701/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4688 - val_loss: 109.4629\n",
      "Epoch 1702/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7895 - val_loss: 107.8684\n",
      "Epoch 1703/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3612 - val_loss: 109.1989\n",
      "Epoch 1704/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6506 - val_loss: 107.5834\n",
      "Epoch 1705/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5238 - val_loss: 111.6750\n",
      "Epoch 1706/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7701 - val_loss: 110.6217\n",
      "Epoch 1707/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8102 - val_loss: 107.7248\n",
      "Epoch 1708/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6351 - val_loss: 107.6694\n",
      "Epoch 1709/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2236 - val_loss: 109.1598\n",
      "Epoch 1710/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3653 - val_loss: 109.3488\n",
      "Epoch 1711/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4123 - val_loss: 108.9988\n",
      "Epoch 1712/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4435 - val_loss: 107.5951\n",
      "Epoch 1713/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3613 - val_loss: 109.7839\n",
      "Epoch 1714/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1239 - val_loss: 107.5932\n",
      "Epoch 1715/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3976 - val_loss: 109.0160\n",
      "Epoch 1716/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3236 - val_loss: 107.7308\n",
      "Epoch 1717/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3298 - val_loss: 106.1559\n",
      "Epoch 1718/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3493 - val_loss: 108.2717\n",
      "Epoch 1719/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.2055 - val_loss: 107.5627\n",
      "Epoch 1720/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 38us/sample - loss: 85.2907 - val_loss: 108.1246\n",
      "Epoch 1721/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.9727 - val_loss: 107.7003\n",
      "Epoch 1722/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.8222 - val_loss: 108.5729\n",
      "Epoch 1723/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0483 - val_loss: 107.8672\n",
      "Epoch 1724/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5506 - val_loss: 108.1400\n",
      "Epoch 1725/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5352 - val_loss: 108.0564\n",
      "Epoch 1726/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5539 - val_loss: 107.4129\n",
      "Epoch 1727/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7007 - val_loss: 107.3946\n",
      "Epoch 1728/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.8945 - val_loss: 109.5290\n",
      "Epoch 1729/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5373 - val_loss: 107.1866\n",
      "Epoch 1730/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2976 - val_loss: 109.3235\n",
      "Epoch 1731/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.5078 - val_loss: 107.3752\n",
      "Epoch 1732/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2575 - val_loss: 109.7281\n",
      "Epoch 1733/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2430 - val_loss: 108.2316\n",
      "Epoch 1734/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9084 - val_loss: 111.2368\n",
      "Epoch 1735/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4160 - val_loss: 108.4960\n",
      "Epoch 1736/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5967 - val_loss: 107.9331\n",
      "Epoch 1737/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4720 - val_loss: 110.1526\n",
      "Epoch 1738/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2999 - val_loss: 109.2555\n",
      "Epoch 1739/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3657 - val_loss: 108.2772\n",
      "Epoch 1740/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2140 - val_loss: 108.8959\n",
      "Epoch 1741/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2171 - val_loss: 107.3417\n",
      "Epoch 1742/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7440 - val_loss: 108.6520\n",
      "Epoch 1743/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4448 - val_loss: 107.8887\n",
      "Epoch 1744/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1107 - val_loss: 108.5817\n",
      "Epoch 1745/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3801 - val_loss: 107.9388\n",
      "Epoch 1746/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0256 - val_loss: 108.1895\n",
      "Epoch 1747/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.6662 - val_loss: 107.8623\n",
      "Epoch 1748/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5298 - val_loss: 108.5545\n",
      "Epoch 1749/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3880 - val_loss: 111.4064\n",
      "Epoch 1750/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1752 - val_loss: 109.5628\n",
      "Epoch 1751/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3035 - val_loss: 107.4587\n",
      "Epoch 1752/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7011 - val_loss: 109.0486\n",
      "Epoch 1753/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3011 - val_loss: 108.4357\n",
      "Epoch 1754/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4426 - val_loss: 108.1416\n",
      "Epoch 1755/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5678 - val_loss: 108.2229\n",
      "Epoch 1756/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2057 - val_loss: 108.1137\n",
      "Epoch 1757/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2759 - val_loss: 107.9385\n",
      "Epoch 1758/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7307 - val_loss: 109.8138\n",
      "Epoch 1759/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2131 - val_loss: 109.9566\n",
      "Epoch 1760/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3611 - val_loss: 111.7297\n",
      "Epoch 1761/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0518 - val_loss: 108.1982\n",
      "Epoch 1762/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0750 - val_loss: 108.1840\n",
      "Epoch 1763/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2004 - val_loss: 110.2737\n",
      "Epoch 1764/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7325 - val_loss: 109.6366\n",
      "Epoch 1765/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1640 - val_loss: 108.8451\n",
      "Epoch 1766/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2557 - val_loss: 107.1694\n",
      "Epoch 1767/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4132 - val_loss: 107.9286\n",
      "Epoch 1768/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3100 - val_loss: 108.9465\n",
      "Epoch 1769/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5223 - val_loss: 108.7474\n",
      "Epoch 1770/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6335 - val_loss: 106.8540\n",
      "Epoch 1771/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.7319 - val_loss: 108.4985\n",
      "Epoch 1772/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3877 - val_loss: 108.2500\n",
      "Epoch 1773/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.2015 - val_loss: 107.8086\n",
      "Epoch 1774/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0407 - val_loss: 110.6552\n",
      "Epoch 1775/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7463 - val_loss: 108.3392\n",
      "Epoch 1776/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 85.2141 - val_loss: 108.0126\n",
      "Epoch 1777/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4208 - val_loss: 108.3185\n",
      "Epoch 1778/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5719 - val_loss: 108.3896\n",
      "Epoch 1779/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3905 - val_loss: 108.8805\n",
      "Epoch 1780/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8689 - val_loss: 108.6197\n",
      "Epoch 1781/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3859 - val_loss: 111.8776\n",
      "Epoch 1782/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5693 - val_loss: 107.8511\n",
      "Epoch 1783/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9910 - val_loss: 109.0646\n",
      "Epoch 1784/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.2071 - val_loss: 108.1356\n",
      "Epoch 1785/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4503 - val_loss: 108.0418\n",
      "Epoch 1786/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.3488 - val_loss: 107.2866\n",
      "Epoch 1787/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.8579 - val_loss: 108.2673\n",
      "Epoch 1788/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1017 - val_loss: 108.4601\n",
      "Epoch 1789/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8150 - val_loss: 108.3595\n",
      "Epoch 1790/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3957 - val_loss: 107.3613\n",
      "Epoch 1791/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5554 - val_loss: 109.1914\n",
      "Epoch 1792/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6733 - val_loss: 109.2636\n",
      "Epoch 1793/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9715 - val_loss: 108.7911\n",
      "Epoch 1794/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5282 - val_loss: 109.2458\n",
      "Epoch 1795/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8817 - val_loss: 107.1503\n",
      "Epoch 1796/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2858 - val_loss: 109.6119\n",
      "Epoch 1797/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7975 - val_loss: 110.6077\n",
      "Epoch 1798/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.5070 - val_loss: 108.2882\n",
      "Epoch 1799/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5408 - val_loss: 108.3213\n",
      "Epoch 1800/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1839 - val_loss: 109.1253\n",
      "Epoch 1801/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0235 - val_loss: 107.8356\n",
      "Epoch 1802/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.3465 - val_loss: 110.0691\n",
      "Epoch 1803/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0707 - val_loss: 109.8385\n",
      "Epoch 1804/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2408 - val_loss: 112.1703\n",
      "Epoch 1805/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3617 - val_loss: 109.3868\n",
      "Epoch 1806/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3019 - val_loss: 109.2746\n",
      "Epoch 1807/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4221 - val_loss: 107.7461\n",
      "Epoch 1808/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1847 - val_loss: 109.3143\n",
      "Epoch 1809/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0746 - val_loss: 107.9683\n",
      "Epoch 1810/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5365 - val_loss: 109.6973\n",
      "Epoch 1811/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 85.0573 - val_loss: 109.1585\n",
      "Epoch 1812/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2520 - val_loss: 108.7492\n",
      "Epoch 1813/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.6227 - val_loss: 109.0367\n",
      "Epoch 1814/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2852 - val_loss: 109.2516\n",
      "Epoch 1815/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4415 - val_loss: 107.4753\n",
      "Epoch 1816/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3748 - val_loss: 107.2938\n",
      "Epoch 1817/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5826 - val_loss: 107.9371\n",
      "Epoch 1818/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.1891 - val_loss: 108.5594\n",
      "Epoch 1819/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2602 - val_loss: 110.5036\n",
      "Epoch 1820/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4374 - val_loss: 108.0549\n",
      "Epoch 1821/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0025 - val_loss: 108.5888\n",
      "Epoch 1822/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2550 - val_loss: 108.4562\n",
      "Epoch 1823/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2378 - val_loss: 108.6917\n",
      "Epoch 1824/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3769 - val_loss: 108.7378\n",
      "Epoch 1825/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4395 - val_loss: 109.2185\n",
      "Epoch 1826/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1744 - val_loss: 109.5004\n",
      "Epoch 1827/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4287 - val_loss: 109.9529\n",
      "Epoch 1828/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4606 - val_loss: 109.5435\n",
      "Epoch 1829/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.1536 - val_loss: 108.9370\n",
      "Epoch 1830/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8842 - val_loss: 108.7037\n",
      "Epoch 1831/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9152 - val_loss: 110.3894\n",
      "Epoch 1832/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.6070 - val_loss: 108.3192\n",
      "Epoch 1833/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1603 - val_loss: 110.1478\n",
      "Epoch 1834/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.0452 - val_loss: 107.8083\n",
      "Epoch 1835/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0047 - val_loss: 108.6811\n",
      "Epoch 1836/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1919 - val_loss: 109.5602\n",
      "Epoch 1837/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4782 - val_loss: 108.9607\n",
      "Epoch 1838/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2048 - val_loss: 108.6558\n",
      "Epoch 1839/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.4778 - val_loss: 108.5570\n",
      "Epoch 1840/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5425 - val_loss: 107.6870\n",
      "Epoch 1841/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2510 - val_loss: 109.1175\n",
      "Epoch 1842/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0715 - val_loss: 107.8102\n",
      "Epoch 1843/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.1509 - val_loss: 109.8413\n",
      "Epoch 1844/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8922 - val_loss: 110.7601\n",
      "Epoch 1845/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1057 - val_loss: 108.7413\n",
      "Epoch 1846/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.8710 - val_loss: 108.3779\n",
      "Epoch 1847/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.5485 - val_loss: 108.6508\n",
      "Epoch 1848/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9437 - val_loss: 109.8936\n",
      "Epoch 1849/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3222 - val_loss: 109.5541\n",
      "Epoch 1850/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2829 - val_loss: 110.2922\n",
      "Epoch 1851/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.4694 - val_loss: 108.9661\n",
      "Epoch 1852/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1423 - val_loss: 108.8044\n",
      "Epoch 1853/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9061 - val_loss: 108.8167\n",
      "Epoch 1854/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7724 - val_loss: 107.5535\n",
      "Epoch 1855/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2791 - val_loss: 108.1964\n",
      "Epoch 1856/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0026 - val_loss: 109.4746\n",
      "Epoch 1857/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.0053 - val_loss: 108.1998\n",
      "Epoch 1858/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0251 - val_loss: 109.7638\n",
      "Epoch 1859/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7789 - val_loss: 110.5898\n",
      "Epoch 1860/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.1870 - val_loss: 111.3897\n",
      "Epoch 1861/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8771 - val_loss: 111.9590\n",
      "Epoch 1862/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3295 - val_loss: 108.9686\n",
      "Epoch 1863/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.9154 - val_loss: 109.6380\n",
      "Epoch 1864/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.4703 - val_loss: 109.9105\n",
      "Epoch 1865/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2095 - val_loss: 109.0488\n",
      "Epoch 1866/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0478 - val_loss: 108.6679\n",
      "Epoch 1867/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4212 - val_loss: 109.2081\n",
      "Epoch 1868/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.6916 - val_loss: 108.2878\n",
      "Epoch 1869/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.1998 - val_loss: 108.2227\n",
      "Epoch 1870/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1362 - val_loss: 111.4494\n",
      "Epoch 1871/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.7520 - val_loss: 108.6281\n",
      "Epoch 1872/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8871 - val_loss: 108.5129\n",
      "Epoch 1873/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3849 - val_loss: 107.9185\n",
      "Epoch 1874/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3351 - val_loss: 109.1848\n",
      "Epoch 1875/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9973 - val_loss: 108.4935\n",
      "Epoch 1876/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2839 - val_loss: 109.6606\n",
      "Epoch 1877/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0813 - val_loss: 107.9483\n",
      "Epoch 1878/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2801 - val_loss: 109.8198\n",
      "Epoch 1879/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2270 - val_loss: 108.8308\n",
      "Epoch 1880/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1883 - val_loss: 109.1862\n",
      "Epoch 1881/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0690 - val_loss: 113.7010\n",
      "Epoch 1882/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0590 - val_loss: 111.9637\n",
      "Epoch 1883/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3528 - val_loss: 107.3711\n",
      "Epoch 1884/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0609 - val_loss: 111.7209\n",
      "Epoch 1885/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1998 - val_loss: 109.9913\n",
      "Epoch 1886/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8191 - val_loss: 110.4069\n",
      "Epoch 1887/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0052 - val_loss: 109.3394\n",
      "Epoch 1888/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0699 - val_loss: 110.0041\n",
      "Epoch 1889/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0449 - val_loss: 110.6777\n",
      "Epoch 1890/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 84.9477 - val_loss: 110.3669\n",
      "Epoch 1891/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.9001 - val_loss: 109.1815\n",
      "Epoch 1892/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2023 - val_loss: 110.0644\n",
      "Epoch 1893/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8581 - val_loss: 109.3833\n",
      "Epoch 1894/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.0844 - val_loss: 109.3298\n",
      "Epoch 1895/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9630 - val_loss: 110.5778\n",
      "Epoch 1896/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3416 - val_loss: 109.0519\n",
      "Epoch 1897/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.5966 - val_loss: 108.7016\n",
      "Epoch 1898/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.9638 - val_loss: 109.6712\n",
      "Epoch 1899/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.1175 - val_loss: 109.0861\n",
      "Epoch 1900/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2318 - val_loss: 108.7832\n",
      "Epoch 1901/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.1966 - val_loss: 109.1876\n",
      "Epoch 1902/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7750 - val_loss: 108.3640\n",
      "Epoch 1903/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0320 - val_loss: 109.1033\n",
      "Epoch 1904/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.1612 - val_loss: 108.4366\n",
      "Epoch 1905/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9427 - val_loss: 108.7850\n",
      "Epoch 1906/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.6064 - val_loss: 109.9017\n",
      "Epoch 1907/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.1054 - val_loss: 109.3207\n",
      "Epoch 1908/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8800 - val_loss: 109.3319\n",
      "Epoch 1909/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 85.2106 - val_loss: 109.8184\n",
      "Epoch 1910/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7669 - val_loss: 108.8695\n",
      "Epoch 1911/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3714 - val_loss: 108.7749\n",
      "Epoch 1912/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.4528 - val_loss: 110.5268\n",
      "Epoch 1913/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2967 - val_loss: 108.4398\n",
      "Epoch 1914/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0872 - val_loss: 109.8670\n",
      "Epoch 1915/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5468 - val_loss: 109.2724\n",
      "Epoch 1916/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9459 - val_loss: 108.5457\n",
      "Epoch 1917/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2719 - val_loss: 109.0922\n",
      "Epoch 1918/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7297 - val_loss: 110.3283\n",
      "Epoch 1919/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6791 - val_loss: 115.7842\n",
      "Epoch 1920/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0906 - val_loss: 108.3097\n",
      "Epoch 1921/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.1786 - val_loss: 110.8043\n",
      "Epoch 1922/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7624 - val_loss: 109.6502\n",
      "Epoch 1923/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.2093 - val_loss: 110.2199\n",
      "Epoch 1924/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0844 - val_loss: 109.5294\n",
      "Epoch 1925/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.3982 - val_loss: 111.4982\n",
      "Epoch 1926/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7928 - val_loss: 109.8335\n",
      "Epoch 1927/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6002 - val_loss: 109.0541\n",
      "Epoch 1928/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0944 - val_loss: 111.2113\n",
      "Epoch 1929/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9336 - val_loss: 109.5596\n",
      "Epoch 1930/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.1264 - val_loss: 109.4751\n",
      "Epoch 1931/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.3853 - val_loss: 109.6066\n",
      "Epoch 1932/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.9070 - val_loss: 111.4521\n",
      "Epoch 1933/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.5543 - val_loss: 110.2697\n",
      "Epoch 1934/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2806 - val_loss: 108.9479\n",
      "Epoch 1935/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1732 - val_loss: 109.0122\n",
      "Epoch 1936/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1583 - val_loss: 110.5411\n",
      "Epoch 1937/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1167 - val_loss: 109.0358\n",
      "Epoch 1938/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0149 - val_loss: 107.7067\n",
      "Epoch 1939/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8517 - val_loss: 108.6753\n",
      "Epoch 1940/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0138 - val_loss: 108.8392\n",
      "Epoch 1941/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.9229 - val_loss: 112.4179\n",
      "Epoch 1942/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2119 - val_loss: 109.1583\n",
      "Epoch 1943/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1157 - val_loss: 111.7365\n",
      "Epoch 1944/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7255 - val_loss: 109.5556\n",
      "Epoch 1945/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8691 - val_loss: 119.4670\n",
      "Epoch 1946/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0201 - val_loss: 108.8791\n",
      "Epoch 1947/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8765 - val_loss: 108.8205\n",
      "Epoch 1948/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6854 - val_loss: 109.7156\n",
      "Epoch 1949/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0199 - val_loss: 109.8009\n",
      "Epoch 1950/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.6494 - val_loss: 109.7200\n",
      "Epoch 1951/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0701 - val_loss: 110.4761\n",
      "Epoch 1952/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1567 - val_loss: 109.9694\n",
      "Epoch 1953/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6390 - val_loss: 109.9324\n",
      "Epoch 1954/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0098 - val_loss: 111.1542\n",
      "Epoch 1955/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8782 - val_loss: 109.4183\n",
      "Epoch 1956/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1786 - val_loss: 110.8767\n",
      "Epoch 1957/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0423 - val_loss: 110.3104\n",
      "Epoch 1958/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2635 - val_loss: 110.8206\n",
      "Epoch 1959/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6882 - val_loss: 110.0960\n",
      "Epoch 1960/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8098 - val_loss: 111.7714\n",
      "Epoch 1961/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.2213 - val_loss: 108.6374\n",
      "Epoch 1962/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9514 - val_loss: 108.2616\n",
      "Epoch 1963/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7676 - val_loss: 109.7085\n",
      "Epoch 1964/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9341 - val_loss: 109.9693\n",
      "Epoch 1965/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1208 - val_loss: 109.5743\n",
      "Epoch 1966/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.4900 - val_loss: 111.1248\n",
      "Epoch 1967/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0776 - val_loss: 108.9679\n",
      "Epoch 1968/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3286 - val_loss: 109.2683\n",
      "Epoch 1969/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8394 - val_loss: 110.4493\n",
      "Epoch 1970/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7361 - val_loss: 109.7687\n",
      "Epoch 1971/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7494 - val_loss: 108.7184\n",
      "Epoch 1972/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 84.9567 - val_loss: 109.5049\n",
      "Epoch 1973/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6430 - val_loss: 111.0279\n",
      "Epoch 1974/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.6638 - val_loss: 109.9361\n",
      "Epoch 1975/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.7522 - val_loss: 110.2842\n",
      "Epoch 1976/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.9161 - val_loss: 110.5809\n",
      "Epoch 1977/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8315 - val_loss: 110.7444\n",
      "Epoch 1978/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.8607 - val_loss: 111.7247\n",
      "Epoch 1979/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0746 - val_loss: 109.4527\n",
      "Epoch 1980/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8225 - val_loss: 109.5990\n",
      "Epoch 1981/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.3434 - val_loss: 108.8730\n",
      "Epoch 1982/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 84.6220 - val_loss: 109.6936\n",
      "Epoch 1983/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.7746 - val_loss: 109.0027\n",
      "Epoch 1984/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.7431 - val_loss: 110.0441\n",
      "Epoch 1985/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0107 - val_loss: 111.7817\n",
      "Epoch 1986/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2739 - val_loss: 108.8254\n",
      "Epoch 1987/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6405 - val_loss: 110.0528\n",
      "Epoch 1988/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9347 - val_loss: 109.8836\n",
      "Epoch 1989/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0378 - val_loss: 111.1191\n",
      "Epoch 1990/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6569 - val_loss: 109.5576\n",
      "Epoch 1991/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8570 - val_loss: 110.7252\n",
      "Epoch 1992/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9807 - val_loss: 110.7052\n",
      "Epoch 1993/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7762 - val_loss: 109.3855\n",
      "Epoch 1994/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7516 - val_loss: 112.6511\n",
      "Epoch 1995/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5683 - val_loss: 114.9368\n",
      "Epoch 1996/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8717 - val_loss: 111.0232\n",
      "Epoch 1997/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.7252 - val_loss: 109.8275\n",
      "Epoch 1998/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.7577 - val_loss: 110.1594\n",
      "Epoch 1999/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8007 - val_loss: 112.3711\n",
      "Epoch 2000/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.7271 - val_loss: 110.7710\n",
      "Epoch 2001/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.2090 - val_loss: 109.0392\n",
      "Epoch 2002/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5199 - val_loss: 109.3726\n",
      "Epoch 2003/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.9867 - val_loss: 111.6322\n",
      "Epoch 2004/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1195 - val_loss: 109.4021\n",
      "Epoch 2005/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8137 - val_loss: 110.3373\n",
      "Epoch 2006/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.6613 - val_loss: 111.7730\n",
      "Epoch 2007/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0077 - val_loss: 111.1384\n",
      "Epoch 2008/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.7609 - val_loss: 111.7330\n",
      "Epoch 2009/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0243 - val_loss: 110.4661\n",
      "Epoch 2010/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8438 - val_loss: 110.6045\n",
      "Epoch 2011/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8653 - val_loss: 109.3442\n",
      "Epoch 2012/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7086 - val_loss: 109.9764\n",
      "Epoch 2013/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5688 - val_loss: 110.8571\n",
      "Epoch 2014/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.6838 - val_loss: 110.7704\n",
      "Epoch 2015/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.6804 - val_loss: 111.2703\n",
      "Epoch 2016/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.9305 - val_loss: 110.6928\n",
      "Epoch 2017/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7390 - val_loss: 109.2618\n",
      "Epoch 2018/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4536 - val_loss: 109.2188\n",
      "Epoch 2019/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.9927 - val_loss: 110.5361\n",
      "Epoch 2020/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9981 - val_loss: 110.5300\n",
      "Epoch 2021/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0520 - val_loss: 110.3158\n",
      "Epoch 2022/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9650 - val_loss: 110.3678\n",
      "Epoch 2023/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1687 - val_loss: 110.0477\n",
      "Epoch 2024/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.7414 - val_loss: 109.2309\n",
      "Epoch 2025/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.2022 - val_loss: 110.3463\n",
      "Epoch 2026/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0533 - val_loss: 109.6809\n",
      "Epoch 2027/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.4639 - val_loss: 112.1485\n",
      "Epoch 2028/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.6975 - val_loss: 110.8257\n",
      "Epoch 2029/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5537 - val_loss: 110.9781\n",
      "Epoch 2030/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7739 - val_loss: 114.0793\n",
      "Epoch 2031/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0268 - val_loss: 111.0200\n",
      "Epoch 2032/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0298 - val_loss: 110.2886\n",
      "Epoch 2033/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6987 - val_loss: 110.2627\n",
      "Epoch 2034/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7368 - val_loss: 110.1072\n",
      "Epoch 2035/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8064 - val_loss: 109.4913\n",
      "Epoch 2036/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7481 - val_loss: 111.6519\n",
      "Epoch 2037/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6098 - val_loss: 110.4543\n",
      "Epoch 2038/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7695 - val_loss: 110.5678\n",
      "Epoch 2039/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6380 - val_loss: 109.7090\n",
      "Epoch 2040/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0660 - val_loss: 111.0970\n",
      "Epoch 2041/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.7343 - val_loss: 110.8522\n",
      "Epoch 2042/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8169 - val_loss: 110.7764\n",
      "Epoch 2043/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.9413 - val_loss: 108.8214\n",
      "Epoch 2044/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.0136 - val_loss: 109.1061\n",
      "Epoch 2045/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.2006 - val_loss: 110.5008\n",
      "Epoch 2046/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7637 - val_loss: 112.2111\n",
      "Epoch 2047/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.9932 - val_loss: 109.4096\n",
      "Epoch 2048/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0296 - val_loss: 110.4664\n",
      "Epoch 2049/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7483 - val_loss: 110.0419\n",
      "Epoch 2050/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7837 - val_loss: 113.0860\n",
      "Epoch 2051/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5600 - val_loss: 108.7394\n",
      "Epoch 2052/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0160 - val_loss: 109.9116\n",
      "Epoch 2053/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7796 - val_loss: 110.1368\n",
      "Epoch 2054/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6538 - val_loss: 110.1003\n",
      "Epoch 2055/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5890 - val_loss: 109.8308\n",
      "Epoch 2056/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6387 - val_loss: 110.2938\n",
      "Epoch 2057/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7736 - val_loss: 109.6913\n",
      "Epoch 2058/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5837 - val_loss: 109.6459\n",
      "Epoch 2059/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6142 - val_loss: 110.2112\n",
      "Epoch 2060/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8355 - val_loss: 109.6128\n",
      "Epoch 2061/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8574 - val_loss: 109.0856\n",
      "Epoch 2062/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6933 - val_loss: 110.7150\n",
      "Epoch 2063/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.9967 - val_loss: 110.1247\n",
      "Epoch 2064/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5271 - val_loss: 112.1344\n",
      "Epoch 2065/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5685 - val_loss: 109.2930\n",
      "Epoch 2066/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5436 - val_loss: 108.7389\n",
      "Epoch 2067/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5268 - val_loss: 110.5113\n",
      "Epoch 2068/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8379 - val_loss: 109.4266\n",
      "Epoch 2069/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8489 - val_loss: 111.3111\n",
      "Epoch 2070/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7463 - val_loss: 110.8327\n",
      "Epoch 2071/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8370 - val_loss: 109.8477\n",
      "Epoch 2072/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 85.1624 - val_loss: 111.7503\n",
      "Epoch 2073/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7459 - val_loss: 109.4891\n",
      "Epoch 2074/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6533 - val_loss: 110.6286\n",
      "Epoch 2075/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7310 - val_loss: 110.3745\n",
      "Epoch 2076/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8569 - val_loss: 109.6198\n",
      "Epoch 2077/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5995 - val_loss: 111.0491\n",
      "Epoch 2078/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7479 - val_loss: 110.7893\n",
      "Epoch 2079/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6933 - val_loss: 112.6906\n",
      "Epoch 2080/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6666 - val_loss: 109.6896\n",
      "Epoch 2081/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7641 - val_loss: 111.4580\n",
      "Epoch 2082/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7125 - val_loss: 110.5516\n",
      "Epoch 2083/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.0004 - val_loss: 109.1957\n",
      "Epoch 2084/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6536 - val_loss: 108.8677\n",
      "Epoch 2085/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.1901 - val_loss: 110.9893\n",
      "Epoch 2086/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 85.2172 - val_loss: 109.7402\n",
      "Epoch 2087/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6166 - val_loss: 109.2220\n",
      "Epoch 2088/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5166 - val_loss: 111.7518\n",
      "Epoch 2089/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4534 - val_loss: 111.4378\n",
      "Epoch 2090/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7188 - val_loss: 111.4936\n",
      "Epoch 2091/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9228 - val_loss: 109.3888\n",
      "Epoch 2092/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6895 - val_loss: 113.1591\n",
      "Epoch 2093/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.1239 - val_loss: 110.8488\n",
      "Epoch 2094/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6565 - val_loss: 109.4829\n",
      "Epoch 2095/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5081 - val_loss: 113.0980\n",
      "Epoch 2096/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5936 - val_loss: 110.4152\n",
      "Epoch 2097/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 85.1078 - val_loss: 111.2253\n",
      "Epoch 2098/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5267 - val_loss: 109.3186\n",
      "Epoch 2099/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9791 - val_loss: 112.7975\n",
      "Epoch 2100/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5000 - val_loss: 110.9495\n",
      "Epoch 2101/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4808 - val_loss: 111.0245\n",
      "Epoch 2102/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8481 - val_loss: 109.6871\n",
      "Epoch 2103/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7975 - val_loss: 111.6361\n",
      "Epoch 2104/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7953 - val_loss: 110.6461\n",
      "Epoch 2105/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8045 - val_loss: 111.2209\n",
      "Epoch 2106/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8306 - val_loss: 109.8921\n",
      "Epoch 2107/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8108 - val_loss: 110.0369\n",
      "Epoch 2108/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5995 - val_loss: 113.5221\n",
      "Epoch 2109/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6759 - val_loss: 112.1019\n",
      "Epoch 2110/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.5861 - val_loss: 110.8986\n",
      "Epoch 2111/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.3683 - val_loss: 111.1926\n",
      "Epoch 2112/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5568 - val_loss: 111.3331\n",
      "Epoch 2113/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6783 - val_loss: 110.3156\n",
      "Epoch 2114/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2244 - val_loss: 112.9405\n",
      "Epoch 2115/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6000 - val_loss: 114.9241\n",
      "Epoch 2116/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.9819 - val_loss: 111.1786\n",
      "Epoch 2117/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4742 - val_loss: 111.2313\n",
      "Epoch 2118/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.3536 - val_loss: 111.0617\n",
      "Epoch 2119/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7505 - val_loss: 110.3619\n",
      "Epoch 2120/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4538 - val_loss: 109.3499\n",
      "Epoch 2121/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8624 - val_loss: 111.5357\n",
      "Epoch 2122/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4623 - val_loss: 111.8051\n",
      "Epoch 2123/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.7534 - val_loss: 109.9588\n",
      "Epoch 2124/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4830 - val_loss: 113.1240\n",
      "Epoch 2125/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.6840 - val_loss: 110.6434\n",
      "Epoch 2126/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.8068 - val_loss: 110.8257\n",
      "Epoch 2127/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5334 - val_loss: 110.2151\n",
      "Epoch 2128/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5898 - val_loss: 112.5726\n",
      "Epoch 2129/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.1090 - val_loss: 111.1096\n",
      "Epoch 2130/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5685 - val_loss: 111.3885\n",
      "Epoch 2131/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5436 - val_loss: 110.3377\n",
      "Epoch 2132/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5356 - val_loss: 111.1396\n",
      "Epoch 2133/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5595 - val_loss: 110.5501\n",
      "Epoch 2134/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.6031 - val_loss: 113.0396\n",
      "Epoch 2135/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7882 - val_loss: 111.5644\n",
      "Epoch 2136/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7024 - val_loss: 111.7118\n",
      "Epoch 2137/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7318 - val_loss: 110.4820\n",
      "Epoch 2138/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2953 - val_loss: 111.0319\n",
      "Epoch 2139/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7384 - val_loss: 111.8361\n",
      "Epoch 2140/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6412 - val_loss: 110.5086\n",
      "Epoch 2141/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4147 - val_loss: 112.5055\n",
      "Epoch 2142/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4020 - val_loss: 113.9251\n",
      "Epoch 2143/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.8550 - val_loss: 110.8563\n",
      "Epoch 2144/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.1923 - val_loss: 110.7324\n",
      "Epoch 2145/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5307 - val_loss: 110.3125\n",
      "Epoch 2146/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.9708 - val_loss: 111.9216\n",
      "Epoch 2147/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.7531 - val_loss: 111.2142\n",
      "Epoch 2148/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5868 - val_loss: 110.4344\n",
      "Epoch 2149/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.5541 - val_loss: 112.2439\n",
      "Epoch 2150/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.9585 - val_loss: 110.3006\n",
      "Epoch 2151/2300\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 84.5505 - val_loss: 111.8930\n",
      "Epoch 2152/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7262 - val_loss: 112.2918\n",
      "Epoch 2153/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6994 - val_loss: 111.3036\n",
      "Epoch 2154/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.3625 - val_loss: 109.7554\n",
      "Epoch 2155/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.3863 - val_loss: 111.5216\n",
      "Epoch 2156/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.3680 - val_loss: 111.6701\n",
      "Epoch 2157/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.8947 - val_loss: 110.1117\n",
      "Epoch 2158/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6032 - val_loss: 109.9902\n",
      "Epoch 2159/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.2437 - val_loss: 110.2669\n",
      "Epoch 2160/2300\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 84.4567 - val_loss: 110.4556\n",
      "Epoch 2161/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5597 - val_loss: 111.1959\n",
      "Epoch 2162/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8887 - val_loss: 112.4166\n",
      "Epoch 2163/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.6521 - val_loss: 111.4604\n",
      "Epoch 2164/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.9665 - val_loss: 114.1852\n",
      "Epoch 2165/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.3076 - val_loss: 110.3484\n",
      "Epoch 2166/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2320 - val_loss: 109.8564\n",
      "Epoch 2167/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6185 - val_loss: 109.2713\n",
      "Epoch 2168/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.7088 - val_loss: 112.5852\n",
      "Epoch 2169/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.6622 - val_loss: 113.0796\n",
      "Epoch 2170/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.2672 - val_loss: 112.6377\n",
      "Epoch 2171/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.4427 - val_loss: 111.0742\n",
      "Epoch 2172/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.8776 - val_loss: 110.6559\n",
      "Epoch 2173/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6721 - val_loss: 112.7262\n",
      "Epoch 2174/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4294 - val_loss: 111.6346\n",
      "Epoch 2175/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7393 - val_loss: 110.0774\n",
      "Epoch 2176/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.7093 - val_loss: 111.3851\n",
      "Epoch 2177/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.3176 - val_loss: 116.2855\n",
      "Epoch 2178/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.6367 - val_loss: 113.9906\n",
      "Epoch 2179/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7297 - val_loss: 111.1761\n",
      "Epoch 2180/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8249 - val_loss: 110.3648\n",
      "Epoch 2181/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4370 - val_loss: 110.6700\n",
      "Epoch 2182/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5161 - val_loss: 110.6878\n",
      "Epoch 2183/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2831 - val_loss: 110.4244\n",
      "Epoch 2184/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7286 - val_loss: 111.2183\n",
      "Epoch 2185/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.9516 - val_loss: 110.5722\n",
      "Epoch 2186/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6212 - val_loss: 110.0522\n",
      "Epoch 2187/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.8570 - val_loss: 110.1259\n",
      "Epoch 2188/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.3361 - val_loss: 110.7500\n",
      "Epoch 2189/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4534 - val_loss: 110.4796\n",
      "Epoch 2190/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5064 - val_loss: 112.9175\n",
      "Epoch 2191/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7126 - val_loss: 111.5902\n",
      "Epoch 2192/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6538 - val_loss: 110.5205\n",
      "Epoch 2193/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.3010 - val_loss: 116.5483\n",
      "Epoch 2194/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7871 - val_loss: 111.9349\n",
      "Epoch 2195/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4680 - val_loss: 111.6395\n",
      "Epoch 2196/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4828 - val_loss: 112.0279\n",
      "Epoch 2197/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6215 - val_loss: 113.0395\n",
      "Epoch 2198/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 85.0147 - val_loss: 111.1342\n",
      "Epoch 2199/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2752 - val_loss: 111.6673\n",
      "Epoch 2200/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6716 - val_loss: 113.0020\n",
      "Epoch 2201/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2820 - val_loss: 112.2348\n",
      "Epoch 2202/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.1096 - val_loss: 111.9296\n",
      "Epoch 2203/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.6185 - val_loss: 111.0506\n",
      "Epoch 2204/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 83.9828 - val_loss: 112.0943\n",
      "Epoch 2205/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5387 - val_loss: 110.4184\n",
      "Epoch 2206/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6644 - val_loss: 113.3663\n",
      "Epoch 2207/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7091 - val_loss: 110.1902\n",
      "Epoch 2208/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5170 - val_loss: 110.9574\n",
      "Epoch 2209/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4877 - val_loss: 111.6224\n",
      "Epoch 2210/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.4740 - val_loss: 111.7245\n",
      "Epoch 2211/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.1067 - val_loss: 111.6718\n",
      "Epoch 2212/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.7676 - val_loss: 109.5678\n",
      "Epoch 2213/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5586 - val_loss: 111.2598\n",
      "Epoch 2214/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.3479 - val_loss: 109.9633\n",
      "Epoch 2215/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.4164 - val_loss: 112.0305\n",
      "Epoch 2216/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.7136 - val_loss: 113.0657\n",
      "Epoch 2217/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6935 - val_loss: 111.8958\n",
      "Epoch 2218/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.1561 - val_loss: 111.0259\n",
      "Epoch 2219/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.6437 - val_loss: 112.1974\n",
      "Epoch 2220/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.4201 - val_loss: 111.4425\n",
      "Epoch 2221/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.4552 - val_loss: 111.1193\n",
      "Epoch 2222/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.4769 - val_loss: 112.3619\n",
      "Epoch 2223/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.5108 - val_loss: 112.2220\n",
      "Epoch 2224/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 85.0113 - val_loss: 112.4747\n",
      "Epoch 2225/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5422 - val_loss: 111.6349\n",
      "Epoch 2226/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.0832 - val_loss: 109.7679\n",
      "Epoch 2227/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.5165 - val_loss: 111.2181\n",
      "Epoch 2228/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.4518 - val_loss: 111.6995\n",
      "Epoch 2229/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.4437 - val_loss: 112.5158\n",
      "Epoch 2230/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5459 - val_loss: 110.9536\n",
      "Epoch 2231/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.2240 - val_loss: 111.6058\n",
      "Epoch 2232/2300\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 84.7369 - val_loss: 112.6770\n",
      "Epoch 2233/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.4905 - val_loss: 111.3233\n",
      "Epoch 2234/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4213 - val_loss: 113.0940\n",
      "Epoch 2235/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.0146 - val_loss: 112.3520\n",
      "Epoch 2236/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.4116 - val_loss: 111.1088\n",
      "Epoch 2237/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.1181 - val_loss: 111.8287\n",
      "Epoch 2238/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5329 - val_loss: 110.9284\n",
      "Epoch 2239/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2328 - val_loss: 111.5937\n",
      "Epoch 2240/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2143 - val_loss: 111.1590\n",
      "Epoch 2241/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.7062 - val_loss: 111.3426\n",
      "Epoch 2242/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.2139 - val_loss: 111.6578\n",
      "Epoch 2243/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.1289 - val_loss: 112.9611\n",
      "Epoch 2244/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.2909 - val_loss: 110.7174\n",
      "Epoch 2245/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5509 - val_loss: 111.1300\n",
      "Epoch 2246/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.7285 - val_loss: 111.4338\n",
      "Epoch 2247/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.3647 - val_loss: 112.6213\n",
      "Epoch 2248/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2175 - val_loss: 114.2917\n",
      "Epoch 2249/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4908 - val_loss: 112.4907\n",
      "Epoch 2250/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.3719 - val_loss: 112.7003\n",
      "Epoch 2251/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.3677 - val_loss: 111.6490\n",
      "Epoch 2252/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2497 - val_loss: 113.7129\n",
      "Epoch 2253/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2309 - val_loss: 114.5281\n",
      "Epoch 2254/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5491 - val_loss: 112.2481\n",
      "Epoch 2255/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2917 - val_loss: 110.6404\n",
      "Epoch 2256/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.5679 - val_loss: 111.5010\n",
      "Epoch 2257/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.2127 - val_loss: 113.7329\n",
      "Epoch 2258/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.4349 - val_loss: 111.4218\n",
      "Epoch 2259/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.1017 - val_loss: 111.7575\n",
      "Epoch 2260/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4630 - val_loss: 111.8792\n",
      "Epoch 2261/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.3720 - val_loss: 113.0427\n",
      "Epoch 2262/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.4610 - val_loss: 110.8871\n",
      "Epoch 2263/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.0902 - val_loss: 112.6692\n",
      "Epoch 2264/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.3871 - val_loss: 113.7652\n",
      "Epoch 2265/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.0864 - val_loss: 112.6504\n",
      "Epoch 2266/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.4781 - val_loss: 114.1940\n",
      "Epoch 2267/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 83.9491 - val_loss: 115.2683\n",
      "Epoch 2268/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.5613 - val_loss: 111.0903\n",
      "Epoch 2269/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 83.9714 - val_loss: 111.6347\n",
      "Epoch 2270/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.4029 - val_loss: 112.9640\n",
      "Epoch 2271/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.4055 - val_loss: 111.7468\n",
      "Epoch 2272/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6504 - val_loss: 113.8685\n",
      "Epoch 2273/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.2134 - val_loss: 113.3900\n",
      "Epoch 2274/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2928 - val_loss: 111.5930\n",
      "Epoch 2275/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.4447 - val_loss: 113.0591\n",
      "Epoch 2276/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2759 - val_loss: 115.5556\n",
      "Epoch 2277/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5012 - val_loss: 113.1015\n",
      "Epoch 2278/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2036 - val_loss: 115.9317\n",
      "Epoch 2279/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2509 - val_loss: 113.3243\n",
      "Epoch 2280/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.3251 - val_loss: 111.1730\n",
      "Epoch 2281/2300\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 84.1988 - val_loss: 111.5411\n",
      "Epoch 2282/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.1378 - val_loss: 111.8181\n",
      "Epoch 2283/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.9219 - val_loss: 110.7420\n",
      "Epoch 2284/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.5871 - val_loss: 111.8579\n",
      "Epoch 2285/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.4956 - val_loss: 112.7708\n",
      "Epoch 2286/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 83.9625 - val_loss: 111.7621\n",
      "Epoch 2287/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.2522 - val_loss: 111.4658\n",
      "Epoch 2288/2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.6545 - val_loss: 112.2067\n",
      "Epoch 2289/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2263 - val_loss: 112.2619\n",
      "Epoch 2290/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 83.9065 - val_loss: 111.6527\n",
      "Epoch 2291/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.2278 - val_loss: 112.8234\n",
      "Epoch 2292/2300\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 84.1563 - val_loss: 111.4952\n",
      "Epoch 2293/2300\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 84.5666 - val_loss: 111.9622\n",
      "Epoch 2294/2300\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 84.3018 - val_loss: 112.5460\n",
      "Epoch 2295/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 84.2940 - val_loss: 112.2251\n",
      "Epoch 2296/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.4027 - val_loss: 110.7084\n",
      "Epoch 2297/2300\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 84.0262 - val_loss: 110.7558\n",
      "Epoch 2298/2300\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 83.9944 - val_loss: 112.2621\n",
      "Epoch 2299/2300\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 85.2546 - val_loss: 111.3832\n",
      "Epoch 2300/2300\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 84.4841 - val_loss: 112.5261\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,validation_split=0.15,\n",
    "            callbacks=[model_checkpoint],\n",
    "          batch_size=64, epochs=epochs,shuffle=True)\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f1d1a663c8>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 0\n",
    "N = 2900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2900, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value = model.predict(X_test[S:N])\n",
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 500 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 700 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3000 Epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
