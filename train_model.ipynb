{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import model\n",
    "import argparse\n",
    "from tensorflow.keras.callbacks import History, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"training_set.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "data = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>order_in_month</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  order_in_month  month  hour  minute   load\n",
       "0    0             2.0      0   0.0     0.0  81.24\n",
       "1    0             3.0      0   0.0     0.0  81.24\n",
       "2    0             0.0      0   0.0     0.0  66.32\n",
       "3    0             0.0      0   0.0     0.0  88.86\n",
       "4    0             3.0      0   0.0    15.0  80.99"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"load\"].values.reshape(-1,1) # training label\n",
    "X = df[df.columns[:-1]].values.reshape(-1,5)  # training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[81.24],\n",
       "       [81.24],\n",
       "       [66.32],\n",
       "       ...,\n",
       "       [80.32],\n",
       "       [92.37],\n",
       "       [80.99]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  0.,  0.,  0.],\n",
       "       [ 0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 6.,  3., 11., 23., 45.],\n",
       "       [ 6.,  0., 11., 23., 45.],\n",
       "       [ 6.,  2., 11., 23., 45.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300,\n",
    "                activation='relu',\n",
    "                input_shape = X_train.shape[1:]))\n",
    "\n",
    "model.add(Dense(90,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(30,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7,\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,\n",
    "                activation='linear'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "checkpoint_file = \"checkpoint/c.hdf5\"\n",
    "model_file = \"model/m.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0005)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_file,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17948 samples, validate on 3168 samples\n",
      "Epoch 1/20000\n",
      "17948/17948 [==============================] - 1s 52us/sample - loss: 70.9816 - val_loss: 193.5632\n",
      "Epoch 2/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6388 - val_loss: 195.9686\n",
      "Epoch 3/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8809 - val_loss: 197.7541\n",
      "Epoch 4/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9303 - val_loss: 195.2887\n",
      "Epoch 5/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8194 - val_loss: 192.1593\n",
      "Epoch 6/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5161 - val_loss: 193.5973\n",
      "Epoch 7/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0686 - val_loss: 196.3753\n",
      "Epoch 8/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6575 - val_loss: 193.2541\n",
      "Epoch 9/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8442 - val_loss: 194.2391\n",
      "Epoch 10/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7016 - val_loss: 193.8314\n",
      "Epoch 11/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9836 - val_loss: 194.4388\n",
      "Epoch 12/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8745 - val_loss: 192.1601\n",
      "Epoch 13/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5482 - val_loss: 191.2299\n",
      "Epoch 14/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7092 - val_loss: 195.0261\n",
      "Epoch 15/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6425 - val_loss: 192.2379\n",
      "Epoch 16/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9384 - val_loss: 192.3835\n",
      "Epoch 17/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6780 - val_loss: 193.9610\n",
      "Epoch 18/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6690 - val_loss: 192.9270\n",
      "Epoch 19/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9629 - val_loss: 193.5034\n",
      "Epoch 20/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9173 - val_loss: 193.3050\n",
      "Epoch 21/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7770 - val_loss: 189.9238\n",
      "Epoch 22/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8044 - val_loss: 190.3213\n",
      "Epoch 23/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5606 - val_loss: 196.5007\n",
      "Epoch 24/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7686 - val_loss: 191.5819\n",
      "Epoch 25/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5636 - val_loss: 194.5851\n",
      "Epoch 26/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9151 - val_loss: 192.5619\n",
      "Epoch 27/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7924 - val_loss: 192.3967\n",
      "Epoch 28/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7272 - val_loss: 193.3463\n",
      "Epoch 29/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7211 - val_loss: 192.1335\n",
      "Epoch 30/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8043 - val_loss: 193.6279\n",
      "Epoch 31/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4642 - val_loss: 191.4838\n",
      "Epoch 32/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8232 - val_loss: 191.3917\n",
      "Epoch 33/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6522 - val_loss: 192.2569\n",
      "Epoch 34/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7250 - val_loss: 192.6639\n",
      "Epoch 35/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8024 - val_loss: 192.5907\n",
      "Epoch 36/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8117 - val_loss: 191.5542\n",
      "Epoch 37/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6206 - val_loss: 189.8825\n",
      "Epoch 38/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1078 - val_loss: 193.4978\n",
      "Epoch 39/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6471 - val_loss: 192.4715\n",
      "Epoch 40/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8547 - val_loss: 192.2298\n",
      "Epoch 41/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6587 - val_loss: 195.4445\n",
      "Epoch 42/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4824 - val_loss: 192.4222\n",
      "Epoch 43/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7620 - val_loss: 192.0824\n",
      "Epoch 44/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8740 - val_loss: 193.4424\n",
      "Epoch 45/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5226 - val_loss: 194.5698\n",
      "Epoch 46/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8328 - val_loss: 195.3096\n",
      "Epoch 47/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5207 - val_loss: 193.4235\n",
      "Epoch 48/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8429 - val_loss: 192.3137\n",
      "Epoch 49/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6051 - val_loss: 195.0821\n",
      "Epoch 50/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9491 - val_loss: 194.5547\n",
      "Epoch 51/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7774 - val_loss: 192.0979\n",
      "Epoch 52/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7398 - val_loss: 194.7751\n",
      "Epoch 53/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6710 - val_loss: 192.6004\n",
      "Epoch 54/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5625 - val_loss: 193.2419\n",
      "Epoch 55/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4486 - val_loss: 190.9217\n",
      "Epoch 56/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8263 - val_loss: 194.8994\n",
      "Epoch 57/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6303 - val_loss: 194.1974\n",
      "Epoch 58/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7067 - val_loss: 195.7757\n",
      "Epoch 59/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9071 - val_loss: 191.8967\n",
      "Epoch 60/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8293 - val_loss: 191.8785\n",
      "Epoch 61/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6764 - val_loss: 190.7904\n",
      "Epoch 62/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.9228 - val_loss: 194.2623\n",
      "Epoch 63/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5624 - val_loss: 195.2057\n",
      "Epoch 64/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9353 - val_loss: 190.7089\n",
      "Epoch 65/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8970 - val_loss: 193.8109\n",
      "Epoch 66/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5599 - val_loss: 192.0791\n",
      "Epoch 67/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7299 - val_loss: 193.8083\n",
      "Epoch 68/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7812 - val_loss: 195.0350\n",
      "Epoch 69/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 71.0247 - val_loss: 189.8579\n",
      "Epoch 70/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8358 - val_loss: 189.8349\n",
      "Epoch 71/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.8429 - val_loss: 192.3610\n",
      "Epoch 72/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5604 - val_loss: 193.4928\n",
      "Epoch 73/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9025 - val_loss: 194.7968\n",
      "Epoch 74/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.7829 - val_loss: 192.8304\n",
      "Epoch 75/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7444 - val_loss: 195.0961\n",
      "Epoch 76/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7920 - val_loss: 195.5371\n",
      "Epoch 77/20000\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 70.6793 - val_loss: 194.5251\n",
      "Epoch 78/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.5750 - val_loss: 192.2009\n",
      "Epoch 79/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7886 - val_loss: 192.2593\n",
      "Epoch 80/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9765 - val_loss: 195.4719\n",
      "Epoch 81/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5795 - val_loss: 193.1437\n",
      "Epoch 82/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7411 - val_loss: 193.0234\n",
      "Epoch 83/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4959 - val_loss: 195.2840\n",
      "Epoch 84/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8678 - val_loss: 190.8879\n",
      "Epoch 85/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6928 - val_loss: 195.0682\n",
      "Epoch 86/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5634 - val_loss: 191.4373\n",
      "Epoch 87/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6043 - val_loss: 196.5858\n",
      "Epoch 88/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7994 - val_loss: 192.5455\n",
      "Epoch 89/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.5823 - val_loss: 198.1096\n",
      "Epoch 90/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8328 - val_loss: 193.5363\n",
      "Epoch 91/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9401 - val_loss: 192.3936\n",
      "Epoch 92/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5805 - val_loss: 193.9681\n",
      "Epoch 93/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6165 - val_loss: 194.0297\n",
      "Epoch 94/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7186 - val_loss: 196.1382\n",
      "Epoch 95/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7316 - val_loss: 196.6157\n",
      "Epoch 96/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4173 - val_loss: 194.9765\n",
      "Epoch 97/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8278 - val_loss: 193.4227\n",
      "Epoch 98/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7393 - val_loss: 194.8752\n",
      "Epoch 99/20000\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 70.5833 - val_loss: 191.7638\n",
      "Epoch 100/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.9734 - val_loss: 192.9703\n",
      "Epoch 101/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.8710 - val_loss: 194.3068\n",
      "Epoch 102/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7417 - val_loss: 193.4188\n",
      "Epoch 103/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9497 - val_loss: 193.1865\n",
      "Epoch 104/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7315 - val_loss: 194.0241\n",
      "Epoch 105/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5869 - val_loss: 192.8654\n",
      "Epoch 106/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7952 - val_loss: 192.4531\n",
      "Epoch 107/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6127 - val_loss: 196.4653\n",
      "Epoch 108/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5972 - val_loss: 193.3494\n",
      "Epoch 109/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 71.0884 - val_loss: 194.6587\n",
      "Epoch 110/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.6138 - val_loss: 193.4172\n",
      "Epoch 111/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.8556 - val_loss: 193.0605\n",
      "Epoch 112/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7801 - val_loss: 193.0195\n",
      "Epoch 113/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8668 - val_loss: 192.1896\n",
      "Epoch 114/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.9340 - val_loss: 192.7669\n",
      "Epoch 115/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7988 - val_loss: 193.2010\n",
      "Epoch 116/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7051 - val_loss: 194.5106\n",
      "Epoch 117/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9252 - val_loss: 196.1347\n",
      "Epoch 118/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5383 - val_loss: 190.6222\n",
      "Epoch 119/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6274 - val_loss: 192.8878\n",
      "Epoch 120/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.9470 - val_loss: 192.6672\n",
      "Epoch 121/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5026 - val_loss: 192.9963\n",
      "Epoch 122/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7580 - val_loss: 194.1095\n",
      "Epoch 123/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5940 - val_loss: 192.1308\n",
      "Epoch 124/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6419 - val_loss: 195.0871\n",
      "Epoch 125/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9948 - val_loss: 192.8123\n",
      "Epoch 126/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7420 - val_loss: 191.9266\n",
      "Epoch 127/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9008 - val_loss: 193.5259\n",
      "Epoch 128/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3559 - val_loss: 193.1841\n",
      "Epoch 129/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0091 - val_loss: 196.2144\n",
      "Epoch 130/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8151 - val_loss: 193.9287\n",
      "Epoch 131/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1550 - val_loss: 189.0432\n",
      "Epoch 132/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6388 - val_loss: 191.1438\n",
      "Epoch 133/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8367 - val_loss: 193.1956\n",
      "Epoch 134/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5581 - val_loss: 194.4998\n",
      "Epoch 135/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5742 - val_loss: 190.5535\n",
      "Epoch 136/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5937 - val_loss: 190.3017\n",
      "Epoch 137/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7977 - val_loss: 193.0423\n",
      "Epoch 138/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6706 - val_loss: 192.7416\n",
      "Epoch 139/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7292 - val_loss: 192.2631\n",
      "Epoch 140/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8661 - val_loss: 191.4564\n",
      "Epoch 141/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9661 - val_loss: 192.8145\n",
      "Epoch 142/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5808 - val_loss: 191.5032\n",
      "Epoch 143/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6065 - val_loss: 192.7013\n",
      "Epoch 144/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8582 - val_loss: 192.4429\n",
      "Epoch 145/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6868 - val_loss: 192.8547\n",
      "Epoch 146/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7442 - val_loss: 194.7325\n",
      "Epoch 147/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8113 - val_loss: 196.1157\n",
      "Epoch 148/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8652 - val_loss: 191.3981\n",
      "Epoch 149/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4438 - val_loss: 195.7989\n",
      "Epoch 150/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8382 - val_loss: 191.2115\n",
      "Epoch 151/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7695 - val_loss: 193.6665\n",
      "Epoch 152/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6870 - val_loss: 193.0753\n",
      "Epoch 153/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0810 - val_loss: 193.2742\n",
      "Epoch 154/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5360 - val_loss: 192.5699\n",
      "Epoch 155/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8693 - val_loss: 191.1944\n",
      "Epoch 156/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7294 - val_loss: 194.5334\n",
      "Epoch 157/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9510 - val_loss: 193.0891\n",
      "Epoch 158/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8707 - val_loss: 194.4276\n",
      "Epoch 159/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6552 - val_loss: 193.5333\n",
      "Epoch 160/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8312 - val_loss: 192.0698\n",
      "Epoch 161/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5880 - val_loss: 192.1836\n",
      "Epoch 162/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5968 - val_loss: 191.6401\n",
      "Epoch 163/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7828 - val_loss: 195.3557\n",
      "Epoch 164/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9333 - val_loss: 194.7214\n",
      "Epoch 165/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6163 - val_loss: 192.4179\n",
      "Epoch 166/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5661 - val_loss: 190.4851\n",
      "Epoch 167/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5595 - val_loss: 192.8508\n",
      "Epoch 168/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8265 - val_loss: 191.2885\n",
      "Epoch 169/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6754 - val_loss: 192.1139\n",
      "Epoch 170/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9671 - val_loss: 193.5554\n",
      "Epoch 171/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7633 - val_loss: 198.5320\n",
      "Epoch 172/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.7870 - val_loss: 194.1503\n",
      "Epoch 173/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6571 - val_loss: 192.9423\n",
      "Epoch 174/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.7775 - val_loss: 191.4954\n",
      "Epoch 175/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7410 - val_loss: 192.5718\n",
      "Epoch 176/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7545 - val_loss: 195.5711\n",
      "Epoch 177/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8494 - val_loss: 194.5301\n",
      "Epoch 178/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8180 - val_loss: 193.4312\n",
      "Epoch 179/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7159 - val_loss: 192.6156\n",
      "Epoch 180/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5062 - val_loss: 194.1520\n",
      "Epoch 181/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4755 - val_loss: 195.4705\n",
      "Epoch 182/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7174 - val_loss: 193.4522\n",
      "Epoch 183/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7188 - val_loss: 195.1028\n",
      "Epoch 184/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5611 - val_loss: 192.7649\n",
      "Epoch 185/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7479 - val_loss: 194.1049\n",
      "Epoch 186/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4719 - val_loss: 195.3232\n",
      "Epoch 187/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9797 - val_loss: 191.2711\n",
      "Epoch 188/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6348 - val_loss: 193.0028\n",
      "Epoch 189/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5789 - val_loss: 193.0121\n",
      "Epoch 190/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8734 - val_loss: 195.0689\n",
      "Epoch 191/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.2203 - val_loss: 195.6041\n",
      "Epoch 192/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.3742 - val_loss: 192.3625\n",
      "Epoch 193/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6359 - val_loss: 193.0518\n",
      "Epoch 194/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1493 - val_loss: 191.9092\n",
      "Epoch 195/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9917 - val_loss: 193.2079\n",
      "Epoch 196/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6891 - val_loss: 191.7914\n",
      "Epoch 197/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6703 - val_loss: 190.5752\n",
      "Epoch 198/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3801 - val_loss: 196.0315\n",
      "Epoch 199/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8333 - val_loss: 194.9571\n",
      "Epoch 200/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7371 - val_loss: 192.1690\n",
      "Epoch 201/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6893 - val_loss: 193.8706\n",
      "Epoch 202/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7824 - val_loss: 194.9337\n",
      "Epoch 203/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7258 - val_loss: 193.0916\n",
      "Epoch 204/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7866 - val_loss: 190.9345\n",
      "Epoch 205/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7922 - val_loss: 192.9303\n",
      "Epoch 206/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5264 - val_loss: 193.7487\n",
      "Epoch 207/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8321 - val_loss: 189.5229\n",
      "Epoch 208/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6171 - val_loss: 192.0818\n",
      "Epoch 209/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0630 - val_loss: 191.9465\n",
      "Epoch 210/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6931 - val_loss: 192.3881\n",
      "Epoch 211/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8675 - val_loss: 189.4986\n",
      "Epoch 212/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7960 - val_loss: 193.1813\n",
      "Epoch 213/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7004 - val_loss: 193.5243\n",
      "Epoch 214/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8575 - val_loss: 189.3941\n",
      "Epoch 215/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.9391 - val_loss: 193.3032\n",
      "Epoch 216/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8042 - val_loss: 194.8962\n",
      "Epoch 217/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7403 - val_loss: 192.3482\n",
      "Epoch 218/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7424 - val_loss: 193.1749\n",
      "Epoch 219/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8730 - val_loss: 194.0129\n",
      "Epoch 220/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6938 - val_loss: 193.6704\n",
      "Epoch 221/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6322 - val_loss: 191.5535\n",
      "Epoch 222/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8827 - val_loss: 193.8319\n",
      "Epoch 223/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5528 - val_loss: 190.4491\n",
      "Epoch 224/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7300 - val_loss: 191.7309\n",
      "Epoch 225/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6347 - val_loss: 192.4853\n",
      "Epoch 226/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5572 - val_loss: 198.3509\n",
      "Epoch 227/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7049 - val_loss: 194.8009\n",
      "Epoch 228/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5412 - val_loss: 195.9854\n",
      "Epoch 229/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8343 - val_loss: 196.8901\n",
      "Epoch 230/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9968 - val_loss: 191.7555\n",
      "Epoch 231/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7759 - val_loss: 194.0627\n",
      "Epoch 232/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6481 - val_loss: 193.8813\n",
      "Epoch 233/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1767 - val_loss: 192.4995\n",
      "Epoch 234/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6117 - val_loss: 193.1658\n",
      "Epoch 235/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7792 - val_loss: 194.2342\n",
      "Epoch 236/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9715 - val_loss: 191.5109\n",
      "Epoch 237/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5869 - val_loss: 194.2180\n",
      "Epoch 238/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1089 - val_loss: 193.6111\n",
      "Epoch 239/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6323 - val_loss: 192.0086\n",
      "Epoch 240/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5728 - val_loss: 194.5528\n",
      "Epoch 241/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5347 - val_loss: 193.4685\n",
      "Epoch 242/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0692 - val_loss: 191.0163\n",
      "Epoch 243/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8094 - val_loss: 195.2637\n",
      "Epoch 244/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6408 - val_loss: 193.9061\n",
      "Epoch 245/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5972 - val_loss: 189.9120\n",
      "Epoch 246/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9011 - val_loss: 192.9503\n",
      "Epoch 247/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6817 - val_loss: 190.9505\n",
      "Epoch 248/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7014 - val_loss: 192.4514\n",
      "Epoch 249/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5540 - val_loss: 192.6878\n",
      "Epoch 250/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0139 - val_loss: 193.8002\n",
      "Epoch 251/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6904 - val_loss: 192.4717\n",
      "Epoch 252/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8065 - val_loss: 192.7982\n",
      "Epoch 253/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5868 - val_loss: 192.7671\n",
      "Epoch 254/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8384 - val_loss: 194.1445\n",
      "Epoch 255/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7863 - val_loss: 192.7937\n",
      "Epoch 256/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7748 - val_loss: 191.9346\n",
      "Epoch 257/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6711 - val_loss: 191.1807\n",
      "Epoch 258/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9016 - val_loss: 194.1360\n",
      "Epoch 259/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4522 - val_loss: 192.5991\n",
      "Epoch 260/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7384 - val_loss: 192.0304\n",
      "Epoch 261/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8052 - val_loss: 192.1949\n",
      "Epoch 262/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7705 - val_loss: 193.2536\n",
      "Epoch 263/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8261 - val_loss: 193.8409\n",
      "Epoch 264/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6969 - val_loss: 192.0403\n",
      "Epoch 265/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5506 - val_loss: 192.0941\n",
      "Epoch 266/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7081 - val_loss: 190.2447\n",
      "Epoch 267/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6136 - val_loss: 192.1022\n",
      "Epoch 268/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6717 - val_loss: 192.2093\n",
      "Epoch 269/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7856 - val_loss: 194.0088\n",
      "Epoch 270/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7467 - val_loss: 190.3510\n",
      "Epoch 271/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6647 - val_loss: 194.7542\n",
      "Epoch 272/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9308 - val_loss: 193.2472\n",
      "Epoch 273/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0543 - val_loss: 194.2594\n",
      "Epoch 274/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6901 - val_loss: 194.3153\n",
      "Epoch 275/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5759 - val_loss: 194.2322\n",
      "Epoch 276/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7414 - val_loss: 196.4304\n",
      "Epoch 277/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3933 - val_loss: 189.6088\n",
      "Epoch 278/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7686 - val_loss: 192.8599\n",
      "Epoch 279/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6844 - val_loss: 192.0328\n",
      "Epoch 280/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8760 - val_loss: 193.6348\n",
      "Epoch 281/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7929 - val_loss: 194.1573\n",
      "Epoch 282/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8217 - val_loss: 194.8443\n",
      "Epoch 283/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6029 - val_loss: 194.9952\n",
      "Epoch 284/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8919 - val_loss: 193.1988\n",
      "Epoch 285/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5369 - val_loss: 192.8535\n",
      "Epoch 286/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3255 - val_loss: 191.8464\n",
      "Epoch 287/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5997 - val_loss: 191.5772\n",
      "Epoch 288/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6054 - val_loss: 191.9472\n",
      "Epoch 289/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8533 - val_loss: 195.7940\n",
      "Epoch 290/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6424 - val_loss: 191.9309\n",
      "Epoch 291/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5614 - val_loss: 193.7675\n",
      "Epoch 292/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9652 - val_loss: 193.8250\n",
      "Epoch 293/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1163 - val_loss: 193.9217\n",
      "Epoch 294/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6519 - val_loss: 194.9794\n",
      "Epoch 295/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5354 - val_loss: 196.5787\n",
      "Epoch 296/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6663 - val_loss: 196.8066\n",
      "Epoch 297/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6854 - val_loss: 192.9942\n",
      "Epoch 298/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6798 - val_loss: 196.0668\n",
      "Epoch 299/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6687 - val_loss: 193.3639\n",
      "Epoch 300/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4163 - val_loss: 194.4212\n",
      "Epoch 301/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0745 - val_loss: 196.5379\n",
      "Epoch 302/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7413 - val_loss: 193.3975\n",
      "Epoch 303/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9539 - val_loss: 193.5160\n",
      "Epoch 304/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6796 - val_loss: 191.6489\n",
      "Epoch 305/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7040 - val_loss: 190.6201\n",
      "Epoch 306/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8031 - val_loss: 191.3566\n",
      "Epoch 307/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6130 - val_loss: 191.4870\n",
      "Epoch 308/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7016 - val_loss: 194.2835\n",
      "Epoch 309/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9002 - val_loss: 192.7718\n",
      "Epoch 310/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5036 - val_loss: 195.0286\n",
      "Epoch 311/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8578 - val_loss: 195.6824\n",
      "Epoch 312/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7704 - val_loss: 192.4254\n",
      "Epoch 313/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8295 - val_loss: 194.0473\n",
      "Epoch 314/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.4504 - val_loss: 192.9688\n",
      "Epoch 315/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6502 - val_loss: 191.3343\n",
      "Epoch 316/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6811 - val_loss: 191.0134\n",
      "Epoch 317/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.3173 - val_loss: 194.5932\n",
      "Epoch 318/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6390 - val_loss: 195.0048\n",
      "Epoch 319/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8352 - val_loss: 192.1080\n",
      "Epoch 320/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6943 - val_loss: 192.0627\n",
      "Epoch 321/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5266 - val_loss: 192.6721\n",
      "Epoch 322/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8958 - val_loss: 194.0210\n",
      "Epoch 323/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6324 - val_loss: 192.9178\n",
      "Epoch 324/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7658 - val_loss: 191.3777\n",
      "Epoch 325/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0365 - val_loss: 193.6829\n",
      "Epoch 326/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.2786 - val_loss: 191.0182\n",
      "Epoch 327/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8889 - val_loss: 193.1857\n",
      "Epoch 328/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5600 - val_loss: 195.0360\n",
      "Epoch 329/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7667 - val_loss: 194.6522\n",
      "Epoch 330/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.3938 - val_loss: 192.1962\n",
      "Epoch 331/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9924 - val_loss: 192.2275\n",
      "Epoch 332/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7015 - val_loss: 195.0544\n",
      "Epoch 333/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4978 - val_loss: 190.4850\n",
      "Epoch 334/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9349 - val_loss: 192.1515\n",
      "Epoch 335/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9756 - val_loss: 191.4922\n",
      "Epoch 336/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8038 - val_loss: 191.5286\n",
      "Epoch 337/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9493 - val_loss: 191.5955\n",
      "Epoch 338/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5905 - val_loss: 192.1545\n",
      "Epoch 339/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6368 - val_loss: 192.1292\n",
      "Epoch 340/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8536 - val_loss: 190.9080\n",
      "Epoch 341/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8552 - val_loss: 191.4851\n",
      "Epoch 342/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5608 - val_loss: 194.1556\n",
      "Epoch 343/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5908 - val_loss: 192.2552\n",
      "Epoch 344/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6521 - val_loss: 193.1711\n",
      "Epoch 345/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6233 - val_loss: 193.1747\n",
      "Epoch 346/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5535 - val_loss: 193.5740\n",
      "Epoch 347/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8485 - val_loss: 190.2661\n",
      "Epoch 348/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7544 - val_loss: 192.1437\n",
      "Epoch 349/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7198 - val_loss: 193.4049\n",
      "Epoch 350/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8445 - val_loss: 190.1609\n",
      "Epoch 351/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5983 - val_loss: 192.9352\n",
      "Epoch 352/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8992 - val_loss: 192.9211\n",
      "Epoch 353/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5090 - val_loss: 190.7727\n",
      "Epoch 354/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9054 - val_loss: 192.8173\n",
      "Epoch 355/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7148 - val_loss: 193.0541\n",
      "Epoch 356/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7519 - val_loss: 191.9066\n",
      "Epoch 357/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5551 - val_loss: 194.1076\n",
      "Epoch 358/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7750 - val_loss: 192.8965\n",
      "Epoch 359/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6519 - val_loss: 194.2215\n",
      "Epoch 360/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4902 - val_loss: 193.8699\n",
      "Epoch 361/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3890 - val_loss: 196.2196\n",
      "Epoch 362/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8392 - val_loss: 193.8844\n",
      "Epoch 363/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8656 - val_loss: 193.8943\n",
      "Epoch 364/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7838 - val_loss: 192.8940\n",
      "Epoch 365/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7120 - val_loss: 196.6952\n",
      "Epoch 366/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4587 - val_loss: 193.6101\n",
      "Epoch 367/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7877 - val_loss: 192.3850\n",
      "Epoch 368/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6942 - val_loss: 189.2781\n",
      "Epoch 369/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7578 - val_loss: 193.7599\n",
      "Epoch 370/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7763 - val_loss: 191.7775\n",
      "Epoch 371/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6478 - val_loss: 192.6883\n",
      "Epoch 372/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6321 - val_loss: 194.6068\n",
      "Epoch 373/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6233 - val_loss: 193.3447\n",
      "Epoch 374/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6691 - val_loss: 200.1371\n",
      "Epoch 375/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7345 - val_loss: 193.5208\n",
      "Epoch 376/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7421 - val_loss: 192.7706\n",
      "Epoch 377/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7054 - val_loss: 191.4964\n",
      "Epoch 378/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0184 - val_loss: 191.0057\n",
      "Epoch 379/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6176 - val_loss: 195.5747\n",
      "Epoch 380/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7431 - val_loss: 193.0142\n",
      "Epoch 381/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3283 - val_loss: 192.2608\n",
      "Epoch 382/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7449 - val_loss: 195.3149\n",
      "Epoch 383/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5667 - val_loss: 194.3167\n",
      "Epoch 384/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9137 - val_loss: 195.7846\n",
      "Epoch 385/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9704 - val_loss: 192.0262\n",
      "Epoch 386/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8776 - val_loss: 193.3433\n",
      "Epoch 387/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7199 - val_loss: 190.3274\n",
      "Epoch 388/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8921 - val_loss: 194.3277\n",
      "Epoch 389/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5705 - val_loss: 193.6174\n",
      "Epoch 390/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8128 - val_loss: 190.2757\n",
      "Epoch 391/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7130 - val_loss: 192.3854\n",
      "Epoch 392/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5727 - val_loss: 192.1439\n",
      "Epoch 393/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6093 - val_loss: 195.9090\n",
      "Epoch 394/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5978 - val_loss: 195.1178\n",
      "Epoch 395/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7353 - val_loss: 194.5691\n",
      "Epoch 396/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8840 - val_loss: 190.5481\n",
      "Epoch 397/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8710 - val_loss: 193.6562\n",
      "Epoch 398/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6050 - val_loss: 194.9737\n",
      "Epoch 399/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.3471 - val_loss: 193.7420\n",
      "Epoch 400/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6385 - val_loss: 194.2462\n",
      "Epoch 401/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9882 - val_loss: 191.2599\n",
      "Epoch 402/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4581 - val_loss: 192.4506\n",
      "Epoch 403/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5463 - val_loss: 193.4121\n",
      "Epoch 404/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6411 - val_loss: 194.7294\n",
      "Epoch 405/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6021 - val_loss: 191.8647\n",
      "Epoch 406/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5090 - val_loss: 191.5553\n",
      "Epoch 407/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7165 - val_loss: 194.5671\n",
      "Epoch 408/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0376 - val_loss: 194.0442\n",
      "Epoch 409/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9433 - val_loss: 193.9402\n",
      "Epoch 410/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8970 - val_loss: 191.3140\n",
      "Epoch 411/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.4411 - val_loss: 192.3957\n",
      "Epoch 412/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8391 - val_loss: 195.0727\n",
      "Epoch 413/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6115 - val_loss: 194.1584\n",
      "Epoch 414/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1460 - val_loss: 192.2850\n",
      "Epoch 415/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8721 - val_loss: 192.6372\n",
      "Epoch 416/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1398 - val_loss: 194.6903\n",
      "Epoch 417/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7934 - val_loss: 194.8158\n",
      "Epoch 418/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0541 - val_loss: 192.7350\n",
      "Epoch 419/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6300 - val_loss: 191.5760\n",
      "Epoch 420/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9398 - val_loss: 196.8712\n",
      "Epoch 421/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8493 - val_loss: 191.1450\n",
      "Epoch 422/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4785 - val_loss: 195.1973\n",
      "Epoch 423/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7721 - val_loss: 191.6878\n",
      "Epoch 424/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5121 - val_loss: 193.9496\n",
      "Epoch 425/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8049 - val_loss: 193.2273\n",
      "Epoch 426/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6255 - val_loss: 196.9534\n",
      "Epoch 427/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9702 - val_loss: 192.8670\n",
      "Epoch 428/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5917 - val_loss: 194.7769\n",
      "Epoch 429/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8003 - val_loss: 195.0208\n",
      "Epoch 430/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.2444 - val_loss: 194.2019\n",
      "Epoch 431/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7258 - val_loss: 193.4014\n",
      "Epoch 432/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5412 - val_loss: 192.9067\n",
      "Epoch 433/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6732 - val_loss: 192.9070\n",
      "Epoch 434/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7377 - val_loss: 195.6203\n",
      "Epoch 435/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6765 - val_loss: 191.6561\n",
      "Epoch 436/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8632 - val_loss: 191.9770\n",
      "Epoch 437/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5036 - val_loss: 193.7347\n",
      "Epoch 438/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9849 - val_loss: 194.1511\n",
      "Epoch 439/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8049 - val_loss: 196.1003\n",
      "Epoch 440/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7536 - val_loss: 192.1613\n",
      "Epoch 441/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9745 - val_loss: 191.9663\n",
      "Epoch 442/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6834 - val_loss: 192.0632\n",
      "Epoch 443/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8920 - val_loss: 192.7080\n",
      "Epoch 444/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7044 - val_loss: 194.7830\n",
      "Epoch 445/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3473 - val_loss: 194.6446\n",
      "Epoch 446/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9854 - val_loss: 192.8082\n",
      "Epoch 447/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8648 - val_loss: 194.0469\n",
      "Epoch 448/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9375 - val_loss: 194.1267\n",
      "Epoch 449/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7914 - val_loss: 192.2660\n",
      "Epoch 450/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8761 - val_loss: 193.3418\n",
      "Epoch 451/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6300 - val_loss: 193.6336\n",
      "Epoch 452/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7120 - val_loss: 193.0674\n",
      "Epoch 453/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7990 - val_loss: 191.1950\n",
      "Epoch 454/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9328 - val_loss: 193.0607\n",
      "Epoch 455/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5887 - val_loss: 191.8708\n",
      "Epoch 456/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5934 - val_loss: 194.3863\n",
      "Epoch 457/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7542 - val_loss: 191.8636\n",
      "Epoch 458/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6104 - val_loss: 191.0441\n",
      "Epoch 459/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8758 - val_loss: 193.9989\n",
      "Epoch 460/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5973 - val_loss: 192.4482\n",
      "Epoch 461/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4846 - val_loss: 190.5423\n",
      "Epoch 462/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5229 - val_loss: 196.1257\n",
      "Epoch 463/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5505 - val_loss: 193.7104\n",
      "Epoch 464/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6458 - val_loss: 195.2087\n",
      "Epoch 465/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6373 - val_loss: 191.3880\n",
      "Epoch 466/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7329 - val_loss: 196.0118\n",
      "Epoch 467/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6255 - val_loss: 194.9457\n",
      "Epoch 468/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7943 - val_loss: 196.0182\n",
      "Epoch 469/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7602 - val_loss: 194.0815\n",
      "Epoch 470/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7222 - val_loss: 192.4726\n",
      "Epoch 471/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8021 - val_loss: 193.8718\n",
      "Epoch 472/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6706 - val_loss: 193.7712\n",
      "Epoch 473/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6356 - val_loss: 193.6776\n",
      "Epoch 474/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5752 - val_loss: 194.2511\n",
      "Epoch 475/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7547 - val_loss: 191.7752\n",
      "Epoch 476/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8195 - val_loss: 196.2547\n",
      "Epoch 477/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7937 - val_loss: 193.7527\n",
      "Epoch 478/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6377 - val_loss: 193.2728\n",
      "Epoch 479/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6687 - val_loss: 192.9262\n",
      "Epoch 480/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8677 - val_loss: 197.4185\n",
      "Epoch 481/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4221 - val_loss: 194.3466\n",
      "Epoch 482/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7460 - val_loss: 195.3279\n",
      "Epoch 483/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8445 - val_loss: 195.7745\n",
      "Epoch 484/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9520 - val_loss: 195.1306\n",
      "Epoch 485/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5431 - val_loss: 194.0488\n",
      "Epoch 486/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6570 - val_loss: 194.7400\n",
      "Epoch 487/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4848 - val_loss: 194.0977\n",
      "Epoch 488/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7095 - val_loss: 193.3564\n",
      "Epoch 489/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7679 - val_loss: 192.9522\n",
      "Epoch 490/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6370 - val_loss: 192.6654\n",
      "Epoch 491/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0009 - val_loss: 191.1409\n",
      "Epoch 492/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8442 - val_loss: 191.4175\n",
      "Epoch 493/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8969 - val_loss: 193.2926\n",
      "Epoch 494/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6972 - val_loss: 193.1987\n",
      "Epoch 495/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5216 - val_loss: 193.1414\n",
      "Epoch 496/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5592 - val_loss: 192.9984\n",
      "Epoch 497/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6768 - val_loss: 193.1740\n",
      "Epoch 498/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7266 - val_loss: 192.5643\n",
      "Epoch 499/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.4339 - val_loss: 193.4298\n",
      "Epoch 500/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5445 - val_loss: 192.8347\n",
      "Epoch 501/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3295 - val_loss: 195.4415\n",
      "Epoch 502/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6771 - val_loss: 192.8872\n",
      "Epoch 503/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6111 - val_loss: 195.7760\n",
      "Epoch 504/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6395 - val_loss: 194.2768\n",
      "Epoch 505/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6691 - val_loss: 193.0701\n",
      "Epoch 506/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8083 - val_loss: 192.6135\n",
      "Epoch 507/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4535 - val_loss: 195.6679\n",
      "Epoch 508/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8390 - val_loss: 192.0133\n",
      "Epoch 509/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8398 - val_loss: 190.5179\n",
      "Epoch 510/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5603 - val_loss: 192.6417\n",
      "Epoch 511/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5536 - val_loss: 191.4684\n",
      "Epoch 512/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0082 - val_loss: 194.3761\n",
      "Epoch 513/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6553 - val_loss: 193.1718\n",
      "Epoch 514/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6277 - val_loss: 194.5577\n",
      "Epoch 515/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5381 - val_loss: 192.0384\n",
      "Epoch 516/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9417 - val_loss: 194.3384\n",
      "Epoch 517/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5455 - val_loss: 194.9142\n",
      "Epoch 518/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6331 - val_loss: 194.8933\n",
      "Epoch 519/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6917 - val_loss: 192.6189\n",
      "Epoch 520/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7313 - val_loss: 195.4922\n",
      "Epoch 521/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7858 - val_loss: 194.0291\n",
      "Epoch 522/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8168 - val_loss: 191.9742\n",
      "Epoch 523/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8146 - val_loss: 194.4836\n",
      "Epoch 524/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7478 - val_loss: 194.5400\n",
      "Epoch 525/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9999 - val_loss: 193.4544\n",
      "Epoch 526/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5973 - val_loss: 191.3722\n",
      "Epoch 527/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8704 - val_loss: 191.9727\n",
      "Epoch 528/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.2398 - val_loss: 191.5585\n",
      "Epoch 529/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4495 - val_loss: 193.8027\n",
      "Epoch 530/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8250 - val_loss: 194.8355\n",
      "Epoch 531/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5664 - val_loss: 193.0692\n",
      "Epoch 532/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3627 - val_loss: 194.5763\n",
      "Epoch 533/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8447 - val_loss: 191.8161\n",
      "Epoch 534/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9464 - val_loss: 192.2900\n",
      "Epoch 535/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7336 - val_loss: 195.0831\n",
      "Epoch 536/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7498 - val_loss: 194.4486\n",
      "Epoch 537/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7125 - val_loss: 193.1879\n",
      "Epoch 538/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9554 - val_loss: 193.5467\n",
      "Epoch 539/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6300 - val_loss: 192.6585\n",
      "Epoch 540/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7747 - val_loss: 196.3607\n",
      "Epoch 541/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6951 - val_loss: 194.0625\n",
      "Epoch 542/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6146 - val_loss: 194.9028\n",
      "Epoch 543/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7830 - val_loss: 194.3847\n",
      "Epoch 544/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8168 - val_loss: 195.0976\n",
      "Epoch 545/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4766 - val_loss: 195.5493\n",
      "Epoch 546/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5353 - val_loss: 193.3248\n",
      "Epoch 547/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4290 - val_loss: 193.8365\n",
      "Epoch 548/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9125 - val_loss: 192.5840\n",
      "Epoch 549/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0032 - val_loss: 194.8883\n",
      "Epoch 550/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5771 - val_loss: 193.5111\n",
      "Epoch 551/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8326 - val_loss: 192.1106\n",
      "Epoch 552/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8108 - val_loss: 191.7742\n",
      "Epoch 553/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7058 - val_loss: 194.1060\n",
      "Epoch 554/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7089 - val_loss: 193.3523\n",
      "Epoch 555/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0589 - val_loss: 191.9579\n",
      "Epoch 556/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8344 - val_loss: 193.4397\n",
      "Epoch 557/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6538 - val_loss: 190.4747\n",
      "Epoch 558/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6634 - val_loss: 192.9199\n",
      "Epoch 559/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0746 - val_loss: 194.4242\n",
      "Epoch 560/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6285 - val_loss: 193.4748\n",
      "Epoch 561/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5495 - val_loss: 194.2772\n",
      "Epoch 562/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6282 - val_loss: 191.5770\n",
      "Epoch 563/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7710 - val_loss: 193.6257\n",
      "Epoch 564/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7642 - val_loss: 193.5703\n",
      "Epoch 565/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6483 - val_loss: 192.3299\n",
      "Epoch 566/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8445 - val_loss: 193.5269\n",
      "Epoch 567/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.98 - 1s 31us/sample - loss: 70.8264 - val_loss: 192.5426\n",
      "Epoch 568/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5041 - val_loss: 193.0693\n",
      "Epoch 569/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7673 - val_loss: 191.5651\n",
      "Epoch 570/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8200 - val_loss: 192.0539\n",
      "Epoch 571/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6332 - val_loss: 195.4297\n",
      "Epoch 572/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7230 - val_loss: 191.5720\n",
      "Epoch 573/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7902 - val_loss: 193.0394\n",
      "Epoch 574/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7764 - val_loss: 192.9927\n",
      "Epoch 575/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7055 - val_loss: 191.6779\n",
      "Epoch 576/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7574 - val_loss: 197.2067\n",
      "Epoch 577/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6916 - val_loss: 192.1527\n",
      "Epoch 578/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8151 - val_loss: 192.3424\n",
      "Epoch 579/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7782 - val_loss: 191.2089\n",
      "Epoch 580/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8983 - val_loss: 195.2697\n",
      "Epoch 581/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7946 - val_loss: 194.7250\n",
      "Epoch 582/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7188 - val_loss: 192.5904\n",
      "Epoch 583/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5298 - val_loss: 190.9848\n",
      "Epoch 584/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6787 - val_loss: 194.6564\n",
      "Epoch 585/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7594 - val_loss: 191.9613\n",
      "Epoch 586/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7817 - val_loss: 192.0371\n",
      "Epoch 587/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7627 - val_loss: 194.6872\n",
      "Epoch 588/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5463 - val_loss: 194.5893\n",
      "Epoch 589/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5317 - val_loss: 193.7975\n",
      "Epoch 590/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8638 - val_loss: 193.7914\n",
      "Epoch 591/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8348 - val_loss: 193.2712\n",
      "Epoch 592/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5315 - val_loss: 192.5409\n",
      "Epoch 593/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4923 - val_loss: 194.6795\n",
      "Epoch 594/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8297 - val_loss: 188.8510\n",
      "Epoch 595/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8114 - val_loss: 190.8662\n",
      "Epoch 596/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6071 - val_loss: 192.7494\n",
      "Epoch 597/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8183 - val_loss: 195.5435\n",
      "Epoch 598/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5869 - val_loss: 193.7255\n",
      "Epoch 599/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6261 - val_loss: 192.5098\n",
      "Epoch 600/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5321 - val_loss: 196.5179\n",
      "Epoch 601/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8438 - val_loss: 193.3052\n",
      "Epoch 602/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6904 - val_loss: 190.5643\n",
      "Epoch 603/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7799 - val_loss: 195.7008\n",
      "Epoch 604/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5430 - val_loss: 193.0655\n",
      "Epoch 605/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5212 - val_loss: 194.3176\n",
      "Epoch 606/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6913 - val_loss: 192.0750\n",
      "Epoch 607/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0098 - val_loss: 190.9850\n",
      "Epoch 608/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8659 - val_loss: 194.7772\n",
      "Epoch 609/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4066 - val_loss: 194.4525\n",
      "Epoch 610/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8577 - val_loss: 194.1293\n",
      "Epoch 611/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7169 - val_loss: 194.9029\n",
      "Epoch 612/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9878 - val_loss: 194.2191\n",
      "Epoch 613/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5439 - val_loss: 195.4459\n",
      "Epoch 614/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8321 - val_loss: 191.9362\n",
      "Epoch 615/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6709 - val_loss: 192.7268\n",
      "Epoch 616/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8390 - val_loss: 191.2990\n",
      "Epoch 617/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5512 - val_loss: 194.1916\n",
      "Epoch 618/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6357 - val_loss: 195.7576\n",
      "Epoch 619/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8040 - val_loss: 192.2439\n",
      "Epoch 620/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8145 - val_loss: 193.0693\n",
      "Epoch 621/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6898 - val_loss: 193.3394\n",
      "Epoch 622/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6446 - val_loss: 192.0951\n",
      "Epoch 623/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4814 - val_loss: 194.3874\n",
      "Epoch 624/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1357 - val_loss: 190.6411\n",
      "Epoch 625/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6875 - val_loss: 193.5996\n",
      "Epoch 626/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1190 - val_loss: 193.3808\n",
      "Epoch 627/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5308 - val_loss: 191.5651\n",
      "Epoch 628/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9068 - val_loss: 194.6538\n",
      "Epoch 629/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6168 - val_loss: 191.1697\n",
      "Epoch 630/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0281 - val_loss: 193.1849\n",
      "Epoch 631/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7763 - val_loss: 195.1753\n",
      "Epoch 632/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8970 - val_loss: 192.4483\n",
      "Epoch 633/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7198 - val_loss: 192.2942\n",
      "Epoch 634/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8049 - val_loss: 192.0699\n",
      "Epoch 635/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7501 - val_loss: 193.9386\n",
      "Epoch 636/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6284 - val_loss: 195.5429\n",
      "Epoch 637/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5791 - val_loss: 194.7985\n",
      "Epoch 638/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9457 - val_loss: 192.5580\n",
      "Epoch 639/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9784 - val_loss: 194.4844\n",
      "Epoch 640/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7186 - val_loss: 195.1462\n",
      "Epoch 641/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0712 - val_loss: 190.5150\n",
      "Epoch 642/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8637 - val_loss: 194.3057\n",
      "Epoch 643/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8012 - val_loss: 194.4809\n",
      "Epoch 644/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6509 - val_loss: 193.2937\n",
      "Epoch 645/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7197 - val_loss: 192.9583\n",
      "Epoch 646/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7157 - val_loss: 193.2216\n",
      "Epoch 647/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5944 - val_loss: 192.1119\n",
      "Epoch 648/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8941 - val_loss: 193.5903\n",
      "Epoch 649/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8138 - val_loss: 192.3667\n",
      "Epoch 650/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7408 - val_loss: 194.1440\n",
      "Epoch 651/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5192 - val_loss: 197.0003\n",
      "Epoch 652/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7513 - val_loss: 194.8367\n",
      "Epoch 653/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6411 - val_loss: 191.4032\n",
      "Epoch 654/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8449 - val_loss: 192.0439\n",
      "Epoch 655/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7315 - val_loss: 193.6682\n",
      "Epoch 656/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8656 - val_loss: 195.1989\n",
      "Epoch 657/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5045 - val_loss: 193.5555\n",
      "Epoch 658/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7398 - val_loss: 193.7158\n",
      "Epoch 659/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7434 - val_loss: 188.6439\n",
      "Epoch 660/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1278 - val_loss: 193.7583\n",
      "Epoch 661/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5467 - val_loss: 192.8135\n",
      "Epoch 662/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.2783 - val_loss: 193.5088\n",
      "Epoch 663/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8685 - val_loss: 192.8319\n",
      "Epoch 664/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4493 - val_loss: 195.0213\n",
      "Epoch 665/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6150 - val_loss: 190.3678\n",
      "Epoch 666/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1235 - val_loss: 192.5607\n",
      "Epoch 667/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7378 - val_loss: 194.0250\n",
      "Epoch 668/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5530 - val_loss: 195.0732\n",
      "Epoch 669/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8096 - val_loss: 189.0350\n",
      "Epoch 670/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7954 - val_loss: 190.3984\n",
      "Epoch 671/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5987 - val_loss: 193.8111\n",
      "Epoch 672/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6810 - val_loss: 193.0276\n",
      "Epoch 673/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6908 - val_loss: 193.7466\n",
      "Epoch 674/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5634 - val_loss: 194.5248\n",
      "Epoch 675/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8318 - val_loss: 195.8363\n",
      "Epoch 676/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7113 - val_loss: 196.0240\n",
      "Epoch 677/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9819 - val_loss: 191.4258\n",
      "Epoch 678/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4010 - val_loss: 193.5309\n",
      "Epoch 679/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4935 - val_loss: 192.9650\n",
      "Epoch 680/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6690 - val_loss: 194.8531\n",
      "Epoch 681/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6571 - val_loss: 195.1449\n",
      "Epoch 682/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6547 - val_loss: 194.6038\n",
      "Epoch 683/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8290 - val_loss: 194.4210\n",
      "Epoch 684/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5009 - val_loss: 191.7830\n",
      "Epoch 685/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9204 - val_loss: 192.2755\n",
      "Epoch 686/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5950 - val_loss: 194.0659\n",
      "Epoch 687/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0701 - val_loss: 194.3811\n",
      "Epoch 688/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6789 - val_loss: 193.1281\n",
      "Epoch 689/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7268 - val_loss: 191.1536\n",
      "Epoch 690/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7769 - val_loss: 193.9142\n",
      "Epoch 691/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6436 - val_loss: 194.9641\n",
      "Epoch 692/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7235 - val_loss: 192.9059\n",
      "Epoch 693/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5496 - val_loss: 195.5011\n",
      "Epoch 694/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9117 - val_loss: 193.0079\n",
      "Epoch 695/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8561 - val_loss: 193.2075\n",
      "Epoch 696/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5708 - val_loss: 193.0835\n",
      "Epoch 697/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7151 - val_loss: 193.6728\n",
      "Epoch 698/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7421 - val_loss: 192.7865\n",
      "Epoch 699/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0648 - val_loss: 192.2917\n",
      "Epoch 700/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7680 - val_loss: 194.3641\n",
      "Epoch 701/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5353 - val_loss: 193.7753\n",
      "Epoch 702/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6579 - val_loss: 194.2479\n",
      "Epoch 703/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6033 - val_loss: 193.3105\n",
      "Epoch 704/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9286 - val_loss: 192.5332\n",
      "Epoch 705/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7636 - val_loss: 192.3387\n",
      "Epoch 706/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7171 - val_loss: 195.5188\n",
      "Epoch 707/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7516 - val_loss: 190.8871\n",
      "Epoch 708/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6773 - val_loss: 192.0949\n",
      "Epoch 709/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8598 - val_loss: 194.0972\n",
      "Epoch 710/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8388 - val_loss: 193.3321\n",
      "Epoch 711/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5753 - val_loss: 197.9358\n",
      "Epoch 712/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6566 - val_loss: 193.0944\n",
      "Epoch 713/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6479 - val_loss: 192.4641\n",
      "Epoch 714/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8113 - val_loss: 191.4754\n",
      "Epoch 715/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3255 - val_loss: 193.5560\n",
      "Epoch 716/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5814 - val_loss: 191.1053\n",
      "Epoch 717/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5885 - val_loss: 194.5257\n",
      "Epoch 718/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7595 - val_loss: 193.5235\n",
      "Epoch 719/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7807 - val_loss: 192.1640\n",
      "Epoch 720/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6432 - val_loss: 193.6066\n",
      "Epoch 721/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6318 - val_loss: 195.7249\n",
      "Epoch 722/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9351 - val_loss: 191.8085\n",
      "Epoch 723/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8064 - val_loss: 192.1991\n",
      "Epoch 724/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3792 - val_loss: 193.9135\n",
      "Epoch 725/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6376 - val_loss: 191.1865\n",
      "Epoch 726/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9326 - val_loss: 194.3454\n",
      "Epoch 727/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8107 - val_loss: 195.0454\n",
      "Epoch 728/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6349 - val_loss: 192.7569\n",
      "Epoch 729/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7271 - val_loss: 192.2607\n",
      "Epoch 730/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4881 - val_loss: 194.2673\n",
      "Epoch 731/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6443 - val_loss: 194.6614\n",
      "Epoch 732/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8876 - val_loss: 191.7688\n",
      "Epoch 733/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8697 - val_loss: 193.4923\n",
      "Epoch 734/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6580 - val_loss: 192.1312\n",
      "Epoch 735/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6146 - val_loss: 194.1728\n",
      "Epoch 736/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5698 - val_loss: 194.7461\n",
      "Epoch 737/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4842 - val_loss: 192.6350\n",
      "Epoch 738/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7728 - val_loss: 192.6408\n",
      "Epoch 739/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7276 - val_loss: 192.6628\n",
      "Epoch 740/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6597 - val_loss: 194.8353\n",
      "Epoch 741/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6846 - val_loss: 193.1488\n",
      "Epoch 742/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5966 - val_loss: 193.6542\n",
      "Epoch 743/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7054 - val_loss: 194.3069\n",
      "Epoch 744/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4811 - val_loss: 192.5401\n",
      "Epoch 745/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6591 - val_loss: 195.7204\n",
      "Epoch 746/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5147 - val_loss: 196.4385\n",
      "Epoch 747/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8017 - val_loss: 191.3319\n",
      "Epoch 748/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5183 - val_loss: 195.0295\n",
      "Epoch 749/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7571 - val_loss: 192.1712\n",
      "Epoch 750/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0383 - val_loss: 193.9633\n",
      "Epoch 751/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8181 - val_loss: 196.8286\n",
      "Epoch 752/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6711 - val_loss: 195.2600\n",
      "Epoch 753/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5935 - val_loss: 191.5541\n",
      "Epoch 754/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8095 - val_loss: 193.7525\n",
      "Epoch 755/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5636 - val_loss: 193.4911\n",
      "Epoch 756/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8039 - val_loss: 192.8258\n",
      "Epoch 757/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8563 - val_loss: 191.5983\n",
      "Epoch 758/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0581 - val_loss: 194.8356\n",
      "Epoch 759/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6378 - val_loss: 193.8351\n",
      "Epoch 760/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5534 - val_loss: 192.5558\n",
      "Epoch 761/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6328 - val_loss: 192.4897\n",
      "Epoch 762/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6680 - val_loss: 192.6395\n",
      "Epoch 763/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7616 - val_loss: 192.9282\n",
      "Epoch 764/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5228 - val_loss: 196.0174\n",
      "Epoch 765/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6367 - val_loss: 193.3109\n",
      "Epoch 766/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7699 - val_loss: 191.4623\n",
      "Epoch 767/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8341 - val_loss: 190.9514\n",
      "Epoch 768/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6413 - val_loss: 193.1246\n",
      "Epoch 769/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6940 - val_loss: 192.5586\n",
      "Epoch 770/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5745 - val_loss: 193.7567\n",
      "Epoch 771/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6481 - val_loss: 195.1330\n",
      "Epoch 772/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7357 - val_loss: 193.6661\n",
      "Epoch 773/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7124 - val_loss: 193.0740\n",
      "Epoch 774/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7774 - val_loss: 195.0456\n",
      "Epoch 775/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8499 - val_loss: 193.4183\n",
      "Epoch 776/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9568 - val_loss: 192.3260\n",
      "Epoch 777/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.2692 - val_loss: 194.0722\n",
      "Epoch 778/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0311 - val_loss: 193.5063\n",
      "Epoch 779/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9115 - val_loss: 195.3315\n",
      "Epoch 780/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7715 - val_loss: 193.9532\n",
      "Epoch 781/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6411 - val_loss: 192.8898\n",
      "Epoch 782/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9956 - val_loss: 191.4483\n",
      "Epoch 783/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8516 - val_loss: 194.4188\n",
      "Epoch 784/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7626 - val_loss: 195.0415\n",
      "Epoch 785/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7301 - val_loss: 193.7920\n",
      "Epoch 786/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7045 - val_loss: 195.7854\n",
      "Epoch 787/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7065 - val_loss: 194.1862\n",
      "Epoch 788/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5012 - val_loss: 192.1294\n",
      "Epoch 789/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6027 - val_loss: 189.4887\n",
      "Epoch 790/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7903 - val_loss: 192.5490\n",
      "Epoch 791/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8763 - val_loss: 195.0896\n",
      "Epoch 792/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8401 - val_loss: 193.3665\n",
      "Epoch 793/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9575 - val_loss: 193.0243\n",
      "Epoch 794/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5297 - val_loss: 194.4067\n",
      "Epoch 795/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5330 - val_loss: 194.4269\n",
      "Epoch 796/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7483 - val_loss: 194.9123\n",
      "Epoch 797/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5027 - val_loss: 191.3726\n",
      "Epoch 798/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9269 - val_loss: 189.5472\n",
      "Epoch 799/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8276 - val_loss: 194.5925\n",
      "Epoch 800/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9052 - val_loss: 193.4286\n",
      "Epoch 801/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6413 - val_loss: 193.6872\n",
      "Epoch 802/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9112 - val_loss: 192.5747\n",
      "Epoch 803/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6996 - val_loss: 192.2187\n",
      "Epoch 804/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5354 - val_loss: 192.4139\n",
      "Epoch 805/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6341 - val_loss: 195.0080\n",
      "Epoch 806/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9733 - val_loss: 194.3303\n",
      "Epoch 807/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9874 - val_loss: 191.9320\n",
      "Epoch 808/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9567 - val_loss: 193.1769\n",
      "Epoch 809/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5288 - val_loss: 195.7123\n",
      "Epoch 810/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5813 - val_loss: 193.8679\n",
      "Epoch 811/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5992 - val_loss: 194.2045\n",
      "Epoch 812/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6991 - val_loss: 196.1465\n",
      "Epoch 813/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8207 - val_loss: 195.6961\n",
      "Epoch 814/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6786 - val_loss: 192.9041\n",
      "Epoch 815/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7859 - val_loss: 192.8866\n",
      "Epoch 816/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9182 - val_loss: 191.3642\n",
      "Epoch 817/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8356 - val_loss: 193.3393\n",
      "Epoch 818/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9089 - val_loss: 194.3512\n",
      "Epoch 819/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9541 - val_loss: 192.2361\n",
      "Epoch 820/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5732 - val_loss: 193.1620\n",
      "Epoch 821/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1757 - val_loss: 190.8110\n",
      "Epoch 822/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5760 - val_loss: 194.1600\n",
      "Epoch 823/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5501 - val_loss: 192.5514\n",
      "Epoch 824/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6394 - val_loss: 192.9184\n",
      "Epoch 825/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5785 - val_loss: 194.7768\n",
      "Epoch 826/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8020 - val_loss: 193.1509\n",
      "Epoch 827/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8732 - val_loss: 190.8581\n",
      "Epoch 828/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4902 - val_loss: 190.6360\n",
      "Epoch 829/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7986 - val_loss: 193.1838\n",
      "Epoch 830/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6864 - val_loss: 192.8580\n",
      "Epoch 831/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6254 - val_loss: 192.5130\n",
      "Epoch 832/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7636 - val_loss: 195.2825\n",
      "Epoch 833/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6191 - val_loss: 189.5810\n",
      "Epoch 834/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6410 - val_loss: 193.6005\n",
      "Epoch 835/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3814 - val_loss: 194.1173\n",
      "Epoch 836/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6846 - val_loss: 194.6230\n",
      "Epoch 837/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4566 - val_loss: 194.4480\n",
      "Epoch 838/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8125 - val_loss: 190.4846\n",
      "Epoch 839/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9247 - val_loss: 189.7737\n",
      "Epoch 840/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8358 - val_loss: 192.7904\n",
      "Epoch 841/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7310 - val_loss: 193.7117\n",
      "Epoch 842/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7832 - val_loss: 193.8176\n",
      "Epoch 843/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0195 - val_loss: 193.2977\n",
      "Epoch 844/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5049 - val_loss: 191.9143\n",
      "Epoch 845/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6180 - val_loss: 193.4253\n",
      "Epoch 846/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7536 - val_loss: 194.3050\n",
      "Epoch 847/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8562 - val_loss: 194.4795\n",
      "Epoch 848/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6077 - val_loss: 192.7312\n",
      "Epoch 849/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5431 - val_loss: 194.9614\n",
      "Epoch 850/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6728 - val_loss: 194.7942\n",
      "Epoch 851/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6791 - val_loss: 193.1093\n",
      "Epoch 852/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5431 - val_loss: 193.4024\n",
      "Epoch 853/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6788 - val_loss: 196.0365\n",
      "Epoch 854/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7457 - val_loss: 190.8063\n",
      "Epoch 855/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6031 - val_loss: 195.0950\n",
      "Epoch 856/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.2153 - val_loss: 194.0059\n",
      "Epoch 857/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9813 - val_loss: 195.6665\n",
      "Epoch 858/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7082 - val_loss: 194.0746\n",
      "Epoch 859/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6361 - val_loss: 193.3412\n",
      "Epoch 860/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6644 - val_loss: 193.3500\n",
      "Epoch 861/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5777 - val_loss: 191.9799\n",
      "Epoch 862/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.3094 - val_loss: 192.0455\n",
      "Epoch 863/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8153 - val_loss: 193.0191\n",
      "Epoch 864/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8486 - val_loss: 190.7264\n",
      "Epoch 865/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7163 - val_loss: 192.3066\n",
      "Epoch 866/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5876 - val_loss: 192.1154\n",
      "Epoch 867/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6906 - val_loss: 194.3921\n",
      "Epoch 868/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5738 - val_loss: 190.6806\n",
      "Epoch 869/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8357 - val_loss: 190.4707\n",
      "Epoch 870/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7040 - val_loss: 190.6734\n",
      "Epoch 871/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5065 - val_loss: 194.1632\n",
      "Epoch 872/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4127 - val_loss: 192.4631\n",
      "Epoch 873/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8621 - val_loss: 193.8626\n",
      "Epoch 874/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8428 - val_loss: 195.1911\n",
      "Epoch 875/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1199 - val_loss: 193.8866\n",
      "Epoch 876/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6543 - val_loss: 193.9558\n",
      "Epoch 877/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7720 - val_loss: 190.0515\n",
      "Epoch 878/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7153 - val_loss: 194.8643\n",
      "Epoch 879/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7320 - val_loss: 193.0358\n",
      "Epoch 880/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5465 - val_loss: 191.8668\n",
      "Epoch 881/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6160 - val_loss: 192.1865\n",
      "Epoch 882/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.2874 - val_loss: 196.5468\n",
      "Epoch 883/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7500 - val_loss: 192.0899\n",
      "Epoch 884/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6243 - val_loss: 192.5400\n",
      "Epoch 885/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4958 - val_loss: 191.3301\n",
      "Epoch 886/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8141 - val_loss: 191.9170\n",
      "Epoch 887/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8117 - val_loss: 192.4476\n",
      "Epoch 888/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6128 - val_loss: 194.5157\n",
      "Epoch 889/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9806 - val_loss: 196.0213\n",
      "Epoch 890/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7111 - val_loss: 192.6561\n",
      "Epoch 891/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0777 - val_loss: 192.5663\n",
      "Epoch 892/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7673 - val_loss: 192.1161\n",
      "Epoch 893/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6794 - val_loss: 193.1475\n",
      "Epoch 894/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6365 - val_loss: 195.9219\n",
      "Epoch 895/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9067 - val_loss: 193.6994\n",
      "Epoch 896/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9105 - val_loss: 191.5812\n",
      "Epoch 897/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5184 - val_loss: 193.0973\n",
      "Epoch 898/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5933 - val_loss: 194.8431\n",
      "Epoch 899/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7398 - val_loss: 192.3389\n",
      "Epoch 900/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6767 - val_loss: 192.6480\n",
      "Epoch 901/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5925 - val_loss: 193.5223\n",
      "Epoch 902/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8280 - val_loss: 193.1141\n",
      "Epoch 903/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6370 - val_loss: 194.1277\n",
      "Epoch 904/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4526 - val_loss: 195.5081\n",
      "Epoch 905/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6898 - val_loss: 191.9185\n",
      "Epoch 906/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8099 - val_loss: 194.8609\n",
      "Epoch 907/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0294 - val_loss: 192.1994\n",
      "Epoch 908/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7602 - val_loss: 196.3168\n",
      "Epoch 909/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4587 - val_loss: 193.0219\n",
      "Epoch 910/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5662 - val_loss: 192.8834\n",
      "Epoch 911/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5745 - val_loss: 191.9950\n",
      "Epoch 912/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7950 - val_loss: 191.8675\n",
      "Epoch 913/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5595 - val_loss: 194.8435\n",
      "Epoch 914/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8931 - val_loss: 193.1127\n",
      "Epoch 915/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9844 - val_loss: 192.8339\n",
      "Epoch 916/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6687 - val_loss: 190.0562\n",
      "Epoch 917/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6998 - val_loss: 193.7478\n",
      "Epoch 918/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5785 - val_loss: 193.4440\n",
      "Epoch 919/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8529 - val_loss: 194.6893\n",
      "Epoch 920/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6550 - val_loss: 192.6678\n",
      "Epoch 921/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6585 - val_loss: 192.0572\n",
      "Epoch 922/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4752 - val_loss: 194.9843\n",
      "Epoch 923/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6189 - val_loss: 192.7934\n",
      "Epoch 924/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7038 - val_loss: 193.5404\n",
      "Epoch 925/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3467 - val_loss: 191.0842\n",
      "Epoch 926/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5257 - val_loss: 193.9857\n",
      "Epoch 927/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8961 - val_loss: 194.3645\n",
      "Epoch 928/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8393 - val_loss: 193.6467\n",
      "Epoch 929/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7467 - val_loss: 194.4766\n",
      "Epoch 930/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8670 - val_loss: 195.0015\n",
      "Epoch 931/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4790 - val_loss: 196.1467\n",
      "Epoch 932/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8345 - val_loss: 193.7231\n",
      "Epoch 933/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8690 - val_loss: 192.1421\n",
      "Epoch 934/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9283 - val_loss: 189.8459\n",
      "Epoch 935/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4971 - val_loss: 191.0030\n",
      "Epoch 936/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5575 - val_loss: 194.0436\n",
      "Epoch 937/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7395 - val_loss: 195.9006\n",
      "Epoch 938/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7567 - val_loss: 193.1750\n",
      "Epoch 939/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6200 - val_loss: 195.2321\n",
      "Epoch 940/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7051 - val_loss: 194.7612\n",
      "Epoch 941/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5048 - val_loss: 193.0724\n",
      "Epoch 942/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4957 - val_loss: 194.3574\n",
      "Epoch 943/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8559 - val_loss: 194.8357\n",
      "Epoch 944/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1308 - val_loss: 193.6793\n",
      "Epoch 945/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7858 - val_loss: 193.7619\n",
      "Epoch 946/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5236 - val_loss: 193.9423\n",
      "Epoch 947/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4859 - val_loss: 193.0210\n",
      "Epoch 948/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6025 - val_loss: 192.9829\n",
      "Epoch 949/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7172 - val_loss: 196.9961\n",
      "Epoch 950/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5099 - val_loss: 192.8527\n",
      "Epoch 951/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5951 - val_loss: 193.0710\n",
      "Epoch 952/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8510 - val_loss: 192.6391\n",
      "Epoch 953/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7028 - val_loss: 191.8433\n",
      "Epoch 954/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9072 - val_loss: 191.8947\n",
      "Epoch 955/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6078 - val_loss: 190.7984\n",
      "Epoch 956/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7390 - val_loss: 194.2788\n",
      "Epoch 957/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8843 - val_loss: 192.4837\n",
      "Epoch 958/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6626 - val_loss: 192.5789\n",
      "Epoch 959/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8102 - val_loss: 192.1817\n",
      "Epoch 960/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6472 - val_loss: 193.1917\n",
      "Epoch 961/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5932 - val_loss: 191.1437\n",
      "Epoch 962/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7297 - val_loss: 193.2666\n",
      "Epoch 963/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0443 - val_loss: 191.3158\n",
      "Epoch 964/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8799 - val_loss: 185.7481\n",
      "Epoch 965/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9096 - val_loss: 192.5707\n",
      "Epoch 966/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3853 - val_loss: 194.1504\n",
      "Epoch 967/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5558 - val_loss: 195.2272\n",
      "Epoch 968/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5902 - val_loss: 191.2247\n",
      "Epoch 969/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6471 - val_loss: 194.1069\n",
      "Epoch 970/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8275 - val_loss: 192.0257\n",
      "Epoch 971/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8288 - val_loss: 189.9906\n",
      "Epoch 972/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6063 - val_loss: 191.9245\n",
      "Epoch 973/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8548 - val_loss: 192.3528\n",
      "Epoch 974/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6331 - val_loss: 191.5135\n",
      "Epoch 975/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7828 - val_loss: 192.5231\n",
      "Epoch 976/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9703 - val_loss: 197.5227\n",
      "Epoch 977/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6209 - val_loss: 191.8527\n",
      "Epoch 978/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6560 - val_loss: 194.5957\n",
      "Epoch 979/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0329 - val_loss: 194.2068\n",
      "Epoch 980/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4849 - val_loss: 195.9251\n",
      "Epoch 981/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4669 - val_loss: 193.5519\n",
      "Epoch 982/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8291 - val_loss: 192.8833\n",
      "Epoch 983/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6251 - val_loss: 190.9396\n",
      "Epoch 984/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5433 - val_loss: 189.5328\n",
      "Epoch 985/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7150 - val_loss: 194.0970\n",
      "Epoch 986/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5204 - val_loss: 192.6083\n",
      "Epoch 987/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5235 - val_loss: 193.5902\n",
      "Epoch 988/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9663 - val_loss: 194.6762\n",
      "Epoch 989/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5606 - val_loss: 190.0201\n",
      "Epoch 990/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7234 - val_loss: 193.0916\n",
      "Epoch 991/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4993 - val_loss: 192.3043\n",
      "Epoch 992/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8895 - val_loss: 193.2948\n",
      "Epoch 993/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6601 - val_loss: 193.5534\n",
      "Epoch 994/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6445 - val_loss: 196.4311\n",
      "Epoch 995/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8681 - val_loss: 194.8227\n",
      "Epoch 996/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6535 - val_loss: 192.5232\n",
      "Epoch 997/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9486 - val_loss: 192.1715\n",
      "Epoch 998/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4483 - val_loss: 190.6141\n",
      "Epoch 999/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6163 - val_loss: 191.0412\n",
      "Epoch 1000/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8393 - val_loss: 195.7254\n",
      "Epoch 1001/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5262 - val_loss: 192.6657\n",
      "Epoch 1002/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8320 - val_loss: 191.8371\n",
      "Epoch 1003/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5399 - val_loss: 194.4490\n",
      "Epoch 1004/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7030 - val_loss: 191.6218\n",
      "Epoch 1005/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5451 - val_loss: 192.8838\n",
      "Epoch 1006/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7542 - val_loss: 193.9659\n",
      "Epoch 1007/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6862 - val_loss: 194.2732\n",
      "Epoch 1008/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5379 - val_loss: 194.2069\n",
      "Epoch 1009/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5323 - val_loss: 196.2771\n",
      "Epoch 1010/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6018 - val_loss: 197.7518\n",
      "Epoch 1011/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5580 - val_loss: 193.7798\n",
      "Epoch 1012/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7065 - val_loss: 194.8703\n",
      "Epoch 1013/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5947 - val_loss: 196.9418\n",
      "Epoch 1014/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7562 - val_loss: 191.6468\n",
      "Epoch 1015/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5683 - val_loss: 195.2711\n",
      "Epoch 1016/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7912 - val_loss: 196.4055\n",
      "Epoch 1017/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7297 - val_loss: 191.8652\n",
      "Epoch 1018/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5904 - val_loss: 194.1943\n",
      "Epoch 1019/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6910 - val_loss: 193.0853\n",
      "Epoch 1020/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6758 - val_loss: 193.8760\n",
      "Epoch 1021/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5545 - val_loss: 194.2024\n",
      "Epoch 1022/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0317 - val_loss: 193.6941\n",
      "Epoch 1023/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5534 - val_loss: 194.8489\n",
      "Epoch 1024/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4624 - val_loss: 193.6631\n",
      "Epoch 1025/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6293 - val_loss: 195.4672\n",
      "Epoch 1026/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8026 - val_loss: 194.3595\n",
      "Epoch 1027/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9869 - val_loss: 196.5131\n",
      "Epoch 1028/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4893 - val_loss: 194.6130\n",
      "Epoch 1029/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6265 - val_loss: 193.6454\n",
      "Epoch 1030/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6440 - val_loss: 194.5191\n",
      "Epoch 1031/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6265 - val_loss: 193.6236\n",
      "Epoch 1032/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7383 - val_loss: 193.6416\n",
      "Epoch 1033/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7752 - val_loss: 191.0590\n",
      "Epoch 1034/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7638 - val_loss: 194.8777\n",
      "Epoch 1035/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7639 - val_loss: 193.7061\n",
      "Epoch 1036/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7057 - val_loss: 193.7563\n",
      "Epoch 1037/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4344 - val_loss: 193.0861\n",
      "Epoch 1038/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8019 - val_loss: 192.6051\n",
      "Epoch 1039/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4699 - val_loss: 193.1982\n",
      "Epoch 1040/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5312 - val_loss: 191.5098\n",
      "Epoch 1041/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5762 - val_loss: 193.3318\n",
      "Epoch 1042/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7679 - val_loss: 194.4164\n",
      "Epoch 1043/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6782 - val_loss: 194.4298\n",
      "Epoch 1044/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7532 - val_loss: 192.4404\n",
      "Epoch 1045/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5605 - val_loss: 194.0741\n",
      "Epoch 1046/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6696 - val_loss: 196.5142\n",
      "Epoch 1047/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6462 - val_loss: 195.9806\n",
      "Epoch 1048/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8947 - val_loss: 194.8827\n",
      "Epoch 1049/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5230 - val_loss: 193.6824\n",
      "Epoch 1050/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5027 - val_loss: 193.1317\n",
      "Epoch 1051/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6690 - val_loss: 193.5224\n",
      "Epoch 1052/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6512 - val_loss: 193.0791\n",
      "Epoch 1053/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7517 - val_loss: 193.8027\n",
      "Epoch 1054/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7311 - val_loss: 194.5398\n",
      "Epoch 1055/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7372 - val_loss: 193.3637\n",
      "Epoch 1056/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6645 - val_loss: 194.3109\n",
      "Epoch 1057/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5730 - val_loss: 195.0665\n",
      "Epoch 1058/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7621 - val_loss: 193.5920\n",
      "Epoch 1059/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8153 - val_loss: 194.8100\n",
      "Epoch 1060/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9253 - val_loss: 194.8392\n",
      "Epoch 1061/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7233 - val_loss: 192.5015\n",
      "Epoch 1062/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5202 - val_loss: 194.8628\n",
      "Epoch 1063/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6653 - val_loss: 194.3137\n",
      "Epoch 1064/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6954 - val_loss: 194.7572\n",
      "Epoch 1065/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7188 - val_loss: 193.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1066/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7689 - val_loss: 193.8198\n",
      "Epoch 1067/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5297 - val_loss: 191.0050\n",
      "Epoch 1068/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3932 - val_loss: 193.7496\n",
      "Epoch 1069/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9843 - val_loss: 189.6025\n",
      "Epoch 1070/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7063 - val_loss: 192.7469\n",
      "Epoch 1071/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9360 - val_loss: 191.2524\n",
      "Epoch 1072/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5710 - val_loss: 193.7400\n",
      "Epoch 1073/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6417 - val_loss: 193.9848\n",
      "Epoch 1074/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8065 - val_loss: 194.0552\n",
      "Epoch 1075/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7987 - val_loss: 191.3348\n",
      "Epoch 1076/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5482 - val_loss: 191.8141\n",
      "Epoch 1077/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8284 - val_loss: 194.7771\n",
      "Epoch 1078/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6890 - val_loss: 192.6556\n",
      "Epoch 1079/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5638 - val_loss: 193.8460\n",
      "Epoch 1080/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7063 - val_loss: 191.6667\n",
      "Epoch 1081/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4273 - val_loss: 193.6869\n",
      "Epoch 1082/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6442 - val_loss: 193.3115\n",
      "Epoch 1083/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8121 - val_loss: 194.0720\n",
      "Epoch 1084/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5133 - val_loss: 189.3192\n",
      "Epoch 1085/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7010 - val_loss: 194.1230\n",
      "Epoch 1086/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6242 - val_loss: 193.1710\n",
      "Epoch 1087/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7855 - val_loss: 193.6455\n",
      "Epoch 1088/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7100 - val_loss: 194.7112\n",
      "Epoch 1089/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5745 - val_loss: 193.3443\n",
      "Epoch 1090/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6538 - val_loss: 194.8620\n",
      "Epoch 1091/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5320 - val_loss: 189.4401\n",
      "Epoch 1092/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7650 - val_loss: 193.5084\n",
      "Epoch 1093/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7123 - val_loss: 195.0711\n",
      "Epoch 1094/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7019 - val_loss: 191.7572\n",
      "Epoch 1095/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5540 - val_loss: 193.2367\n",
      "Epoch 1096/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6213 - val_loss: 192.2801\n",
      "Epoch 1097/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6603 - val_loss: 191.6359\n",
      "Epoch 1098/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9045 - val_loss: 191.3894\n",
      "Epoch 1099/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7152 - val_loss: 195.5103\n",
      "Epoch 1100/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0377 - val_loss: 194.1841\n",
      "Epoch 1101/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9820 - val_loss: 192.2158\n",
      "Epoch 1102/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4644 - val_loss: 194.7010\n",
      "Epoch 1103/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5595 - val_loss: 196.1711\n",
      "Epoch 1104/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5575 - val_loss: 194.2421\n",
      "Epoch 1105/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5989 - val_loss: 194.6084\n",
      "Epoch 1106/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7169 - val_loss: 195.8420\n",
      "Epoch 1107/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8807 - val_loss: 192.4803\n",
      "Epoch 1108/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5908 - val_loss: 193.7094\n",
      "Epoch 1109/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8965 - val_loss: 193.6425\n",
      "Epoch 1110/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4785 - val_loss: 193.3162\n",
      "Epoch 1111/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.72 - 1s 30us/sample - loss: 70.5710 - val_loss: 192.7722\n",
      "Epoch 1112/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6476 - val_loss: 195.1743\n",
      "Epoch 1113/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7361 - val_loss: 191.5420\n",
      "Epoch 1114/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8214 - val_loss: 194.3625\n",
      "Epoch 1115/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7535 - val_loss: 194.1296\n",
      "Epoch 1116/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7010 - val_loss: 192.0168\n",
      "Epoch 1117/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5821 - val_loss: 194.6395\n",
      "Epoch 1118/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7338 - val_loss: 192.6682\n",
      "Epoch 1119/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5214 - val_loss: 196.6924\n",
      "Epoch 1120/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.92 - 1s 31us/sample - loss: 70.8396 - val_loss: 192.5582\n",
      "Epoch 1121/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7546 - val_loss: 194.0078\n",
      "Epoch 1122/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7549 - val_loss: 195.3598\n",
      "Epoch 1123/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7842 - val_loss: 192.2497\n",
      "Epoch 1124/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7390 - val_loss: 193.9408\n",
      "Epoch 1125/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0027 - val_loss: 196.7859\n",
      "Epoch 1126/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5662 - val_loss: 195.1521\n",
      "Epoch 1127/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.2717 - val_loss: 195.0470\n",
      "Epoch 1128/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6510 - val_loss: 194.4407\n",
      "Epoch 1129/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8772 - val_loss: 195.1163\n",
      "Epoch 1130/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8740 - val_loss: 195.3445\n",
      "Epoch 1131/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7277 - val_loss: 192.0788\n",
      "Epoch 1132/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7842 - val_loss: 195.5706\n",
      "Epoch 1133/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8874 - val_loss: 196.0700\n",
      "Epoch 1134/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7407 - val_loss: 192.0422\n",
      "Epoch 1135/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5061 - val_loss: 194.7558\n",
      "Epoch 1136/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6210 - val_loss: 193.2833\n",
      "Epoch 1137/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8159 - val_loss: 193.1870\n",
      "Epoch 1138/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7613 - val_loss: 194.4795\n",
      "Epoch 1139/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6775 - val_loss: 193.6404\n",
      "Epoch 1140/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5611 - val_loss: 193.5747\n",
      "Epoch 1141/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8049 - val_loss: 196.3776\n",
      "Epoch 1142/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7808 - val_loss: 195.6856\n",
      "Epoch 1143/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0507 - val_loss: 193.4536\n",
      "Epoch 1144/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7718 - val_loss: 193.1615\n",
      "Epoch 1145/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5972 - val_loss: 194.8131\n",
      "Epoch 1146/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5396 - val_loss: 193.4491\n",
      "Epoch 1147/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4929 - val_loss: 192.6098\n",
      "Epoch 1148/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5826 - val_loss: 194.1683\n",
      "Epoch 1149/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6934 - val_loss: 194.5591\n",
      "Epoch 1150/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8851 - val_loss: 196.7898\n",
      "Epoch 1151/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4962 - val_loss: 194.7965\n",
      "Epoch 1152/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6811 - val_loss: 192.8394\n",
      "Epoch 1153/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7162 - val_loss: 194.5064\n",
      "Epoch 1154/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5458 - val_loss: 197.3025\n",
      "Epoch 1155/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7240 - val_loss: 194.0877\n",
      "Epoch 1156/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6043 - val_loss: 193.0326\n",
      "Epoch 1157/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5302 - val_loss: 192.3040\n",
      "Epoch 1158/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6020 - val_loss: 192.4901\n",
      "Epoch 1159/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6554 - val_loss: 192.6716\n",
      "Epoch 1160/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.70 - 1s 31us/sample - loss: 70.7915 - val_loss: 195.4728\n",
      "Epoch 1161/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9106 - val_loss: 194.3024\n",
      "Epoch 1162/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3106 - val_loss: 195.6249\n",
      "Epoch 1163/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8674 - val_loss: 189.9863\n",
      "Epoch 1164/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8009 - val_loss: 194.9366\n",
      "Epoch 1165/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5813 - val_loss: 196.0000\n",
      "Epoch 1166/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7383 - val_loss: 193.9593\n",
      "Epoch 1167/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9914 - val_loss: 194.1108\n",
      "Epoch 1168/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6529 - val_loss: 193.9958\n",
      "Epoch 1169/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5055 - val_loss: 194.1408\n",
      "Epoch 1170/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8287 - val_loss: 191.2082\n",
      "Epoch 1171/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6376 - val_loss: 191.9682\n",
      "Epoch 1172/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7943 - val_loss: 195.5942\n",
      "Epoch 1173/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8724 - val_loss: 193.4650\n",
      "Epoch 1174/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6506 - val_loss: 194.5957\n",
      "Epoch 1175/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8578 - val_loss: 193.2066\n",
      "Epoch 1176/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6481 - val_loss: 194.4280\n",
      "Epoch 1177/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6964 - val_loss: 193.1972\n",
      "Epoch 1178/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7364 - val_loss: 196.2404\n",
      "Epoch 1179/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8073 - val_loss: 195.2503\n",
      "Epoch 1180/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0117 - val_loss: 193.7095\n",
      "Epoch 1181/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7440 - val_loss: 192.9374\n",
      "Epoch 1182/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8988 - val_loss: 195.8591\n",
      "Epoch 1183/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4881 - val_loss: 194.7445\n",
      "Epoch 1184/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5731 - val_loss: 193.9367\n",
      "Epoch 1185/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4329 - val_loss: 189.8603\n",
      "Epoch 1186/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7643 - val_loss: 191.1992\n",
      "Epoch 1187/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8381 - val_loss: 194.9936\n",
      "Epoch 1188/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5804 - val_loss: 192.9280\n",
      "Epoch 1189/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9493 - val_loss: 192.2146\n",
      "Epoch 1190/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6060 - val_loss: 193.0680\n",
      "Epoch 1191/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5553 - val_loss: 194.1564\n",
      "Epoch 1192/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4349 - val_loss: 192.2379\n",
      "Epoch 1193/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5694 - val_loss: 191.0670\n",
      "Epoch 1194/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4819 - val_loss: 191.4918\n",
      "Epoch 1195/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7962 - val_loss: 193.6534\n",
      "Epoch 1196/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7446 - val_loss: 192.4036\n",
      "Epoch 1197/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8737 - val_loss: 191.3369\n",
      "Epoch 1198/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7123 - val_loss: 192.7290\n",
      "Epoch 1199/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6737 - val_loss: 192.8188\n",
      "Epoch 1200/20000\n",
      "17948/17948 [==============================] - 1s 54us/sample - loss: 70.7182 - val_loss: 192.9381\n",
      "Epoch 1201/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0867 - val_loss: 194.3383\n",
      "Epoch 1202/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7193 - val_loss: 194.9601\n",
      "Epoch 1203/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7350 - val_loss: 192.3345\n",
      "Epoch 1204/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7506 - val_loss: 189.9605\n",
      "Epoch 1205/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8044 - val_loss: 195.2334\n",
      "Epoch 1206/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6981 - val_loss: 190.6387\n",
      "Epoch 1207/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8739 - val_loss: 193.4752\n",
      "Epoch 1208/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4457 - val_loss: 193.2967\n",
      "Epoch 1209/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8799 - val_loss: 192.4367\n",
      "Epoch 1210/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6385 - val_loss: 192.4431\n",
      "Epoch 1211/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6200 - val_loss: 194.1640\n",
      "Epoch 1212/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8169 - val_loss: 191.0353\n",
      "Epoch 1213/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7653 - val_loss: 194.5650\n",
      "Epoch 1214/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6062 - val_loss: 194.7102\n",
      "Epoch 1215/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6968 - val_loss: 194.6368\n",
      "Epoch 1216/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.3201 - val_loss: 193.0640\n",
      "Epoch 1217/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0308 - val_loss: 195.1072\n",
      "Epoch 1218/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7812 - val_loss: 192.8843\n",
      "Epoch 1219/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6272 - val_loss: 191.1798\n",
      "Epoch 1220/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4097 - val_loss: 192.5934\n",
      "Epoch 1221/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.1454 - val_loss: 194.9307\n",
      "Epoch 1222/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9684 - val_loss: 193.6386\n",
      "Epoch 1223/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6753 - val_loss: 193.7759\n",
      "Epoch 1224/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4812 - val_loss: 193.9129\n",
      "Epoch 1225/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6398 - val_loss: 192.9636\n",
      "Epoch 1226/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6668 - val_loss: 193.9248\n",
      "Epoch 1227/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5980 - val_loss: 193.9296\n",
      "Epoch 1228/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5627 - val_loss: 190.9980\n",
      "Epoch 1229/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9496 - val_loss: 193.7221\n",
      "Epoch 1230/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5703 - val_loss: 190.9417\n",
      "Epoch 1231/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6405 - val_loss: 192.6739\n",
      "Epoch 1232/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6319 - val_loss: 191.8339\n",
      "Epoch 1233/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9249 - val_loss: 192.9864\n",
      "Epoch 1234/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6598 - val_loss: 194.0043\n",
      "Epoch 1235/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6012 - val_loss: 192.9150\n",
      "Epoch 1236/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6338 - val_loss: 195.0330\n",
      "Epoch 1237/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5691 - val_loss: 195.9652\n",
      "Epoch 1238/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7468 - val_loss: 193.9613\n",
      "Epoch 1239/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7977 - val_loss: 193.8292\n",
      "Epoch 1240/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.87 - 1s 30us/sample - loss: 70.7075 - val_loss: 192.6606\n",
      "Epoch 1241/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5355 - val_loss: 193.8922\n",
      "Epoch 1242/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7699 - val_loss: 191.6267\n",
      "Epoch 1243/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7603 - val_loss: 192.3246\n",
      "Epoch 1244/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8306 - val_loss: 194.0974\n",
      "Epoch 1245/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9024 - val_loss: 190.7817\n",
      "Epoch 1246/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7224 - val_loss: 192.2454\n",
      "Epoch 1247/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3167 - val_loss: 191.7704\n",
      "Epoch 1248/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6421 - val_loss: 196.1230\n",
      "Epoch 1249/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5345 - val_loss: 197.5757\n",
      "Epoch 1250/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8044 - val_loss: 193.8953\n",
      "Epoch 1251/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9277 - val_loss: 192.3908\n",
      "Epoch 1252/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6758 - val_loss: 194.2489\n",
      "Epoch 1253/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8404 - val_loss: 193.3116\n",
      "Epoch 1254/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9135 - val_loss: 192.5552\n",
      "Epoch 1255/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6413 - val_loss: 191.3828\n",
      "Epoch 1256/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5594 - val_loss: 193.9337\n",
      "Epoch 1257/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6660 - val_loss: 193.4232\n",
      "Epoch 1258/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5927 - val_loss: 194.5134\n",
      "Epoch 1259/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9368 - val_loss: 192.6834\n",
      "Epoch 1260/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4892 - val_loss: 194.5906\n",
      "Epoch 1261/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8720 - val_loss: 190.9888\n",
      "Epoch 1262/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6136 - val_loss: 190.0505\n",
      "Epoch 1263/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6242 - val_loss: 192.9152\n",
      "Epoch 1264/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6355 - val_loss: 192.0753\n",
      "Epoch 1265/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0324 - val_loss: 193.6853\n",
      "Epoch 1266/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6080 - val_loss: 195.8485\n",
      "Epoch 1267/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6600 - val_loss: 190.9219\n",
      "Epoch 1268/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7268 - val_loss: 193.0736\n",
      "Epoch 1269/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4391 - val_loss: 194.8371\n",
      "Epoch 1270/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8101 - val_loss: 195.5590\n",
      "Epoch 1271/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9639 - val_loss: 190.6727\n",
      "Epoch 1272/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6997 - val_loss: 193.1311\n",
      "Epoch 1273/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4316 - val_loss: 192.4334\n",
      "Epoch 1274/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7506 - val_loss: 192.2857\n",
      "Epoch 1275/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5600 - val_loss: 193.2775\n",
      "Epoch 1276/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4065 - val_loss: 192.3966\n",
      "Epoch 1277/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5625 - val_loss: 195.8288\n",
      "Epoch 1278/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5665 - val_loss: 193.2490\n",
      "Epoch 1279/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1894 - val_loss: 194.6630\n",
      "Epoch 1280/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7787 - val_loss: 192.0398\n",
      "Epoch 1281/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6377 - val_loss: 194.6176\n",
      "Epoch 1282/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5440 - val_loss: 190.6026\n",
      "Epoch 1283/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5025 - val_loss: 194.2670\n",
      "Epoch 1284/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5305 - val_loss: 188.4977\n",
      "Epoch 1285/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4591 - val_loss: 191.7436\n",
      "Epoch 1286/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8890 - val_loss: 192.7585\n",
      "Epoch 1287/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7334 - val_loss: 193.4920\n",
      "Epoch 1288/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6588 - val_loss: 194.2545\n",
      "Epoch 1289/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6720 - val_loss: 193.5887\n",
      "Epoch 1290/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7618 - val_loss: 194.1928\n",
      "Epoch 1291/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7217 - val_loss: 193.0387\n",
      "Epoch 1292/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7517 - val_loss: 193.8651\n",
      "Epoch 1293/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6274 - val_loss: 193.3166\n",
      "Epoch 1294/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8623 - val_loss: 195.1320\n",
      "Epoch 1295/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3093 - val_loss: 193.5258\n",
      "Epoch 1296/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8535 - val_loss: 195.3355\n",
      "Epoch 1297/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8381 - val_loss: 189.8496\n",
      "Epoch 1298/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.4685 - val_loss: 192.0382\n",
      "Epoch 1299/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8638 - val_loss: 195.0116\n",
      "Epoch 1300/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4450 - val_loss: 194.7468\n",
      "Epoch 1301/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8166 - val_loss: 192.1021\n",
      "Epoch 1302/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7028 - val_loss: 192.8765\n",
      "Epoch 1303/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7646 - val_loss: 192.7728\n",
      "Epoch 1304/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7225 - val_loss: 194.0613\n",
      "Epoch 1305/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4932 - val_loss: 194.3851\n",
      "Epoch 1306/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7875 - val_loss: 192.9658\n",
      "Epoch 1307/20000\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 70.7516 - val_loss: 194.5268\n",
      "Epoch 1308/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.8144 - val_loss: 193.6700\n",
      "Epoch 1309/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7303 - val_loss: 192.2160\n",
      "Epoch 1310/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6241 - val_loss: 194.7381\n",
      "Epoch 1311/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6705 - val_loss: 194.6433\n",
      "Epoch 1312/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5239 - val_loss: 195.8925\n",
      "Epoch 1313/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8583 - val_loss: 193.9040\n",
      "Epoch 1314/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4719 - val_loss: 195.0302\n",
      "Epoch 1315/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7763 - val_loss: 195.3796\n",
      "Epoch 1316/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5126 - val_loss: 197.7690\n",
      "Epoch 1317/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5472 - val_loss: 194.6368\n",
      "Epoch 1318/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7911 - val_loss: 192.9651\n",
      "Epoch 1319/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5801 - val_loss: 193.2586\n",
      "Epoch 1320/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8591 - val_loss: 192.7296\n",
      "Epoch 1321/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8324 - val_loss: 193.2040\n",
      "Epoch 1322/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6325 - val_loss: 194.8482\n",
      "Epoch 1323/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.9026 - val_loss: 191.2157\n",
      "Epoch 1324/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7905 - val_loss: 194.4429\n",
      "Epoch 1325/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5730 - val_loss: 191.7918\n",
      "Epoch 1326/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9189 - val_loss: 194.4923\n",
      "Epoch 1327/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.1183 - val_loss: 191.5260\n",
      "Epoch 1328/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7047 - val_loss: 194.1688\n",
      "Epoch 1329/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8258 - val_loss: 193.4355\n",
      "Epoch 1330/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8133 - val_loss: 193.9748\n",
      "Epoch 1331/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5977 - val_loss: 193.2184\n",
      "Epoch 1332/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.8389 - val_loss: 192.7460\n",
      "Epoch 1333/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.7572 - val_loss: 191.8762\n",
      "Epoch 1334/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6510 - val_loss: 193.8164\n",
      "Epoch 1335/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7271 - val_loss: 194.1660\n",
      "Epoch 1336/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6493 - val_loss: 191.5073\n",
      "Epoch 1337/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7262 - val_loss: 195.6259\n",
      "Epoch 1338/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7699 - val_loss: 190.5042\n",
      "Epoch 1339/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8524 - val_loss: 192.8066\n",
      "Epoch 1340/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5839 - val_loss: 193.1988\n",
      "Epoch 1341/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5124 - val_loss: 192.4791\n",
      "Epoch 1342/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5019 - val_loss: 193.7065\n",
      "Epoch 1343/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7373 - val_loss: 195.5195\n",
      "Epoch 1344/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5277 - val_loss: 192.1671\n",
      "Epoch 1345/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5661 - val_loss: 191.8003\n",
      "Epoch 1346/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8286 - val_loss: 194.5071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1347/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7928 - val_loss: 194.1118\n",
      "Epoch 1348/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.7897 - val_loss: 193.0552\n",
      "Epoch 1349/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8646 - val_loss: 196.1389\n",
      "Epoch 1350/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6958 - val_loss: 195.9080\n",
      "Epoch 1351/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4759 - val_loss: 194.4433\n",
      "Epoch 1352/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6054 - val_loss: 194.5693\n",
      "Epoch 1353/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6748 - val_loss: 191.1855\n",
      "Epoch 1354/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4960 - val_loss: 193.0739\n",
      "Epoch 1355/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8856 - val_loss: 192.6127\n",
      "Epoch 1356/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5657 - val_loss: 194.2256\n",
      "Epoch 1357/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9476 - val_loss: 194.1160\n",
      "Epoch 1358/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9269 - val_loss: 192.8964\n",
      "Epoch 1359/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6894 - val_loss: 194.1924\n",
      "Epoch 1360/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5644 - val_loss: 195.1805\n",
      "Epoch 1361/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6368 - val_loss: 194.8204\n",
      "Epoch 1362/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6651 - val_loss: 194.6431\n",
      "Epoch 1363/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7598 - val_loss: 193.2673\n",
      "Epoch 1364/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6100 - val_loss: 191.2575\n",
      "Epoch 1365/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6702 - val_loss: 195.5921\n",
      "Epoch 1366/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0623 - val_loss: 194.0470\n",
      "Epoch 1367/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8240 - val_loss: 194.4172\n",
      "Epoch 1368/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5521 - val_loss: 193.6602\n",
      "Epoch 1369/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4774 - val_loss: 192.0038\n",
      "Epoch 1370/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6312 - val_loss: 193.6913\n",
      "Epoch 1371/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4259 - val_loss: 190.0621\n",
      "Epoch 1372/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6585 - val_loss: 191.4920\n",
      "Epoch 1373/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.6601 - val_loss: 196.3759\n",
      "Epoch 1374/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7891 - val_loss: 195.1866\n",
      "Epoch 1375/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7632 - val_loss: 195.1530\n",
      "Epoch 1376/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 70.5318 - val_loss: 193.8510\n",
      "Epoch 1377/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9673 - val_loss: 192.4293\n",
      "Epoch 1378/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6673 - val_loss: 190.0141\n",
      "Epoch 1379/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7801 - val_loss: 192.7515\n",
      "Epoch 1380/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6415 - val_loss: 193.4429\n",
      "Epoch 1381/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5051 - val_loss: 193.2756\n",
      "Epoch 1382/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7567 - val_loss: 195.8427\n",
      "Epoch 1383/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8894 - val_loss: 194.9323\n",
      "Epoch 1384/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9875 - val_loss: 192.0901\n",
      "Epoch 1385/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3685 - val_loss: 195.5438\n",
      "Epoch 1386/20000\n",
      "17948/17948 [==============================] - 1s 30us/sample - loss: 71.0192 - val_loss: 192.9345\n",
      "Epoch 1387/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7210 - val_loss: 194.4048\n",
      "Epoch 1388/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7294 - val_loss: 191.7885\n",
      "Epoch 1389/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4762 - val_loss: 196.5960\n",
      "Epoch 1390/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8400 - val_loss: 192.3622\n",
      "Epoch 1391/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6332 - val_loss: 192.7938\n",
      "Epoch 1392/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7276 - val_loss: 193.9202\n",
      "Epoch 1393/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4743 - val_loss: 194.7343\n",
      "Epoch 1394/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7675 - val_loss: 192.0319\n",
      "Epoch 1395/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9424 - val_loss: 192.7010\n",
      "Epoch 1396/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5763 - val_loss: 195.6206\n",
      "Epoch 1397/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4196 - val_loss: 193.6961\n",
      "Epoch 1398/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4061 - val_loss: 190.8596\n",
      "Epoch 1399/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7750 - val_loss: 193.9278\n",
      "Epoch 1400/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9425 - val_loss: 191.3839\n",
      "Epoch 1401/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8651 - val_loss: 193.2168\n",
      "Epoch 1402/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6758 - val_loss: 194.8250\n",
      "Epoch 1403/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6527 - val_loss: 193.2062\n",
      "Epoch 1404/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7582 - val_loss: 194.9863\n",
      "Epoch 1405/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5131 - val_loss: 193.3307\n",
      "Epoch 1406/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7219 - val_loss: 190.4019\n",
      "Epoch 1407/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6035 - val_loss: 190.0954\n",
      "Epoch 1408/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5551 - val_loss: 189.1287\n",
      "Epoch 1409/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.8566 - val_loss: 194.5144\n",
      "Epoch 1410/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8006 - val_loss: 193.2803\n",
      "Epoch 1411/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0245 - val_loss: 194.5455\n",
      "Epoch 1412/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5644 - val_loss: 193.5802\n",
      "Epoch 1413/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.6719 - val_loss: 194.1343\n",
      "Epoch 1414/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8849 - val_loss: 191.7580\n",
      "Epoch 1415/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1390 - val_loss: 191.6496\n",
      "Epoch 1416/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5580 - val_loss: 194.3223\n",
      "Epoch 1417/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.8300 - val_loss: 193.5907\n",
      "Epoch 1418/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8205 - val_loss: 192.8617\n",
      "Epoch 1419/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6523 - val_loss: 194.5278\n",
      "Epoch 1420/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6723 - val_loss: 194.0913\n",
      "Epoch 1421/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6830 - val_loss: 192.9004\n",
      "Epoch 1422/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4722 - val_loss: 192.4043\n",
      "Epoch 1423/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6222 - val_loss: 195.3292\n",
      "Epoch 1424/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5213 - val_loss: 194.9187\n",
      "Epoch 1425/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5862 - val_loss: 194.0731\n",
      "Epoch 1426/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8795 - val_loss: 194.0733\n",
      "Epoch 1427/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7075 - val_loss: 195.1100\n",
      "Epoch 1428/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7634 - val_loss: 194.5374\n",
      "Epoch 1429/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4817 - val_loss: 195.1946\n",
      "Epoch 1430/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6263 - val_loss: 194.3558\n",
      "Epoch 1431/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.52 - 1s 33us/sample - loss: 70.5056 - val_loss: 195.3286\n",
      "Epoch 1432/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6907 - val_loss: 191.0870\n",
      "Epoch 1433/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6515 - val_loss: 194.6519\n",
      "Epoch 1434/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6630 - val_loss: 191.4867\n",
      "Epoch 1435/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8513 - val_loss: 193.5915\n",
      "Epoch 1436/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9745 - val_loss: 193.7792\n",
      "Epoch 1437/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8277 - val_loss: 192.9756\n",
      "Epoch 1438/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8262 - val_loss: 193.2105\n",
      "Epoch 1439/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6987 - val_loss: 190.7806\n",
      "Epoch 1440/20000\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 70.6269 - val_loss: 191.7802\n",
      "Epoch 1441/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8273 - val_loss: 193.0088\n",
      "Epoch 1442/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7645 - val_loss: 192.5135\n",
      "Epoch 1443/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.6731 - val_loss: 192.5715\n",
      "Epoch 1444/20000\n",
      "17948/17948 [==============================] - 1s 52us/sample - loss: 70.7183 - val_loss: 190.1118\n",
      "Epoch 1445/20000\n",
      "17948/17948 [==============================] - 1s 55us/sample - loss: 70.9055 - val_loss: 192.6046\n",
      "Epoch 1446/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5655 - val_loss: 192.0441\n",
      "Epoch 1447/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6284 - val_loss: 193.1606\n",
      "Epoch 1448/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5166 - val_loss: 191.6174\n",
      "Epoch 1449/20000\n",
      "17948/17948 [==============================] - 1s 49us/sample - loss: 70.7267 - val_loss: 193.7225\n",
      "Epoch 1450/20000\n",
      "17948/17948 [==============================] - 1s 54us/sample - loss: 70.3277 - val_loss: 192.5148\n",
      "Epoch 1451/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5692 - val_loss: 193.0523\n",
      "Epoch 1452/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8190 - val_loss: 192.1819\n",
      "Epoch 1453/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5797 - val_loss: 189.3097\n",
      "Epoch 1454/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5634 - val_loss: 196.0103\n",
      "Epoch 1455/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8290 - val_loss: 191.5980\n",
      "Epoch 1456/20000\n",
      "17948/17948 [==============================] - 1s 42us/sample - loss: 70.6019 - val_loss: 194.8121\n",
      "Epoch 1457/20000\n",
      "17948/17948 [==============================] - 1s 47us/sample - loss: 70.5969 - val_loss: 192.1787\n",
      "Epoch 1458/20000\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 71.0045 - val_loss: 197.7733\n",
      "Epoch 1459/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6690 - val_loss: 195.8511\n",
      "Epoch 1460/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.3625 - val_loss: 193.4842\n",
      "Epoch 1461/20000\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 70.6686 - val_loss: 194.7869\n",
      "Epoch 1462/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5177 - val_loss: 194.2407\n",
      "Epoch 1463/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7542 - val_loss: 193.2424\n",
      "Epoch 1464/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5114 - val_loss: 193.9711\n",
      "Epoch 1465/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.6754 - val_loss: 194.3743\n",
      "Epoch 1466/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5224 - val_loss: 194.2318\n",
      "Epoch 1467/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5338 - val_loss: 193.9024\n",
      "Epoch 1468/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.5395 - val_loss: 194.4905\n",
      "Epoch 1469/20000\n",
      "17948/17948 [==============================] - 1s 42us/sample - loss: 70.6234 - val_loss: 194.2025\n",
      "Epoch 1470/20000\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 70.6540 - val_loss: 194.1255\n",
      "Epoch 1471/20000\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 70.9113 - val_loss: 190.7876\n",
      "Epoch 1472/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.5968 - val_loss: 194.1522\n",
      "Epoch 1473/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.7476 - val_loss: 195.3854\n",
      "Epoch 1474/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.6657 - val_loss: 193.6299\n",
      "Epoch 1475/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4683 - val_loss: 191.6986\n",
      "Epoch 1476/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.5585 - val_loss: 194.1249\n",
      "Epoch 1477/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.7729 - val_loss: 193.4187\n",
      "Epoch 1478/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6164 - val_loss: 192.9858\n",
      "Epoch 1479/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8056 - val_loss: 195.6732\n",
      "Epoch 1480/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8069 - val_loss: 193.1277\n",
      "Epoch 1481/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8415 - val_loss: 190.5119\n",
      "Epoch 1482/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4681 - val_loss: 194.5656\n",
      "Epoch 1483/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8087 - val_loss: 195.3727\n",
      "Epoch 1484/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8111 - val_loss: 192.5497\n",
      "Epoch 1485/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.4256 - val_loss: 195.0762\n",
      "Epoch 1486/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8433 - val_loss: 191.8647\n",
      "Epoch 1487/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.7236 - val_loss: 195.8020\n",
      "Epoch 1488/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5427 - val_loss: 193.6703\n",
      "Epoch 1489/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6618 - val_loss: 193.1747\n",
      "Epoch 1490/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6356 - val_loss: 193.0886\n",
      "Epoch 1491/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6967 - val_loss: 193.0998\n",
      "Epoch 1492/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3593 - val_loss: 192.7737\n",
      "Epoch 1493/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6865 - val_loss: 193.1813\n",
      "Epoch 1494/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4992 - val_loss: 193.7943\n",
      "Epoch 1495/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7923 - val_loss: 194.1066\n",
      "Epoch 1496/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5438 - val_loss: 193.7251\n",
      "Epoch 1497/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.6210 - val_loss: 197.6200\n",
      "Epoch 1498/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 71.1203 - val_loss: 196.3773\n",
      "Epoch 1499/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8772 - val_loss: 194.9847\n",
      "Epoch 1500/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.9787 - val_loss: 192.2211\n",
      "Epoch 1501/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5255 - val_loss: 191.0905\n",
      "Epoch 1502/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4553 - val_loss: 190.8514\n",
      "Epoch 1503/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7671 - val_loss: 194.3790\n",
      "Epoch 1504/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6676 - val_loss: 194.6206\n",
      "Epoch 1505/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7282 - val_loss: 194.3458\n",
      "Epoch 1506/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5850 - val_loss: 193.9926\n",
      "Epoch 1507/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6479 - val_loss: 192.8401\n",
      "Epoch 1508/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6227 - val_loss: 197.3994\n",
      "Epoch 1509/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.8834 - val_loss: 194.9463\n",
      "Epoch 1510/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.4981 - val_loss: 189.6207\n",
      "Epoch 1511/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7928 - val_loss: 195.6085\n",
      "Epoch 1512/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7796 - val_loss: 195.0461\n",
      "Epoch 1513/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4551 - val_loss: 193.8006\n",
      "Epoch 1514/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.5241 - val_loss: 192.4431\n",
      "Epoch 1515/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6208 - val_loss: 194.7073\n",
      "Epoch 1516/20000\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 70.7135 - val_loss: 191.8314\n",
      "Epoch 1517/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5729 - val_loss: 191.9204\n",
      "Epoch 1518/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8228 - val_loss: 193.3579\n",
      "Epoch 1519/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.0236 - val_loss: 195.6620\n",
      "Epoch 1520/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7880 - val_loss: 192.2304\n",
      "Epoch 1521/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7645 - val_loss: 193.8794\n",
      "Epoch 1522/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5059 - val_loss: 194.5372\n",
      "Epoch 1523/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3928 - val_loss: 195.5836\n",
      "Epoch 1524/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5019 - val_loss: 195.6623\n",
      "Epoch 1525/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8195 - val_loss: 192.3432\n",
      "Epoch 1526/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7574 - val_loss: 194.8674\n",
      "Epoch 1527/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5881 - val_loss: 197.5148\n",
      "Epoch 1528/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6194 - val_loss: 192.2909\n",
      "Epoch 1529/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9053 - val_loss: 197.7377\n",
      "Epoch 1530/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9242 - val_loss: 193.0629\n",
      "Epoch 1531/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3986 - val_loss: 195.2745\n",
      "Epoch 1532/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6563 - val_loss: 194.9662\n",
      "Epoch 1533/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7547 - val_loss: 194.1439\n",
      "Epoch 1534/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8960 - val_loss: 190.6445\n",
      "Epoch 1535/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.8506 - val_loss: 193.6974\n",
      "Epoch 1536/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6216 - val_loss: 194.1335\n",
      "Epoch 1537/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7019 - val_loss: 192.4776\n",
      "Epoch 1538/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7145 - val_loss: 194.6477\n",
      "Epoch 1539/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5711 - val_loss: 195.8916\n",
      "Epoch 1540/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8117 - val_loss: 195.7707\n",
      "Epoch 1541/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5933 - val_loss: 196.5331\n",
      "Epoch 1542/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6826 - val_loss: 192.1802\n",
      "Epoch 1543/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7630 - val_loss: 195.2142\n",
      "Epoch 1544/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8600 - val_loss: 191.5964\n",
      "Epoch 1545/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5863 - val_loss: 194.4271\n",
      "Epoch 1546/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3308 - val_loss: 192.7416\n",
      "Epoch 1547/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4522 - val_loss: 193.4569\n",
      "Epoch 1548/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5832 - val_loss: 193.9419\n",
      "Epoch 1549/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8856 - val_loss: 194.3049\n",
      "Epoch 1550/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6133 - val_loss: 195.6788\n",
      "Epoch 1551/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0885 - val_loss: 192.9277\n",
      "Epoch 1552/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0281 - val_loss: 193.0869\n",
      "Epoch 1553/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.2600 - val_loss: 194.5798\n",
      "Epoch 1554/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4568 - val_loss: 192.3046\n",
      "Epoch 1555/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7979 - val_loss: 193.1974\n",
      "Epoch 1556/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7403 - val_loss: 192.6543\n",
      "Epoch 1557/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6241 - val_loss: 192.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1558/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7678 - val_loss: 192.4841\n",
      "Epoch 1559/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7532 - val_loss: 193.5554\n",
      "Epoch 1560/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4280 - val_loss: 195.1754\n",
      "Epoch 1561/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1050 - val_loss: 189.8748\n",
      "Epoch 1562/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7429 - val_loss: 193.4034\n",
      "Epoch 1563/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2584 - val_loss: 191.9821\n",
      "Epoch 1564/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6120 - val_loss: 194.3234\n",
      "Epoch 1565/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7241 - val_loss: 193.9367\n",
      "Epoch 1566/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6881 - val_loss: 191.1930\n",
      "Epoch 1567/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4490 - val_loss: 193.4020\n",
      "Epoch 1568/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7264 - val_loss: 191.9921\n",
      "Epoch 1569/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4873 - val_loss: 193.6117\n",
      "Epoch 1570/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6113 - val_loss: 194.1634\n",
      "Epoch 1571/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6500 - val_loss: 192.6257\n",
      "Epoch 1572/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3882 - val_loss: 195.1776\n",
      "Epoch 1573/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7797 - val_loss: 195.5164\n",
      "Epoch 1574/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8171 - val_loss: 193.3558\n",
      "Epoch 1575/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9409 - val_loss: 193.1552\n",
      "Epoch 1576/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6819 - val_loss: 195.9306\n",
      "Epoch 1577/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5252 - val_loss: 193.5166\n",
      "Epoch 1578/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5977 - val_loss: 193.1938\n",
      "Epoch 1579/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3635 - val_loss: 195.1368\n",
      "Epoch 1580/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5172 - val_loss: 192.8102\n",
      "Epoch 1581/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5970 - val_loss: 195.4224\n",
      "Epoch 1582/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9144 - val_loss: 195.6812\n",
      "Epoch 1583/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5374 - val_loss: 193.4734\n",
      "Epoch 1584/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7114 - val_loss: 195.1674\n",
      "Epoch 1585/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8799 - val_loss: 195.5330\n",
      "Epoch 1586/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7422 - val_loss: 195.6395\n",
      "Epoch 1587/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6729 - val_loss: 192.7846\n",
      "Epoch 1588/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5294 - val_loss: 197.6685\n",
      "Epoch 1589/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5903 - val_loss: 193.5720\n",
      "Epoch 1590/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4742 - val_loss: 192.5496\n",
      "Epoch 1591/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5454 - val_loss: 195.1846\n",
      "Epoch 1592/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6665 - val_loss: 195.6677\n",
      "Epoch 1593/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5032 - val_loss: 191.9099\n",
      "Epoch 1594/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7958 - val_loss: 194.5765\n",
      "Epoch 1595/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6331 - val_loss: 192.5331\n",
      "Epoch 1596/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6983 - val_loss: 194.2052\n",
      "Epoch 1597/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5837 - val_loss: 197.0616\n",
      "Epoch 1598/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7465 - val_loss: 194.3401\n",
      "Epoch 1599/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7864 - val_loss: 195.9565\n",
      "Epoch 1600/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5542 - val_loss: 192.5702\n",
      "Epoch 1601/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5873 - val_loss: 193.7770\n",
      "Epoch 1602/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8782 - val_loss: 195.0103\n",
      "Epoch 1603/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6938 - val_loss: 193.9820\n",
      "Epoch 1604/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7736 - val_loss: 192.1772\n",
      "Epoch 1605/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7939 - val_loss: 191.9432\n",
      "Epoch 1606/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4059 - val_loss: 194.5810\n",
      "Epoch 1607/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6752 - val_loss: 193.0412\n",
      "Epoch 1608/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7688 - val_loss: 194.5464\n",
      "Epoch 1609/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8074 - val_loss: 198.6053\n",
      "Epoch 1610/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7850 - val_loss: 195.1074\n",
      "Epoch 1611/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5121 - val_loss: 198.4362\n",
      "Epoch 1612/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7110 - val_loss: 192.4817\n",
      "Epoch 1613/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4568 - val_loss: 195.8627\n",
      "Epoch 1614/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6181 - val_loss: 194.5954\n",
      "Epoch 1615/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4653 - val_loss: 193.9472\n",
      "Epoch 1616/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5500 - val_loss: 192.6558\n",
      "Epoch 1617/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5386 - val_loss: 194.6339\n",
      "Epoch 1618/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6659 - val_loss: 192.9058\n",
      "Epoch 1619/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6292 - val_loss: 194.7347\n",
      "Epoch 1620/20000\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 70.5279 - val_loss: 194.2268\n",
      "Epoch 1621/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7510 - val_loss: 192.3085\n",
      "Epoch 1622/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5963 - val_loss: 196.3363\n",
      "Epoch 1623/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0752 - val_loss: 194.6888\n",
      "Epoch 1624/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7774 - val_loss: 193.7108\n",
      "Epoch 1625/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7838 - val_loss: 192.4420\n",
      "Epoch 1626/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3377 - val_loss: 194.1884\n",
      "Epoch 1627/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7239 - val_loss: 193.1391\n",
      "Epoch 1628/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7669 - val_loss: 193.0737\n",
      "Epoch 1629/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6722 - val_loss: 191.6510\n",
      "Epoch 1630/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5602 - val_loss: 193.0994\n",
      "Epoch 1631/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7362 - val_loss: 192.7456\n",
      "Epoch 1632/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5908 - val_loss: 192.9344\n",
      "Epoch 1633/20000\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 70.5548 - val_loss: 193.5600\n",
      "Epoch 1634/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.6206 - val_loss: 193.5126\n",
      "Epoch 1635/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5553 - val_loss: 193.9406\n",
      "Epoch 1636/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6829 - val_loss: 194.0559\n",
      "Epoch 1637/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8448 - val_loss: 190.9778\n",
      "Epoch 1638/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8545 - val_loss: 192.2375\n",
      "Epoch 1639/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6689 - val_loss: 195.3945\n",
      "Epoch 1640/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8224 - val_loss: 193.1710\n",
      "Epoch 1641/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3905 - val_loss: 193.9641\n",
      "Epoch 1642/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5727 - val_loss: 195.7455\n",
      "Epoch 1643/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6319 - val_loss: 196.2970\n",
      "Epoch 1644/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5079 - val_loss: 195.2972\n",
      "Epoch 1645/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5741 - val_loss: 195.3489\n",
      "Epoch 1646/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5573 - val_loss: 195.8501\n",
      "Epoch 1647/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6845 - val_loss: 193.2202\n",
      "Epoch 1648/20000\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 70.9257 - val_loss: 194.4144\n",
      "Epoch 1649/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.6105 - val_loss: 191.6624\n",
      "Epoch 1650/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5512 - val_loss: 194.7371\n",
      "Epoch 1651/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9652 - val_loss: 193.6859\n",
      "Epoch 1652/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4651 - val_loss: 192.7912\n",
      "Epoch 1653/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5317 - val_loss: 195.3174\n",
      "Epoch 1654/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5007 - val_loss: 193.3643\n",
      "Epoch 1655/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3655 - val_loss: 194.6161\n",
      "Epoch 1656/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7871 - val_loss: 187.8998\n",
      "Epoch 1657/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7546 - val_loss: 192.4059\n",
      "Epoch 1658/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8043 - val_loss: 197.0568\n",
      "Epoch 1659/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4895 - val_loss: 195.6129\n",
      "Epoch 1660/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4011 - val_loss: 193.8631\n",
      "Epoch 1661/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8631 - val_loss: 194.7369\n",
      "Epoch 1662/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4677 - val_loss: 192.9320\n",
      "Epoch 1663/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8082 - val_loss: 195.1851\n",
      "Epoch 1664/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6354 - val_loss: 194.0400\n",
      "Epoch 1665/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6453 - val_loss: 195.2452\n",
      "Epoch 1666/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6620 - val_loss: 193.5545\n",
      "Epoch 1667/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7232 - val_loss: 194.7303\n",
      "Epoch 1668/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9483 - val_loss: 192.7906\n",
      "Epoch 1669/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8891 - val_loss: 192.5992\n",
      "Epoch 1670/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4220 - val_loss: 194.6939\n",
      "Epoch 1671/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5039 - val_loss: 194.6484\n",
      "Epoch 1672/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8686 - val_loss: 194.0677\n",
      "Epoch 1673/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7063 - val_loss: 197.4270\n",
      "Epoch 1674/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6498 - val_loss: 195.3247\n",
      "Epoch 1675/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6070 - val_loss: 193.4005\n",
      "Epoch 1676/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8868 - val_loss: 193.9351\n",
      "Epoch 1677/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5108 - val_loss: 194.6181\n",
      "Epoch 1678/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7472 - val_loss: 190.2439\n",
      "Epoch 1679/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7572 - val_loss: 193.8147\n",
      "Epoch 1680/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3720 - val_loss: 193.3543\n",
      "Epoch 1681/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7885 - val_loss: 193.1824\n",
      "Epoch 1682/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6546 - val_loss: 191.4182\n",
      "Epoch 1683/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5912 - val_loss: 192.7388\n",
      "Epoch 1684/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9437 - val_loss: 194.2256\n",
      "Epoch 1685/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9723 - val_loss: 193.2298\n",
      "Epoch 1686/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5647 - val_loss: 190.1821\n",
      "Epoch 1687/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4774 - val_loss: 195.4368\n",
      "Epoch 1688/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5152 - val_loss: 193.4801\n",
      "Epoch 1689/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4696 - val_loss: 193.4648\n",
      "Epoch 1690/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6766 - val_loss: 194.0058\n",
      "Epoch 1691/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5319 - val_loss: 190.6955\n",
      "Epoch 1692/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9824 - val_loss: 193.0558\n",
      "Epoch 1693/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5976 - val_loss: 193.2699\n",
      "Epoch 1694/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4677 - val_loss: 195.2873\n",
      "Epoch 1695/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6247 - val_loss: 197.2898\n",
      "Epoch 1696/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7922 - val_loss: 191.4111\n",
      "Epoch 1697/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6799 - val_loss: 193.3972\n",
      "Epoch 1698/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6505 - val_loss: 193.0224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1699/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9458 - val_loss: 189.4463\n",
      "Epoch 1700/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1026 - val_loss: 192.7211\n",
      "Epoch 1701/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7422 - val_loss: 192.0751\n",
      "Epoch 1702/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6030 - val_loss: 193.7693\n",
      "Epoch 1703/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6603 - val_loss: 193.4278\n",
      "Epoch 1704/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6547 - val_loss: 194.6341\n",
      "Epoch 1705/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4959 - val_loss: 193.5730\n",
      "Epoch 1706/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4733 - val_loss: 193.8229\n",
      "Epoch 1707/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4190 - val_loss: 195.5204\n",
      "Epoch 1708/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4648 - val_loss: 194.6610\n",
      "Epoch 1709/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7248 - val_loss: 194.2640\n",
      "Epoch 1710/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8697 - val_loss: 196.6414\n",
      "Epoch 1711/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5835 - val_loss: 195.0396\n",
      "Epoch 1712/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3921 - val_loss: 192.2673\n",
      "Epoch 1713/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6511 - val_loss: 194.5422\n",
      "Epoch 1714/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7223 - val_loss: 193.2589\n",
      "Epoch 1715/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8694 - val_loss: 192.7306\n",
      "Epoch 1716/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5043 - val_loss: 195.4396\n",
      "Epoch 1717/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6456 - val_loss: 196.7820\n",
      "Epoch 1718/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6307 - val_loss: 193.9733\n",
      "Epoch 1719/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5897 - val_loss: 194.1092\n",
      "Epoch 1720/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5738 - val_loss: 196.4142\n",
      "Epoch 1721/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2874 - val_loss: 193.7340\n",
      "Epoch 1722/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8811 - val_loss: 193.1114\n",
      "Epoch 1723/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6632 - val_loss: 194.0186\n",
      "Epoch 1724/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5397 - val_loss: 197.5279\n",
      "Epoch 1725/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6007 - val_loss: 193.3185\n",
      "Epoch 1726/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9950 - val_loss: 192.8954\n",
      "Epoch 1727/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9022 - val_loss: 193.7296\n",
      "Epoch 1728/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6577 - val_loss: 191.2077\n",
      "Epoch 1729/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5355 - val_loss: 193.9905\n",
      "Epoch 1730/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6200 - val_loss: 194.1837\n",
      "Epoch 1731/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6154 - val_loss: 195.3481\n",
      "Epoch 1732/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6049 - val_loss: 195.0802\n",
      "Epoch 1733/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4564 - val_loss: 194.8241\n",
      "Epoch 1734/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7796 - val_loss: 195.0513\n",
      "Epoch 1735/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5994 - val_loss: 193.9010\n",
      "Epoch 1736/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7673 - val_loss: 196.7691\n",
      "Epoch 1737/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5350 - val_loss: 194.3266\n",
      "Epoch 1738/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6115 - val_loss: 194.2467\n",
      "Epoch 1739/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6517 - val_loss: 191.9274\n",
      "Epoch 1740/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6915 - val_loss: 194.3222\n",
      "Epoch 1741/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5625 - val_loss: 194.5947\n",
      "Epoch 1742/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4596 - val_loss: 195.9108\n",
      "Epoch 1743/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7669 - val_loss: 190.9358\n",
      "Epoch 1744/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8106 - val_loss: 194.7375\n",
      "Epoch 1745/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.3001 - val_loss: 194.2009\n",
      "Epoch 1746/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7266 - val_loss: 193.3079\n",
      "Epoch 1747/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9641 - val_loss: 189.9526\n",
      "Epoch 1748/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6343 - val_loss: 194.4852\n",
      "Epoch 1749/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7516 - val_loss: 192.6513\n",
      "Epoch 1750/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8602 - val_loss: 193.3545\n",
      "Epoch 1751/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1905 - val_loss: 195.8017\n",
      "Epoch 1752/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8009 - val_loss: 192.7092\n",
      "Epoch 1753/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9800 - val_loss: 190.6010\n",
      "Epoch 1754/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5903 - val_loss: 192.9332\n",
      "Epoch 1755/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6422 - val_loss: 195.4158\n",
      "Epoch 1756/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3412 - val_loss: 190.9339\n",
      "Epoch 1757/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6222 - val_loss: 194.7222\n",
      "Epoch 1758/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8261 - val_loss: 194.0946\n",
      "Epoch 1759/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7093 - val_loss: 194.6592\n",
      "Epoch 1760/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5914 - val_loss: 195.3353\n",
      "Epoch 1761/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8691 - val_loss: 193.0401\n",
      "Epoch 1762/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5263 - val_loss: 193.5172\n",
      "Epoch 1763/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4557 - val_loss: 190.4901\n",
      "Epoch 1764/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5982 - val_loss: 193.0009\n",
      "Epoch 1765/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9777 - val_loss: 193.8809\n",
      "Epoch 1766/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.1587 - val_loss: 194.5999\n",
      "Epoch 1767/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3301 - val_loss: 194.3201\n",
      "Epoch 1768/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5732 - val_loss: 190.9098\n",
      "Epoch 1769/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7037 - val_loss: 194.2204\n",
      "Epoch 1770/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6670 - val_loss: 197.3254\n",
      "Epoch 1771/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5970 - val_loss: 193.7789\n",
      "Epoch 1772/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5841 - val_loss: 193.3312\n",
      "Epoch 1773/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5382 - val_loss: 192.3424\n",
      "Epoch 1774/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4046 - val_loss: 194.7358\n",
      "Epoch 1775/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4381 - val_loss: 193.7054\n",
      "Epoch 1776/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8321 - val_loss: 193.9440\n",
      "Epoch 1777/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4441 - val_loss: 197.3282\n",
      "Epoch 1778/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7134 - val_loss: 191.0869\n",
      "Epoch 1779/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6448 - val_loss: 193.3935\n",
      "Epoch 1780/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7035 - val_loss: 194.2735\n",
      "Epoch 1781/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6374 - val_loss: 194.6527\n",
      "Epoch 1782/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8392 - val_loss: 193.7598\n",
      "Epoch 1783/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4874 - val_loss: 195.6287\n",
      "Epoch 1784/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5643 - val_loss: 194.3503\n",
      "Epoch 1785/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5440 - val_loss: 194.0249\n",
      "Epoch 1786/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6274 - val_loss: 191.8131\n",
      "Epoch 1787/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7423 - val_loss: 192.7050\n",
      "Epoch 1788/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4649 - val_loss: 192.2149\n",
      "Epoch 1789/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8109 - val_loss: 193.8615\n",
      "Epoch 1790/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5236 - val_loss: 196.8019\n",
      "Epoch 1791/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8275 - val_loss: 192.6287\n",
      "Epoch 1792/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6865 - val_loss: 193.4485\n",
      "Epoch 1793/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8093 - val_loss: 192.3997\n",
      "Epoch 1794/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7840 - val_loss: 194.1644\n",
      "Epoch 1795/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7472 - val_loss: 193.7992\n",
      "Epoch 1796/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6272 - val_loss: 192.5383\n",
      "Epoch 1797/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6080 - val_loss: 195.8443\n",
      "Epoch 1798/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2332 - val_loss: 192.7554\n",
      "Epoch 1799/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6560 - val_loss: 192.0972\n",
      "Epoch 1800/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6236 - val_loss: 193.3803\n",
      "Epoch 1801/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4624 - val_loss: 191.6732\n",
      "Epoch 1802/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4296 - val_loss: 194.5690\n",
      "Epoch 1803/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5751 - val_loss: 192.8395\n",
      "Epoch 1804/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7387 - val_loss: 197.4077\n",
      "Epoch 1805/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5842 - val_loss: 193.5820\n",
      "Epoch 1806/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4812 - val_loss: 192.2561\n",
      "Epoch 1807/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6987 - val_loss: 192.6007\n",
      "Epoch 1808/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5720 - val_loss: 193.3290\n",
      "Epoch 1809/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6969 - val_loss: 194.2413\n",
      "Epoch 1810/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9331 - val_loss: 190.5818\n",
      "Epoch 1811/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5864 - val_loss: 194.8060\n",
      "Epoch 1812/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8678 - val_loss: 193.8363\n",
      "Epoch 1813/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9577 - val_loss: 193.5272\n",
      "Epoch 1814/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9529 - val_loss: 192.6967\n",
      "Epoch 1815/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9307 - val_loss: 196.1153\n",
      "Epoch 1816/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6664 - val_loss: 192.9875\n",
      "Epoch 1817/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8360 - val_loss: 192.0505\n",
      "Epoch 1818/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8053 - val_loss: 193.9684\n",
      "Epoch 1819/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6367 - val_loss: 194.4645\n",
      "Epoch 1820/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7901 - val_loss: 194.0119\n",
      "Epoch 1821/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4663 - val_loss: 192.4126\n",
      "Epoch 1822/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4789 - val_loss: 194.3695\n",
      "Epoch 1823/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6770 - val_loss: 193.8945\n",
      "Epoch 1824/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3418 - val_loss: 194.7851\n",
      "Epoch 1825/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5569 - val_loss: 193.3776\n",
      "Epoch 1826/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6166 - val_loss: 194.3023\n",
      "Epoch 1827/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5106 - val_loss: 192.1060\n",
      "Epoch 1828/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6170 - val_loss: 192.3560\n",
      "Epoch 1829/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5979 - val_loss: 193.7550\n",
      "Epoch 1830/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7935 - val_loss: 192.8675\n",
      "Epoch 1831/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4278 - val_loss: 194.3211\n",
      "Epoch 1832/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6025 - val_loss: 190.5662\n",
      "Epoch 1833/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7053 - val_loss: 192.8607\n",
      "Epoch 1834/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7803 - val_loss: 192.8815\n",
      "Epoch 1835/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3475 - val_loss: 196.7892\n",
      "Epoch 1836/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9539 - val_loss: 192.7905\n",
      "Epoch 1837/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8725 - val_loss: 193.9145\n",
      "Epoch 1838/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5363 - val_loss: 193.2350\n",
      "Epoch 1839/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5987 - val_loss: 195.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1840/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9118 - val_loss: 193.7373\n",
      "Epoch 1841/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4535 - val_loss: 196.6645\n",
      "Epoch 1842/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6758 - val_loss: 197.7762\n",
      "Epoch 1843/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6890 - val_loss: 194.5838\n",
      "Epoch 1844/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7734 - val_loss: 196.2597\n",
      "Epoch 1845/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6959 - val_loss: 193.1060\n",
      "Epoch 1846/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7984 - val_loss: 191.9762\n",
      "Epoch 1847/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0419 - val_loss: 192.9665\n",
      "Epoch 1848/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4051 - val_loss: 191.0266\n",
      "Epoch 1849/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7317 - val_loss: 194.3252\n",
      "Epoch 1850/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4746 - val_loss: 192.3418\n",
      "Epoch 1851/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4721 - val_loss: 193.3805\n",
      "Epoch 1852/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5854 - val_loss: 192.6776\n",
      "Epoch 1853/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6986 - val_loss: 196.7071\n",
      "Epoch 1854/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6207 - val_loss: 192.1951\n",
      "Epoch 1855/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7961 - val_loss: 193.4763\n",
      "Epoch 1856/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5826 - val_loss: 192.0394\n",
      "Epoch 1857/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5074 - val_loss: 196.3920\n",
      "Epoch 1858/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8819 - val_loss: 195.6254\n",
      "Epoch 1859/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9594 - val_loss: 192.9471\n",
      "Epoch 1860/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8198 - val_loss: 193.8455\n",
      "Epoch 1861/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6761 - val_loss: 194.0364\n",
      "Epoch 1862/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6707 - val_loss: 195.0396\n",
      "Epoch 1863/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7032 - val_loss: 196.0230\n",
      "Epoch 1864/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7068 - val_loss: 195.6279\n",
      "Epoch 1865/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6640 - val_loss: 193.4597\n",
      "Epoch 1866/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4811 - val_loss: 194.0120\n",
      "Epoch 1867/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4048 - val_loss: 193.0874\n",
      "Epoch 1868/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9206 - val_loss: 195.4385\n",
      "Epoch 1869/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6883 - val_loss: 193.3322\n",
      "Epoch 1870/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4998 - val_loss: 195.3315\n",
      "Epoch 1871/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5687 - val_loss: 192.6127\n",
      "Epoch 1872/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6808 - val_loss: 190.4805\n",
      "Epoch 1873/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7718 - val_loss: 191.8218\n",
      "Epoch 1874/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6134 - val_loss: 191.2175\n",
      "Epoch 1875/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7907 - val_loss: 194.1495\n",
      "Epoch 1876/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5433 - val_loss: 193.4735\n",
      "Epoch 1877/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7370 - val_loss: 193.2780\n",
      "Epoch 1878/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4985 - val_loss: 194.4619\n",
      "Epoch 1879/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6235 - val_loss: 196.1292\n",
      "Epoch 1880/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5843 - val_loss: 193.3963\n",
      "Epoch 1881/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4083 - val_loss: 194.0559\n",
      "Epoch 1882/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7629 - val_loss: 192.6596\n",
      "Epoch 1883/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4715 - val_loss: 196.5077\n",
      "Epoch 1884/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5579 - val_loss: 193.0568\n",
      "Epoch 1885/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5488 - val_loss: 194.9603\n",
      "Epoch 1886/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7220 - val_loss: 193.5920\n",
      "Epoch 1887/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8474 - val_loss: 193.1101\n",
      "Epoch 1888/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5959 - val_loss: 194.1899\n",
      "Epoch 1889/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3619 - val_loss: 194.1161\n",
      "Epoch 1890/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6126 - val_loss: 195.3781\n",
      "Epoch 1891/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7772 - val_loss: 196.6874\n",
      "Epoch 1892/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0281 - val_loss: 195.3932\n",
      "Epoch 1893/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5684 - val_loss: 193.9618\n",
      "Epoch 1894/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7768 - val_loss: 195.4240\n",
      "Epoch 1895/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6196 - val_loss: 193.8817\n",
      "Epoch 1896/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8589 - val_loss: 197.3118\n",
      "Epoch 1897/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7361 - val_loss: 194.2117\n",
      "Epoch 1898/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1972 - val_loss: 194.8538\n",
      "Epoch 1899/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7983 - val_loss: 195.0272\n",
      "Epoch 1900/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7543 - val_loss: 195.7838\n",
      "Epoch 1901/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5678 - val_loss: 194.3082\n",
      "Epoch 1902/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4239 - val_loss: 193.5910\n",
      "Epoch 1903/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5218 - val_loss: 195.6239\n",
      "Epoch 1904/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5897 - val_loss: 194.7304\n",
      "Epoch 1905/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5877 - val_loss: 193.7396\n",
      "Epoch 1906/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6554 - val_loss: 195.9451\n",
      "Epoch 1907/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4376 - val_loss: 193.0092\n",
      "Epoch 1908/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7205 - val_loss: 194.1621\n",
      "Epoch 1909/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5007 - val_loss: 195.6046\n",
      "Epoch 1910/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7755 - val_loss: 195.4220\n",
      "Epoch 1911/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6527 - val_loss: 193.4768\n",
      "Epoch 1912/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6120 - val_loss: 193.9067\n",
      "Epoch 1913/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4917 - val_loss: 197.2084\n",
      "Epoch 1914/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6316 - val_loss: 196.5000\n",
      "Epoch 1915/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7141 - val_loss: 193.8116\n",
      "Epoch 1916/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6405 - val_loss: 195.4550\n",
      "Epoch 1917/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6946 - val_loss: 194.6431\n",
      "Epoch 1918/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7986 - val_loss: 195.0272\n",
      "Epoch 1919/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5759 - val_loss: 193.0755\n",
      "Epoch 1920/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4647 - val_loss: 193.3210\n",
      "Epoch 1921/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3472 - val_loss: 191.9283\n",
      "Epoch 1922/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4515 - val_loss: 193.4454\n",
      "Epoch 1923/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7229 - val_loss: 194.2231\n",
      "Epoch 1924/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6745 - val_loss: 191.1859\n",
      "Epoch 1925/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6079 - val_loss: 191.7390\n",
      "Epoch 1926/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4638 - val_loss: 195.7062\n",
      "Epoch 1927/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6984 - val_loss: 195.3278\n",
      "Epoch 1928/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6048 - val_loss: 195.7272\n",
      "Epoch 1929/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5143 - val_loss: 196.1910\n",
      "Epoch 1930/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5102 - val_loss: 197.1121\n",
      "Epoch 1931/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7722 - val_loss: 194.6651\n",
      "Epoch 1932/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0146 - val_loss: 193.8507\n",
      "Epoch 1933/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4925 - val_loss: 194.3105\n",
      "Epoch 1934/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7046 - val_loss: 192.7895\n",
      "Epoch 1935/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6413 - val_loss: 193.5686\n",
      "Epoch 1936/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5889 - val_loss: 196.3688\n",
      "Epoch 1937/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3937 - val_loss: 191.5422\n",
      "Epoch 1938/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7175 - val_loss: 191.7853\n",
      "Epoch 1939/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5030 - val_loss: 195.0144\n",
      "Epoch 1940/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6196 - val_loss: 195.4808\n",
      "Epoch 1941/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7354 - val_loss: 194.4533\n",
      "Epoch 1942/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5103 - val_loss: 194.5823\n",
      "Epoch 1943/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0689 - val_loss: 194.6172\n",
      "Epoch 1944/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5713 - val_loss: 196.3329\n",
      "Epoch 1945/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6123 - val_loss: 195.4951\n",
      "Epoch 1946/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6067 - val_loss: 192.7579\n",
      "Epoch 1947/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6030 - val_loss: 193.0189\n",
      "Epoch 1948/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6856 - val_loss: 192.3549\n",
      "Epoch 1949/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5369 - val_loss: 192.5846\n",
      "Epoch 1950/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5948 - val_loss: 193.2888\n",
      "Epoch 1951/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6186 - val_loss: 193.4600\n",
      "Epoch 1952/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6761 - val_loss: 192.8026\n",
      "Epoch 1953/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6704 - val_loss: 194.8212\n",
      "Epoch 1954/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4696 - val_loss: 192.2799\n",
      "Epoch 1955/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7375 - val_loss: 192.0978\n",
      "Epoch 1956/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5442 - val_loss: 191.9269\n",
      "Epoch 1957/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4477 - val_loss: 196.3604\n",
      "Epoch 1958/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5714 - val_loss: 191.3340\n",
      "Epoch 1959/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8177 - val_loss: 196.8111\n",
      "Epoch 1960/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4140 - val_loss: 193.5240\n",
      "Epoch 1961/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7091 - val_loss: 196.6018\n",
      "Epoch 1962/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6004 - val_loss: 193.1363\n",
      "Epoch 1963/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5161 - val_loss: 193.0579\n",
      "Epoch 1964/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7342 - val_loss: 191.9191\n",
      "Epoch 1965/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6480 - val_loss: 192.8332\n",
      "Epoch 1966/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6818 - val_loss: 192.2095\n",
      "Epoch 1967/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8376 - val_loss: 194.3934\n",
      "Epoch 1968/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6990 - val_loss: 194.2287\n",
      "Epoch 1969/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3313 - val_loss: 193.2023\n",
      "Epoch 1970/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6983 - val_loss: 193.6539\n",
      "Epoch 1971/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3789 - val_loss: 197.9230\n",
      "Epoch 1972/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3955 - val_loss: 192.9239\n",
      "Epoch 1973/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5234 - val_loss: 192.5718\n",
      "Epoch 1974/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7145 - val_loss: 194.6141\n",
      "Epoch 1975/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6222 - val_loss: 193.0381\n",
      "Epoch 1976/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4592 - val_loss: 194.1819\n",
      "Epoch 1977/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5981 - val_loss: 191.3084\n",
      "Epoch 1978/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7064 - val_loss: 195.4363\n",
      "Epoch 1979/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6625 - val_loss: 194.6316\n",
      "Epoch 1980/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3973 - val_loss: 196.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1981/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9098 - val_loss: 191.2683\n",
      "Epoch 1982/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8149 - val_loss: 193.8114\n",
      "Epoch 1983/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4393 - val_loss: 191.8671\n",
      "Epoch 1984/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6528 - val_loss: 195.0711\n",
      "Epoch 1985/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1558 - val_loss: 194.1568\n",
      "Epoch 1986/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8456 - val_loss: 193.7499\n",
      "Epoch 1987/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6643 - val_loss: 195.9786\n",
      "Epoch 1988/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7781 - val_loss: 193.5765\n",
      "Epoch 1989/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4504 - val_loss: 194.4586\n",
      "Epoch 1990/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5007 - val_loss: 192.7463\n",
      "Epoch 1991/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6862 - val_loss: 196.7442\n",
      "Epoch 1992/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7729 - val_loss: 190.0483\n",
      "Epoch 1993/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4715 - val_loss: 192.3450\n",
      "Epoch 1994/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.9103 - val_loss: 194.8908\n",
      "Epoch 1995/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7913 - val_loss: 192.9400\n",
      "Epoch 1996/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4483 - val_loss: 192.6830\n",
      "Epoch 1997/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6890 - val_loss: 195.9331\n",
      "Epoch 1998/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5933 - val_loss: 193.9180\n",
      "Epoch 1999/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5776 - val_loss: 194.0028\n",
      "Epoch 2000/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7124 - val_loss: 196.5120\n",
      "Epoch 2001/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6084 - val_loss: 197.6645\n",
      "Epoch 2002/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7843 - val_loss: 194.4918\n",
      "Epoch 2003/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5367 - val_loss: 194.0692\n",
      "Epoch 2004/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8757 - val_loss: 191.4383\n",
      "Epoch 2005/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6582 - val_loss: 192.5158\n",
      "Epoch 2006/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7276 - val_loss: 194.7860\n",
      "Epoch 2007/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7440 - val_loss: 190.7227\n",
      "Epoch 2008/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7774 - val_loss: 192.8856\n",
      "Epoch 2009/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6656 - val_loss: 196.3192\n",
      "Epoch 2010/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8386 - val_loss: 190.5431\n",
      "Epoch 2011/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6059 - val_loss: 194.7574\n",
      "Epoch 2012/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6505 - val_loss: 191.2294\n",
      "Epoch 2013/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4570 - val_loss: 193.1345\n",
      "Epoch 2014/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7653 - val_loss: 191.6391\n",
      "Epoch 2015/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4468 - val_loss: 193.7317\n",
      "Epoch 2016/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5003 - val_loss: 194.2892\n",
      "Epoch 2017/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5411 - val_loss: 195.1285\n",
      "Epoch 2018/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4156 - val_loss: 193.9311\n",
      "Epoch 2019/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3948 - val_loss: 194.0272\n",
      "Epoch 2020/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4386 - val_loss: 193.5186\n",
      "Epoch 2021/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9531 - val_loss: 194.7812\n",
      "Epoch 2022/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6661 - val_loss: 193.4904\n",
      "Epoch 2023/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5105 - val_loss: 195.0216\n",
      "Epoch 2024/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6525 - val_loss: 194.2369\n",
      "Epoch 2025/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2829 - val_loss: 192.9035\n",
      "Epoch 2026/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7142 - val_loss: 192.2648\n",
      "Epoch 2027/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5335 - val_loss: 192.6471\n",
      "Epoch 2028/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8047 - val_loss: 192.9429\n",
      "Epoch 2029/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5438 - val_loss: 193.4499\n",
      "Epoch 2030/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7899 - val_loss: 194.6297\n",
      "Epoch 2031/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5615 - val_loss: 192.3294\n",
      "Epoch 2032/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6033 - val_loss: 194.2984\n",
      "Epoch 2033/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7340 - val_loss: 191.4853\n",
      "Epoch 2034/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8591 - val_loss: 194.7649\n",
      "Epoch 2035/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6137 - val_loss: 190.9790\n",
      "Epoch 2036/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9897 - val_loss: 194.8409\n",
      "Epoch 2037/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4495 - val_loss: 194.3226\n",
      "Epoch 2038/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6819 - val_loss: 192.8922\n",
      "Epoch 2039/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7714 - val_loss: 196.0650\n",
      "Epoch 2040/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7878 - val_loss: 196.2536\n",
      "Epoch 2041/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6878 - val_loss: 193.0657\n",
      "Epoch 2042/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6536 - val_loss: 194.0359\n",
      "Epoch 2043/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6567 - val_loss: 191.4997\n",
      "Epoch 2044/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6307 - val_loss: 193.8335\n",
      "Epoch 2045/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5403 - val_loss: 194.2854\n",
      "Epoch 2046/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8238 - val_loss: 193.1230\n",
      "Epoch 2047/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4312 - val_loss: 194.0246\n",
      "Epoch 2048/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7344 - val_loss: 194.7725\n",
      "Epoch 2049/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7627 - val_loss: 193.9651\n",
      "Epoch 2050/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4211 - val_loss: 192.9870\n",
      "Epoch 2051/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7487 - val_loss: 194.3525\n",
      "Epoch 2052/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7639 - val_loss: 193.2437\n",
      "Epoch 2053/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5191 - val_loss: 193.5498\n",
      "Epoch 2054/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6846 - val_loss: 194.5018\n",
      "Epoch 2055/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3965 - val_loss: 191.9507\n",
      "Epoch 2056/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7054 - val_loss: 192.5286\n",
      "Epoch 2057/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6249 - val_loss: 195.9267\n",
      "Epoch 2058/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5212 - val_loss: 192.1074\n",
      "Epoch 2059/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6068 - val_loss: 192.5033\n",
      "Epoch 2060/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6302 - val_loss: 197.3809\n",
      "Epoch 2061/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6058 - val_loss: 192.5166\n",
      "Epoch 2062/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6835 - val_loss: 193.3769\n",
      "Epoch 2063/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5648 - val_loss: 194.1268\n",
      "Epoch 2064/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4747 - val_loss: 191.4991\n",
      "Epoch 2065/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7026 - val_loss: 193.9242\n",
      "Epoch 2066/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8627 - val_loss: 190.9184\n",
      "Epoch 2067/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3823 - val_loss: 197.4763\n",
      "Epoch 2068/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6478 - val_loss: 192.1038\n",
      "Epoch 2069/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5954 - val_loss: 193.2364\n",
      "Epoch 2070/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6567 - val_loss: 193.4502\n",
      "Epoch 2071/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8765 - val_loss: 194.5552\n",
      "Epoch 2072/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4921 - val_loss: 195.7641\n",
      "Epoch 2073/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5543 - val_loss: 194.9837\n",
      "Epoch 2074/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7514 - val_loss: 193.3827\n",
      "Epoch 2075/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4652 - val_loss: 190.5371\n",
      "Epoch 2076/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7545 - val_loss: 194.9179\n",
      "Epoch 2077/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7825 - val_loss: 195.0626\n",
      "Epoch 2078/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1907 - val_loss: 194.2622\n",
      "Epoch 2079/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5763 - val_loss: 194.4461\n",
      "Epoch 2080/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0293 - val_loss: 196.5331\n",
      "Epoch 2081/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5449 - val_loss: 193.6169\n",
      "Epoch 2082/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3682 - val_loss: 194.4780\n",
      "Epoch 2083/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5402 - val_loss: 194.1007\n",
      "Epoch 2084/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5286 - val_loss: 193.9673\n",
      "Epoch 2085/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5155 - val_loss: 193.7612\n",
      "Epoch 2086/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4414 - val_loss: 193.0477\n",
      "Epoch 2087/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4779 - val_loss: 195.2667\n",
      "Epoch 2088/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5555 - val_loss: 194.4992\n",
      "Epoch 2089/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6034 - val_loss: 194.8600\n",
      "Epoch 2090/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7895 - val_loss: 195.8555\n",
      "Epoch 2091/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6206 - val_loss: 195.5496\n",
      "Epoch 2092/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7199 - val_loss: 195.3057\n",
      "Epoch 2093/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3925 - val_loss: 195.1450\n",
      "Epoch 2094/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5609 - val_loss: 196.3428\n",
      "Epoch 2095/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6372 - val_loss: 197.4374\n",
      "Epoch 2096/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5712 - val_loss: 196.0675\n",
      "Epoch 2097/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6459 - val_loss: 193.9803\n",
      "Epoch 2098/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4182 - val_loss: 193.1702\n",
      "Epoch 2099/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5722 - val_loss: 191.8977\n",
      "Epoch 2100/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5137 - val_loss: 191.7280\n",
      "Epoch 2101/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3530 - val_loss: 193.8624\n",
      "Epoch 2102/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6263 - val_loss: 193.6363\n",
      "Epoch 2103/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8441 - val_loss: 196.0080\n",
      "Epoch 2104/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4610 - val_loss: 195.6181\n",
      "Epoch 2105/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4488 - val_loss: 196.0548\n",
      "Epoch 2106/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5815 - val_loss: 196.4064\n",
      "Epoch 2107/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4701 - val_loss: 193.3943\n",
      "Epoch 2108/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4319 - val_loss: 193.7428\n",
      "Epoch 2109/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6002 - val_loss: 194.1815\n",
      "Epoch 2110/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6205 - val_loss: 193.9489\n",
      "Epoch 2111/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6217 - val_loss: 195.9753\n",
      "Epoch 2112/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4720 - val_loss: 198.3276\n",
      "Epoch 2113/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5363 - val_loss: 193.3417\n",
      "Epoch 2114/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3717 - val_loss: 194.9940\n",
      "Epoch 2115/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7714 - val_loss: 194.2634\n",
      "Epoch 2116/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7212 - val_loss: 193.6880\n",
      "Epoch 2117/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4983 - val_loss: 196.2346\n",
      "Epoch 2118/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0031 - val_loss: 191.9027\n",
      "Epoch 2119/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7328 - val_loss: 196.9938\n",
      "Epoch 2120/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2692 - val_loss: 193.3721\n",
      "Epoch 2121/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5648 - val_loss: 197.2147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2122/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5961 - val_loss: 192.3595\n",
      "Epoch 2123/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4464 - val_loss: 194.8013\n",
      "Epoch 2124/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9103 - val_loss: 194.8117\n",
      "Epoch 2125/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5780 - val_loss: 195.6164\n",
      "Epoch 2126/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8328 - val_loss: 193.0145\n",
      "Epoch 2127/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7709 - val_loss: 193.9405\n",
      "Epoch 2128/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4157 - val_loss: 195.8418\n",
      "Epoch 2129/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6006 - val_loss: 195.3118\n",
      "Epoch 2130/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6093 - val_loss: 192.8335\n",
      "Epoch 2131/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7204 - val_loss: 190.5024\n",
      "Epoch 2132/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5618 - val_loss: 196.7815\n",
      "Epoch 2133/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6829 - val_loss: 196.9277\n",
      "Epoch 2134/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9542 - val_loss: 191.7535\n",
      "Epoch 2135/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6109 - val_loss: 193.8070\n",
      "Epoch 2136/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1024 - val_loss: 193.4153\n",
      "Epoch 2137/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6684 - val_loss: 194.7600\n",
      "Epoch 2138/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5941 - val_loss: 196.3297\n",
      "Epoch 2139/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7450 - val_loss: 194.3674\n",
      "Epoch 2140/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5520 - val_loss: 194.7433\n",
      "Epoch 2141/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3666 - val_loss: 196.2960\n",
      "Epoch 2142/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6648 - val_loss: 196.1684\n",
      "Epoch 2143/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7033 - val_loss: 194.4423\n",
      "Epoch 2144/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5967 - val_loss: 195.5553\n",
      "Epoch 2145/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4844 - val_loss: 196.3750\n",
      "Epoch 2146/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7556 - val_loss: 195.9681\n",
      "Epoch 2147/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6681 - val_loss: 195.9041\n",
      "Epoch 2148/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6427 - val_loss: 191.9553\n",
      "Epoch 2149/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6214 - val_loss: 194.5460\n",
      "Epoch 2150/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5594 - val_loss: 191.7597\n",
      "Epoch 2151/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3612 - val_loss: 195.9341\n",
      "Epoch 2152/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7555 - val_loss: 197.1136\n",
      "Epoch 2153/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9647 - val_loss: 192.1781\n",
      "Epoch 2154/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5988 - val_loss: 195.0832\n",
      "Epoch 2155/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7398 - val_loss: 195.8712\n",
      "Epoch 2156/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5632 - val_loss: 192.1795\n",
      "Epoch 2157/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7265 - val_loss: 190.9518\n",
      "Epoch 2158/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3061 - val_loss: 194.5907\n",
      "Epoch 2159/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5501 - val_loss: 193.7081\n",
      "Epoch 2160/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3593 - val_loss: 196.1267\n",
      "Epoch 2161/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7170 - val_loss: 194.7685\n",
      "Epoch 2162/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5071 - val_loss: 195.4673\n",
      "Epoch 2163/20000\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 70.5989 - val_loss: 192.5458\n",
      "Epoch 2164/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.3943 - val_loss: 197.7004\n",
      "Epoch 2165/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5996 - val_loss: 193.1018\n",
      "Epoch 2166/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5010 - val_loss: 194.3498\n",
      "Epoch 2167/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5765 - val_loss: 194.5027\n",
      "Epoch 2168/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4210 - val_loss: 191.4482\n",
      "Epoch 2169/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6233 - val_loss: 194.3600\n",
      "Epoch 2170/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6601 - val_loss: 194.2782\n",
      "Epoch 2171/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5445 - val_loss: 194.9227\n",
      "Epoch 2172/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6628 - val_loss: 194.0068\n",
      "Epoch 2173/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7058 - val_loss: 192.7634\n",
      "Epoch 2174/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7723 - val_loss: 193.7073\n",
      "Epoch 2175/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4220 - val_loss: 195.5001\n",
      "Epoch 2176/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7127 - val_loss: 193.3794\n",
      "Epoch 2177/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5575 - val_loss: 194.8895\n",
      "Epoch 2178/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6806 - val_loss: 192.4575\n",
      "Epoch 2179/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5550 - val_loss: 195.8502\n",
      "Epoch 2180/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7049 - val_loss: 192.8326\n",
      "Epoch 2181/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6101 - val_loss: 194.9585\n",
      "Epoch 2182/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5613 - val_loss: 196.6193\n",
      "Epoch 2183/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6669 - val_loss: 194.6110\n",
      "Epoch 2184/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7120 - val_loss: 195.9972\n",
      "Epoch 2185/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8530 - val_loss: 195.2750\n",
      "Epoch 2186/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3463 - val_loss: 193.7063\n",
      "Epoch 2187/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7362 - val_loss: 193.0162\n",
      "Epoch 2188/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6849 - val_loss: 191.6385\n",
      "Epoch 2189/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6350 - val_loss: 194.0714\n",
      "Epoch 2190/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1263 - val_loss: 196.9774\n",
      "Epoch 2191/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7959 - val_loss: 198.1417\n",
      "Epoch 2192/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7239 - val_loss: 193.9914\n",
      "Epoch 2193/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6594 - val_loss: 191.4566\n",
      "Epoch 2194/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5570 - val_loss: 192.2788\n",
      "Epoch 2195/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7489 - val_loss: 192.3154\n",
      "Epoch 2196/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6261 - val_loss: 194.7203\n",
      "Epoch 2197/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7128 - val_loss: 195.6546\n",
      "Epoch 2198/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7148 - val_loss: 193.3747\n",
      "Epoch 2199/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6662 - val_loss: 195.7825\n",
      "Epoch 2200/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7388 - val_loss: 194.4741\n",
      "Epoch 2201/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8346 - val_loss: 193.3431\n",
      "Epoch 2202/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5184 - val_loss: 191.5979\n",
      "Epoch 2203/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5945 - val_loss: 195.6676\n",
      "Epoch 2204/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7608 - val_loss: 193.3655\n",
      "Epoch 2205/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4278 - val_loss: 198.8053\n",
      "Epoch 2206/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6672 - val_loss: 194.3215\n",
      "Epoch 2207/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5226 - val_loss: 195.8117\n",
      "Epoch 2208/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7319 - val_loss: 191.3438\n",
      "Epoch 2209/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7681 - val_loss: 192.9398\n",
      "Epoch 2210/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5589 - val_loss: 197.5689\n",
      "Epoch 2211/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6771 - val_loss: 195.6601\n",
      "Epoch 2212/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4026 - val_loss: 192.5052\n",
      "Epoch 2213/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8032 - val_loss: 199.4270\n",
      "Epoch 2214/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7289 - val_loss: 193.3458\n",
      "Epoch 2215/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4811 - val_loss: 193.2990\n",
      "Epoch 2216/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4041 - val_loss: 194.6380\n",
      "Epoch 2217/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9412 - val_loss: 194.4443\n",
      "Epoch 2218/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6547 - val_loss: 193.5038\n",
      "Epoch 2219/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5334 - val_loss: 194.0563\n",
      "Epoch 2220/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5040 - val_loss: 193.9655\n",
      "Epoch 2221/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5276 - val_loss: 193.3260\n",
      "Epoch 2222/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5478 - val_loss: 193.7022\n",
      "Epoch 2223/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3910 - val_loss: 194.2492\n",
      "Epoch 2224/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5528 - val_loss: 193.1900\n",
      "Epoch 2225/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7286 - val_loss: 194.3474\n",
      "Epoch 2226/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3151 - val_loss: 196.4831\n",
      "Epoch 2227/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3905 - val_loss: 193.2439\n",
      "Epoch 2228/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7308 - val_loss: 191.7892\n",
      "Epoch 2229/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5881 - val_loss: 193.0362\n",
      "Epoch 2230/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7257 - val_loss: 194.8402\n",
      "Epoch 2231/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0493 - val_loss: 193.8798\n",
      "Epoch 2232/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4556 - val_loss: 198.1123\n",
      "Epoch 2233/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3612 - val_loss: 196.1223\n",
      "Epoch 2234/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7314 - val_loss: 194.3479\n",
      "Epoch 2235/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7075 - val_loss: 194.2858\n",
      "Epoch 2236/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7169 - val_loss: 191.9344\n",
      "Epoch 2237/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4200 - val_loss: 193.8420\n",
      "Epoch 2238/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7755 - val_loss: 192.0571\n",
      "Epoch 2239/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7977 - val_loss: 194.5733\n",
      "Epoch 2240/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4989 - val_loss: 195.2809\n",
      "Epoch 2241/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6617 - val_loss: 196.8207\n",
      "Epoch 2242/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6752 - val_loss: 195.8272\n",
      "Epoch 2243/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4880 - val_loss: 192.4120\n",
      "Epoch 2244/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8965 - val_loss: 193.2076\n",
      "Epoch 2245/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5677 - val_loss: 192.4838\n",
      "Epoch 2246/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8028 - val_loss: 193.3971\n",
      "Epoch 2247/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5955 - val_loss: 193.6693\n",
      "Epoch 2248/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6774 - val_loss: 194.4634\n",
      "Epoch 2249/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3988 - val_loss: 192.4830\n",
      "Epoch 2250/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6343 - val_loss: 193.9779\n",
      "Epoch 2251/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4579 - val_loss: 193.4013\n",
      "Epoch 2252/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5024 - val_loss: 194.0489\n",
      "Epoch 2253/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6873 - val_loss: 194.6676\n",
      "Epoch 2254/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5083 - val_loss: 194.7368\n",
      "Epoch 2255/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5164 - val_loss: 195.1122\n",
      "Epoch 2256/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6217 - val_loss: 196.6726\n",
      "Epoch 2257/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8772 - val_loss: 194.5210\n",
      "Epoch 2258/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5704 - val_loss: 192.1876\n",
      "Epoch 2259/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4857 - val_loss: 195.8617\n",
      "Epoch 2260/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7931 - val_loss: 194.6165\n",
      "Epoch 2261/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4394 - val_loss: 195.8419\n",
      "Epoch 2262/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6153 - val_loss: 193.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2263/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5924 - val_loss: 193.5889\n",
      "Epoch 2264/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4553 - val_loss: 195.7013\n",
      "Epoch 2265/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2962 - val_loss: 193.8256\n",
      "Epoch 2266/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5866 - val_loss: 192.1268\n",
      "Epoch 2267/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5508 - val_loss: 191.9520\n",
      "Epoch 2268/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8186 - val_loss: 194.6817\n",
      "Epoch 2269/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5496 - val_loss: 197.3036\n",
      "Epoch 2270/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6014 - val_loss: 193.5907\n",
      "Epoch 2271/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8050 - val_loss: 196.2827\n",
      "Epoch 2272/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8478 - val_loss: 191.0919\n",
      "Epoch 2273/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7185 - val_loss: 194.5470\n",
      "Epoch 2274/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9116 - val_loss: 197.4972\n",
      "Epoch 2275/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7638 - val_loss: 195.1618\n",
      "Epoch 2276/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3789 - val_loss: 193.8714\n",
      "Epoch 2277/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7455 - val_loss: 192.4869\n",
      "Epoch 2278/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4066 - val_loss: 195.4607\n",
      "Epoch 2279/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4384 - val_loss: 192.4602\n",
      "Epoch 2280/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6458 - val_loss: 195.0541\n",
      "Epoch 2281/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5767 - val_loss: 192.8233\n",
      "Epoch 2282/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5682 - val_loss: 193.5890\n",
      "Epoch 2283/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8337 - val_loss: 193.3418\n",
      "Epoch 2284/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5527 - val_loss: 194.7859\n",
      "Epoch 2285/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4656 - val_loss: 194.3977\n",
      "Epoch 2286/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7357 - val_loss: 197.5171\n",
      "Epoch 2287/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4357 - val_loss: 192.4672\n",
      "Epoch 2288/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2634 - val_loss: 194.0099\n",
      "Epoch 2289/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8357 - val_loss: 197.0378\n",
      "Epoch 2290/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8200 - val_loss: 193.4280\n",
      "Epoch 2291/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6219 - val_loss: 195.4440\n",
      "Epoch 2292/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8229 - val_loss: 195.9327\n",
      "Epoch 2293/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5624 - val_loss: 193.1350\n",
      "Epoch 2294/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5401 - val_loss: 194.2964\n",
      "Epoch 2295/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5253 - val_loss: 194.3504\n",
      "Epoch 2296/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6862 - val_loss: 194.8555\n",
      "Epoch 2297/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4123 - val_loss: 193.1541\n",
      "Epoch 2298/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8081 - val_loss: 193.4818\n",
      "Epoch 2299/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3944 - val_loss: 196.2948\n",
      "Epoch 2300/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4266 - val_loss: 194.0298\n",
      "Epoch 2301/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4413 - val_loss: 197.1553\n",
      "Epoch 2302/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8094 - val_loss: 190.4691\n",
      "Epoch 2303/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7844 - val_loss: 193.0516\n",
      "Epoch 2304/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6330 - val_loss: 193.7808\n",
      "Epoch 2305/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6230 - val_loss: 195.6867\n",
      "Epoch 2306/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3263 - val_loss: 190.7107\n",
      "Epoch 2307/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6605 - val_loss: 191.7268\n",
      "Epoch 2308/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5320 - val_loss: 192.5856\n",
      "Epoch 2309/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6538 - val_loss: 196.1672\n",
      "Epoch 2310/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6247 - val_loss: 192.4884\n",
      "Epoch 2311/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5571 - val_loss: 196.6534\n",
      "Epoch 2312/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8755 - val_loss: 193.8855\n",
      "Epoch 2313/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7088 - val_loss: 194.1858\n",
      "Epoch 2314/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5206 - val_loss: 196.1562\n",
      "Epoch 2315/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6768 - val_loss: 193.1611\n",
      "Epoch 2316/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5978 - val_loss: 192.3165\n",
      "Epoch 2317/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4913 - val_loss: 193.0318\n",
      "Epoch 2318/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6564 - val_loss: 190.5075\n",
      "Epoch 2319/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7330 - val_loss: 194.8036\n",
      "Epoch 2320/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4796 - val_loss: 195.5542\n",
      "Epoch 2321/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5183 - val_loss: 193.2362\n",
      "Epoch 2322/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3638 - val_loss: 192.8260\n",
      "Epoch 2323/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5897 - val_loss: 193.7848\n",
      "Epoch 2324/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2982 - val_loss: 191.0155\n",
      "Epoch 2325/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6567 - val_loss: 192.9898\n",
      "Epoch 2326/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6779 - val_loss: 192.2241\n",
      "Epoch 2327/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4023 - val_loss: 194.6044\n",
      "Epoch 2328/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3889 - val_loss: 193.3996\n",
      "Epoch 2329/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6374 - val_loss: 197.4441\n",
      "Epoch 2330/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5613 - val_loss: 193.7076\n",
      "Epoch 2331/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8057 - val_loss: 194.3307\n",
      "Epoch 2332/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5932 - val_loss: 192.0895\n",
      "Epoch 2333/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6400 - val_loss: 191.3780\n",
      "Epoch 2334/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7249 - val_loss: 194.8487\n",
      "Epoch 2335/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5360 - val_loss: 193.9413\n",
      "Epoch 2336/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4412 - val_loss: 190.1763\n",
      "Epoch 2337/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8332 - val_loss: 194.2327\n",
      "Epoch 2338/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6706 - val_loss: 197.5952\n",
      "Epoch 2339/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6083 - val_loss: 193.1567\n",
      "Epoch 2340/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4774 - val_loss: 195.3767\n",
      "Epoch 2341/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4569 - val_loss: 196.0441\n",
      "Epoch 2342/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6677 - val_loss: 194.9475\n",
      "Epoch 2343/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6789 - val_loss: 193.6291\n",
      "Epoch 2344/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5038 - val_loss: 196.6601\n",
      "Epoch 2345/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4446 - val_loss: 195.7522\n",
      "Epoch 2346/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6855 - val_loss: 193.9028\n",
      "Epoch 2347/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3670 - val_loss: 198.9190\n",
      "Epoch 2348/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8206 - val_loss: 192.9979\n",
      "Epoch 2349/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8144 - val_loss: 193.6008\n",
      "Epoch 2350/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4000 - val_loss: 195.3564\n",
      "Epoch 2351/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1751 - val_loss: 191.1541\n",
      "Epoch 2352/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6533 - val_loss: 194.6202\n",
      "Epoch 2353/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6332 - val_loss: 192.9048\n",
      "Epoch 2354/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4912 - val_loss: 193.0530\n",
      "Epoch 2355/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6392 - val_loss: 194.7995\n",
      "Epoch 2356/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2176 - val_loss: 194.0603\n",
      "Epoch 2357/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.8014 - val_loss: 194.9339\n",
      "Epoch 2358/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5600 - val_loss: 191.3922\n",
      "Epoch 2359/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9810 - val_loss: 193.6054\n",
      "Epoch 2360/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0934 - val_loss: 193.2473\n",
      "Epoch 2361/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7272 - val_loss: 193.5833\n",
      "Epoch 2362/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3776 - val_loss: 194.2538\n",
      "Epoch 2363/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9547 - val_loss: 193.3278\n",
      "Epoch 2364/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4054 - val_loss: 190.8440\n",
      "Epoch 2365/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5693 - val_loss: 191.9608\n",
      "Epoch 2366/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4783 - val_loss: 192.0650\n",
      "Epoch 2367/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8213 - val_loss: 194.0453\n",
      "Epoch 2368/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5000 - val_loss: 191.4325\n",
      "Epoch 2369/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6086 - val_loss: 194.9562\n",
      "Epoch 2370/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5835 - val_loss: 192.3923\n",
      "Epoch 2371/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5609 - val_loss: 195.5452\n",
      "Epoch 2372/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5585 - val_loss: 194.1318\n",
      "Epoch 2373/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9241 - val_loss: 195.9963\n",
      "Epoch 2374/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7889 - val_loss: 197.8337\n",
      "Epoch 2375/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7256 - val_loss: 192.3340\n",
      "Epoch 2376/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5244 - val_loss: 195.8562\n",
      "Epoch 2377/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1950 - val_loss: 193.5472\n",
      "Epoch 2378/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5043 - val_loss: 196.1127\n",
      "Epoch 2379/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7196 - val_loss: 193.1783\n",
      "Epoch 2380/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7417 - val_loss: 195.3876\n",
      "Epoch 2381/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5034 - val_loss: 193.6755\n",
      "Epoch 2382/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6546 - val_loss: 194.3223\n",
      "Epoch 2383/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7341 - val_loss: 193.1161\n",
      "Epoch 2384/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7230 - val_loss: 191.6530\n",
      "Epoch 2385/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6799 - val_loss: 193.5060\n",
      "Epoch 2386/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0176 - val_loss: 192.8896\n",
      "Epoch 2387/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8148 - val_loss: 195.3373\n",
      "Epoch 2388/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3978 - val_loss: 193.3820\n",
      "Epoch 2389/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7404 - val_loss: 192.5074\n",
      "Epoch 2390/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6212 - val_loss: 195.8337\n",
      "Epoch 2391/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5982 - val_loss: 192.4930\n",
      "Epoch 2392/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6356 - val_loss: 197.8271\n",
      "Epoch 2393/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3014 - val_loss: 192.3515\n",
      "Epoch 2394/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7011 - val_loss: 191.0207\n",
      "Epoch 2395/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2732 - val_loss: 194.7779\n",
      "Epoch 2396/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2942 - val_loss: 193.1038\n",
      "Epoch 2397/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4002 - val_loss: 195.2633\n",
      "Epoch 2398/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6258 - val_loss: 193.8113\n",
      "Epoch 2399/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4621 - val_loss: 194.6121\n",
      "Epoch 2400/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7689 - val_loss: 193.2931\n",
      "Epoch 2401/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7525 - val_loss: 193.6593\n",
      "Epoch 2402/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6238 - val_loss: 193.3155\n",
      "Epoch 2403/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6089 - val_loss: 195.8124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2404/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6506 - val_loss: 194.1052\n",
      "Epoch 2405/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8215 - val_loss: 194.0116\n",
      "Epoch 2406/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4910 - val_loss: 194.3722\n",
      "Epoch 2407/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5747 - val_loss: 199.8552\n",
      "Epoch 2408/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5335 - val_loss: 193.2487\n",
      "Epoch 2409/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4886 - val_loss: 194.6056\n",
      "Epoch 2410/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5137 - val_loss: 192.7734\n",
      "Epoch 2411/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5615 - val_loss: 191.5304\n",
      "Epoch 2412/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4892 - val_loss: 193.0091\n",
      "Epoch 2413/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7977 - val_loss: 192.4693\n",
      "Epoch 2414/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3128 - val_loss: 195.0836\n",
      "Epoch 2415/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8754 - val_loss: 195.2254\n",
      "Epoch 2416/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7297 - val_loss: 195.4644\n",
      "Epoch 2417/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4539 - val_loss: 194.6809\n",
      "Epoch 2418/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8083 - val_loss: 192.2102\n",
      "Epoch 2419/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8963 - val_loss: 195.6333\n",
      "Epoch 2420/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4284 - val_loss: 193.4377\n",
      "Epoch 2421/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7429 - val_loss: 193.9317\n",
      "Epoch 2422/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4661 - val_loss: 193.4489\n",
      "Epoch 2423/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5766 - val_loss: 194.0225\n",
      "Epoch 2424/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7451 - val_loss: 190.7295\n",
      "Epoch 2425/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4906 - val_loss: 194.9150\n",
      "Epoch 2426/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4111 - val_loss: 191.0200\n",
      "Epoch 2427/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5331 - val_loss: 192.7629\n",
      "Epoch 2428/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6673 - val_loss: 195.1795\n",
      "Epoch 2429/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6226 - val_loss: 195.5215\n",
      "Epoch 2430/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4382 - val_loss: 195.1978\n",
      "Epoch 2431/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3694 - val_loss: 190.3577\n",
      "Epoch 2432/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4922 - val_loss: 193.8724\n",
      "Epoch 2433/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5904 - val_loss: 195.9863\n",
      "Epoch 2434/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0473 - val_loss: 194.5307\n",
      "Epoch 2435/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3834 - val_loss: 197.2344\n",
      "Epoch 2436/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7225 - val_loss: 191.7158\n",
      "Epoch 2437/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6551 - val_loss: 192.4164\n",
      "Epoch 2438/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5359 - val_loss: 192.9538\n",
      "Epoch 2439/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7732 - val_loss: 193.8258\n",
      "Epoch 2440/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5224 - val_loss: 194.6546\n",
      "Epoch 2441/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0389 - val_loss: 193.7126\n",
      "Epoch 2442/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3038 - val_loss: 196.0079\n",
      "Epoch 2443/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9774 - val_loss: 198.3576\n",
      "Epoch 2444/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6235 - val_loss: 197.0715\n",
      "Epoch 2445/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5640 - val_loss: 194.2028\n",
      "Epoch 2446/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2162 - val_loss: 192.0294\n",
      "Epoch 2447/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8164 - val_loss: 191.9949\n",
      "Epoch 2448/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5443 - val_loss: 194.0231\n",
      "Epoch 2449/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6114 - val_loss: 196.5953\n",
      "Epoch 2450/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4289 - val_loss: 195.6956\n",
      "Epoch 2451/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6206 - val_loss: 195.1833\n",
      "Epoch 2452/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4692 - val_loss: 195.8564\n",
      "Epoch 2453/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8927 - val_loss: 191.0556\n",
      "Epoch 2454/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6974 - val_loss: 196.5028\n",
      "Epoch 2455/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5741 - val_loss: 190.3762\n",
      "Epoch 2456/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7202 - val_loss: 193.2999\n",
      "Epoch 2457/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9544 - val_loss: 194.3100\n",
      "Epoch 2458/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4875 - val_loss: 194.6540\n",
      "Epoch 2459/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3755 - val_loss: 193.8934\n",
      "Epoch 2460/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5219 - val_loss: 193.4835\n",
      "Epoch 2461/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3871 - val_loss: 197.6707\n",
      "Epoch 2462/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5659 - val_loss: 194.3619\n",
      "Epoch 2463/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7847 - val_loss: 196.8069\n",
      "Epoch 2464/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4668 - val_loss: 194.5670\n",
      "Epoch 2465/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5820 - val_loss: 191.8672\n",
      "Epoch 2466/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4188 - val_loss: 191.7937\n",
      "Epoch 2467/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5142 - val_loss: 195.1675\n",
      "Epoch 2468/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0004 - val_loss: 195.1662\n",
      "Epoch 2469/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6384 - val_loss: 192.5402\n",
      "Epoch 2470/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6621 - val_loss: 195.9746\n",
      "Epoch 2471/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7396 - val_loss: 193.9923\n",
      "Epoch 2472/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7277 - val_loss: 191.8896\n",
      "Epoch 2473/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3634 - val_loss: 196.3672\n",
      "Epoch 2474/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4111 - val_loss: 192.9729\n",
      "Epoch 2475/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5603 - val_loss: 192.2408\n",
      "Epoch 2476/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6238 - val_loss: 193.6450\n",
      "Epoch 2477/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5565 - val_loss: 192.9840\n",
      "Epoch 2478/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7810 - val_loss: 195.5503\n",
      "Epoch 2479/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2434 - val_loss: 197.1053\n",
      "Epoch 2480/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8941 - val_loss: 193.6806\n",
      "Epoch 2481/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9083 - val_loss: 192.1636\n",
      "Epoch 2482/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4697 - val_loss: 193.9971\n",
      "Epoch 2483/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7369 - val_loss: 193.2630\n",
      "Epoch 2484/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8161 - val_loss: 193.7829\n",
      "Epoch 2485/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4757 - val_loss: 194.9595\n",
      "Epoch 2486/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5902 - val_loss: 192.2678\n",
      "Epoch 2487/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6135 - val_loss: 194.7375\n",
      "Epoch 2488/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5530 - val_loss: 191.4608\n",
      "Epoch 2489/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7683 - val_loss: 192.1405\n",
      "Epoch 2490/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5660 - val_loss: 195.8970\n",
      "Epoch 2491/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5546 - val_loss: 194.3813\n",
      "Epoch 2492/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5897 - val_loss: 193.3607\n",
      "Epoch 2493/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4997 - val_loss: 192.1812\n",
      "Epoch 2494/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5026 - val_loss: 192.0236\n",
      "Epoch 2495/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5651 - val_loss: 198.7159\n",
      "Epoch 2496/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5169 - val_loss: 192.7996\n",
      "Epoch 2497/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6126 - val_loss: 193.2370\n",
      "Epoch 2498/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7721 - val_loss: 199.0837\n",
      "Epoch 2499/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4958 - val_loss: 193.1821\n",
      "Epoch 2500/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5147 - val_loss: 192.8152\n",
      "Epoch 2501/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5569 - val_loss: 192.5071\n",
      "Epoch 2502/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4455 - val_loss: 195.3532\n",
      "Epoch 2503/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6892 - val_loss: 192.4477\n",
      "Epoch 2504/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7645 - val_loss: 192.6311\n",
      "Epoch 2505/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4087 - val_loss: 195.8102\n",
      "Epoch 2506/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4453 - val_loss: 192.9826\n",
      "Epoch 2507/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5309 - val_loss: 196.5431\n",
      "Epoch 2508/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5238 - val_loss: 197.5157\n",
      "Epoch 2509/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8073 - val_loss: 194.2617\n",
      "Epoch 2510/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6669 - val_loss: 192.3706\n",
      "Epoch 2511/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6745 - val_loss: 191.6095\n",
      "Epoch 2512/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6717 - val_loss: 193.1539\n",
      "Epoch 2513/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4181 - val_loss: 193.6289\n",
      "Epoch 2514/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8321 - val_loss: 193.7142\n",
      "Epoch 2515/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5455 - val_loss: 193.7496\n",
      "Epoch 2516/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3573 - val_loss: 194.9544\n",
      "Epoch 2517/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7777 - val_loss: 193.1599\n",
      "Epoch 2518/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8681 - val_loss: 194.1216\n",
      "Epoch 2519/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6770 - val_loss: 194.0883\n",
      "Epoch 2520/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6531 - val_loss: 195.2656\n",
      "Epoch 2521/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5685 - val_loss: 194.9457\n",
      "Epoch 2522/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3755 - val_loss: 197.2694\n",
      "Epoch 2523/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3929 - val_loss: 193.5985\n",
      "Epoch 2524/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4633 - val_loss: 193.7684\n",
      "Epoch 2525/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5900 - val_loss: 192.5899\n",
      "Epoch 2526/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4656 - val_loss: 195.7102\n",
      "Epoch 2527/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7238 - val_loss: 193.2554\n",
      "Epoch 2528/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9260 - val_loss: 191.9869\n",
      "Epoch 2529/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2878 - val_loss: 195.0293\n",
      "Epoch 2530/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5283 - val_loss: 192.9170\n",
      "Epoch 2531/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5007 - val_loss: 194.5908\n",
      "Epoch 2532/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5616 - val_loss: 193.8174\n",
      "Epoch 2533/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5640 - val_loss: 192.9672\n",
      "Epoch 2534/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4563 - val_loss: 195.1873\n",
      "Epoch 2535/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6660 - val_loss: 193.8937\n",
      "Epoch 2536/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6939 - val_loss: 191.4769\n",
      "Epoch 2537/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4355 - val_loss: 194.9492\n",
      "Epoch 2538/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8311 - val_loss: 194.1180\n",
      "Epoch 2539/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5120 - val_loss: 194.0705\n",
      "Epoch 2540/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5084 - val_loss: 195.2862\n",
      "Epoch 2541/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4742 - val_loss: 192.7606\n",
      "Epoch 2542/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7668 - val_loss: 193.4679\n",
      "Epoch 2543/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7540 - val_loss: 193.9577\n",
      "Epoch 2544/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5797 - val_loss: 194.2350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2545/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4230 - val_loss: 195.7458\n",
      "Epoch 2546/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9891 - val_loss: 195.5020\n",
      "Epoch 2547/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5016 - val_loss: 194.2510\n",
      "Epoch 2548/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7374 - val_loss: 194.2043\n",
      "Epoch 2549/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6503 - val_loss: 194.2247\n",
      "Epoch 2550/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6154 - val_loss: 194.7279\n",
      "Epoch 2551/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4792 - val_loss: 189.4514\n",
      "Epoch 2552/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7546 - val_loss: 193.6738\n",
      "Epoch 2553/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4348 - val_loss: 194.3822\n",
      "Epoch 2554/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7423 - val_loss: 195.2850\n",
      "Epoch 2555/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5242 - val_loss: 195.7866\n",
      "Epoch 2556/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4715 - val_loss: 193.1937\n",
      "Epoch 2557/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6520 - val_loss: 194.2281\n",
      "Epoch 2558/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7266 - val_loss: 194.6885\n",
      "Epoch 2559/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5127 - val_loss: 192.3372\n",
      "Epoch 2560/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6170 - val_loss: 194.3433\n",
      "Epoch 2561/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5099 - val_loss: 196.9084\n",
      "Epoch 2562/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6355 - val_loss: 195.1001\n",
      "Epoch 2563/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4443 - val_loss: 193.9580\n",
      "Epoch 2564/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5758 - val_loss: 193.1766\n",
      "Epoch 2565/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4516 - val_loss: 194.9860\n",
      "Epoch 2566/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6746 - val_loss: 192.9570\n",
      "Epoch 2567/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6494 - val_loss: 194.3849\n",
      "Epoch 2568/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4939 - val_loss: 194.3588\n",
      "Epoch 2569/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6072 - val_loss: 194.9791\n",
      "Epoch 2570/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5234 - val_loss: 193.7893\n",
      "Epoch 2571/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5470 - val_loss: 196.3679\n",
      "Epoch 2572/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.1060 - val_loss: 193.0751\n",
      "Epoch 2573/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3628 - val_loss: 191.5745\n",
      "Epoch 2574/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4754 - val_loss: 196.0775\n",
      "Epoch 2575/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6410 - val_loss: 194.4771\n",
      "Epoch 2576/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7834 - val_loss: 193.6204\n",
      "Epoch 2577/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6173 - val_loss: 191.7958\n",
      "Epoch 2578/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6233 - val_loss: 195.1983\n",
      "Epoch 2579/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6436 - val_loss: 195.2093\n",
      "Epoch 2580/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5814 - val_loss: 193.2510\n",
      "Epoch 2581/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5147 - val_loss: 193.7402\n",
      "Epoch 2582/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4980 - val_loss: 194.0113\n",
      "Epoch 2583/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3695 - val_loss: 192.4941\n",
      "Epoch 2584/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4363 - val_loss: 190.6329\n",
      "Epoch 2585/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8744 - val_loss: 195.0514\n",
      "Epoch 2586/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7318 - val_loss: 193.0303\n",
      "Epoch 2587/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4777 - val_loss: 193.0213\n",
      "Epoch 2588/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3905 - val_loss: 195.5713\n",
      "Epoch 2589/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5592 - val_loss: 194.5408\n",
      "Epoch 2590/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7666 - val_loss: 193.4717\n",
      "Epoch 2591/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5446 - val_loss: 194.1441\n",
      "Epoch 2592/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4843 - val_loss: 192.7650\n",
      "Epoch 2593/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5461 - val_loss: 195.9799\n",
      "Epoch 2594/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7017 - val_loss: 195.4552\n",
      "Epoch 2595/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7309 - val_loss: 192.1909\n",
      "Epoch 2596/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6868 - val_loss: 196.9361\n",
      "Epoch 2597/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7628 - val_loss: 197.4460\n",
      "Epoch 2598/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7554 - val_loss: 190.1343\n",
      "Epoch 2599/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6283 - val_loss: 193.1981\n",
      "Epoch 2600/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5214 - val_loss: 194.3307\n",
      "Epoch 2601/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6422 - val_loss: 197.5862\n",
      "Epoch 2602/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9094 - val_loss: 191.0500\n",
      "Epoch 2603/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8935 - val_loss: 192.1721\n",
      "Epoch 2604/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6782 - val_loss: 193.3774\n",
      "Epoch 2605/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8127 - val_loss: 193.7773\n",
      "Epoch 2606/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6156 - val_loss: 197.5231\n",
      "Epoch 2607/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6564 - val_loss: 195.1169\n",
      "Epoch 2608/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8790 - val_loss: 197.2522\n",
      "Epoch 2609/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4696 - val_loss: 194.6380\n",
      "Epoch 2610/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4478 - val_loss: 193.2071\n",
      "Epoch 2611/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6054 - val_loss: 192.9028\n",
      "Epoch 2612/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4995 - val_loss: 192.7565\n",
      "Epoch 2613/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7210 - val_loss: 190.7232\n",
      "Epoch 2614/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7648 - val_loss: 194.6274\n",
      "Epoch 2615/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4721 - val_loss: 193.4648\n",
      "Epoch 2616/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5174 - val_loss: 195.5436\n",
      "Epoch 2617/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9600 - val_loss: 195.1799\n",
      "Epoch 2618/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7810 - val_loss: 191.0052\n",
      "Epoch 2619/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8505 - val_loss: 194.3484\n",
      "Epoch 2620/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6038 - val_loss: 196.8979\n",
      "Epoch 2621/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6333 - val_loss: 191.6912\n",
      "Epoch 2622/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4877 - val_loss: 192.6230\n",
      "Epoch 2623/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7235 - val_loss: 194.3048\n",
      "Epoch 2624/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3844 - val_loss: 192.5459\n",
      "Epoch 2625/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8178 - val_loss: 193.1902\n",
      "Epoch 2626/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6112 - val_loss: 194.9274\n",
      "Epoch 2627/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7260 - val_loss: 194.2803\n",
      "Epoch 2628/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5768 - val_loss: 194.1452\n",
      "Epoch 2629/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8281 - val_loss: 195.4424\n",
      "Epoch 2630/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5543 - val_loss: 194.6676\n",
      "Epoch 2631/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1179 - val_loss: 191.9797\n",
      "Epoch 2632/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7272 - val_loss: 193.3022\n",
      "Epoch 2633/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4466 - val_loss: 195.5639\n",
      "Epoch 2634/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6567 - val_loss: 194.0110\n",
      "Epoch 2635/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4420 - val_loss: 194.3561\n",
      "Epoch 2636/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7509 - val_loss: 196.0941\n",
      "Epoch 2637/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7111 - val_loss: 194.7990\n",
      "Epoch 2638/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3107 - val_loss: 193.4190\n",
      "Epoch 2639/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4830 - val_loss: 192.1339\n",
      "Epoch 2640/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6108 - val_loss: 192.7379\n",
      "Epoch 2641/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5825 - val_loss: 197.1993\n",
      "Epoch 2642/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7501 - val_loss: 191.4910\n",
      "Epoch 2643/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7732 - val_loss: 195.4132\n",
      "Epoch 2644/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2983 - val_loss: 193.9442\n",
      "Epoch 2645/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5497 - val_loss: 197.3521\n",
      "Epoch 2646/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8586 - val_loss: 196.9808\n",
      "Epoch 2647/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6716 - val_loss: 192.4277\n",
      "Epoch 2648/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8135 - val_loss: 195.3122\n",
      "Epoch 2649/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7091 - val_loss: 194.3024\n",
      "Epoch 2650/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6162 - val_loss: 192.2855\n",
      "Epoch 2651/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6151 - val_loss: 194.2476\n",
      "Epoch 2652/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7798 - val_loss: 193.0050\n",
      "Epoch 2653/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5518 - val_loss: 191.2701\n",
      "Epoch 2654/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7065 - val_loss: 193.8845\n",
      "Epoch 2655/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8621 - val_loss: 192.9518\n",
      "Epoch 2656/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4657 - val_loss: 192.5111\n",
      "Epoch 2657/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7383 - val_loss: 194.8040\n",
      "Epoch 2658/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6755 - val_loss: 195.7249\n",
      "Epoch 2659/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4599 - val_loss: 193.8784\n",
      "Epoch 2660/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8337 - val_loss: 193.0489\n",
      "Epoch 2661/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4068 - val_loss: 193.8134\n",
      "Epoch 2662/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6378 - val_loss: 193.2382\n",
      "Epoch 2663/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4920 - val_loss: 193.2086\n",
      "Epoch 2664/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5495 - val_loss: 191.9165\n",
      "Epoch 2665/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7149 - val_loss: 195.3936\n",
      "Epoch 2666/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6954 - val_loss: 193.4045\n",
      "Epoch 2667/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4626 - val_loss: 194.7237\n",
      "Epoch 2668/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5278 - val_loss: 195.0620\n",
      "Epoch 2669/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4721 - val_loss: 195.3760\n",
      "Epoch 2670/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7192 - val_loss: 196.8415\n",
      "Epoch 2671/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6529 - val_loss: 195.9950\n",
      "Epoch 2672/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5547 - val_loss: 200.4807\n",
      "Epoch 2673/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5406 - val_loss: 196.8526\n",
      "Epoch 2674/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7566 - val_loss: 193.2933\n",
      "Epoch 2675/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3919 - val_loss: 196.4376\n",
      "Epoch 2676/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5810 - val_loss: 194.6866\n",
      "Epoch 2677/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6305 - val_loss: 194.3592\n",
      "Epoch 2678/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4085 - val_loss: 193.7433\n",
      "Epoch 2679/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7841 - val_loss: 192.0182\n",
      "Epoch 2680/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5626 - val_loss: 192.3549\n",
      "Epoch 2681/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5495 - val_loss: 194.0267\n",
      "Epoch 2682/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6587 - val_loss: 194.6500\n",
      "Epoch 2683/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7689 - val_loss: 192.5767\n",
      "Epoch 2684/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6210 - val_loss: 196.2850\n",
      "Epoch 2685/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4850 - val_loss: 192.9142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2686/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6460 - val_loss: 194.3884\n",
      "Epoch 2687/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8766 - val_loss: 194.5243\n",
      "Epoch 2688/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7660 - val_loss: 194.9972\n",
      "Epoch 2689/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3551 - val_loss: 194.3245\n",
      "Epoch 2690/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4912 - val_loss: 194.8061\n",
      "Epoch 2691/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7056 - val_loss: 194.0514\n",
      "Epoch 2692/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4786 - val_loss: 192.5706\n",
      "Epoch 2693/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4604 - val_loss: 193.5471\n",
      "Epoch 2694/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6166 - val_loss: 196.6519\n",
      "Epoch 2695/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6142 - val_loss: 191.8538\n",
      "Epoch 2696/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5940 - val_loss: 192.9053\n",
      "Epoch 2697/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5982 - val_loss: 196.2250\n",
      "Epoch 2698/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7688 - val_loss: 191.5322\n",
      "Epoch 2699/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5130 - val_loss: 195.7148\n",
      "Epoch 2700/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4678 - val_loss: 197.6486\n",
      "Epoch 2701/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5162 - val_loss: 194.5722\n",
      "Epoch 2702/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4649 - val_loss: 193.0876\n",
      "Epoch 2703/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5269 - val_loss: 193.4683\n",
      "Epoch 2704/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5044 - val_loss: 193.5820\n",
      "Epoch 2705/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7076 - val_loss: 194.9975\n",
      "Epoch 2706/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3801 - val_loss: 193.6933\n",
      "Epoch 2707/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0977 - val_loss: 193.7276\n",
      "Epoch 2708/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6474 - val_loss: 195.5446\n",
      "Epoch 2709/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4446 - val_loss: 195.1471\n",
      "Epoch 2710/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2092 - val_loss: 196.2426\n",
      "Epoch 2711/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7900 - val_loss: 196.1155\n",
      "Epoch 2712/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5530 - val_loss: 196.5770\n",
      "Epoch 2713/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0434 - val_loss: 193.0880\n",
      "Epoch 2714/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6138 - val_loss: 194.8477\n",
      "Epoch 2715/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4562 - val_loss: 192.5819\n",
      "Epoch 2716/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4968 - val_loss: 194.5691\n",
      "Epoch 2717/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3509 - val_loss: 194.4140\n",
      "Epoch 2718/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6783 - val_loss: 194.1654\n",
      "Epoch 2719/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7873 - val_loss: 194.1630\n",
      "Epoch 2720/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3474 - val_loss: 193.2595\n",
      "Epoch 2721/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7186 - val_loss: 193.1899\n",
      "Epoch 2722/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7097 - val_loss: 193.9334\n",
      "Epoch 2723/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3753 - val_loss: 195.0989\n",
      "Epoch 2724/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9254 - val_loss: 196.0827\n",
      "Epoch 2725/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3731 - val_loss: 194.2360\n",
      "Epoch 2726/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6016 - val_loss: 195.8982\n",
      "Epoch 2727/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4961 - val_loss: 195.2886\n",
      "Epoch 2728/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7827 - val_loss: 194.0472\n",
      "Epoch 2729/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6562 - val_loss: 191.5137\n",
      "Epoch 2730/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4873 - val_loss: 194.2730\n",
      "Epoch 2731/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6034 - val_loss: 195.9929\n",
      "Epoch 2732/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6135 - val_loss: 194.5880\n",
      "Epoch 2733/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5442 - val_loss: 191.9032\n",
      "Epoch 2734/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4097 - val_loss: 194.5953\n",
      "Epoch 2735/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0264 - val_loss: 194.1222\n",
      "Epoch 2736/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5330 - val_loss: 196.6809\n",
      "Epoch 2737/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4814 - val_loss: 195.2675\n",
      "Epoch 2738/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7324 - val_loss: 193.0429\n",
      "Epoch 2739/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8909 - val_loss: 194.9909\n",
      "Epoch 2740/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8368 - val_loss: 195.2148\n",
      "Epoch 2741/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5576 - val_loss: 197.1120\n",
      "Epoch 2742/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7871 - val_loss: 196.8704\n",
      "Epoch 2743/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8693 - val_loss: 194.0938\n",
      "Epoch 2744/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4341 - val_loss: 191.6006\n",
      "Epoch 2745/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4907 - val_loss: 194.4779\n",
      "Epoch 2746/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7031 - val_loss: 193.0465\n",
      "Epoch 2747/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6245 - val_loss: 196.8291\n",
      "Epoch 2748/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6412 - val_loss: 196.6378\n",
      "Epoch 2749/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7318 - val_loss: 197.6773\n",
      "Epoch 2750/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3219 - val_loss: 195.5510\n",
      "Epoch 2751/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5533 - val_loss: 196.8253\n",
      "Epoch 2752/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5494 - val_loss: 193.8861\n",
      "Epoch 2753/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8138 - val_loss: 195.3720\n",
      "Epoch 2754/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3128 - val_loss: 197.6397\n",
      "Epoch 2755/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5684 - val_loss: 193.7674\n",
      "Epoch 2756/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7408 - val_loss: 193.4495\n",
      "Epoch 2757/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5949 - val_loss: 191.1647\n",
      "Epoch 2758/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4458 - val_loss: 193.0864\n",
      "Epoch 2759/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3540 - val_loss: 192.7347\n",
      "Epoch 2760/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3639 - val_loss: 194.1879\n",
      "Epoch 2761/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4837 - val_loss: 190.9234\n",
      "Epoch 2762/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5376 - val_loss: 197.6907\n",
      "Epoch 2763/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5633 - val_loss: 192.9163\n",
      "Epoch 2764/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6083 - val_loss: 193.9504\n",
      "Epoch 2765/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6140 - val_loss: 196.7165\n",
      "Epoch 2766/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4645 - val_loss: 195.2588\n",
      "Epoch 2767/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5469 - val_loss: 195.2077\n",
      "Epoch 2768/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5008 - val_loss: 192.3958\n",
      "Epoch 2769/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7626 - val_loss: 193.6274\n",
      "Epoch 2770/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4943 - val_loss: 193.3637\n",
      "Epoch 2771/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6257 - val_loss: 192.8701\n",
      "Epoch 2772/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4633 - val_loss: 196.9409\n",
      "Epoch 2773/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7655 - val_loss: 193.7918\n",
      "Epoch 2774/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6522 - val_loss: 194.6462\n",
      "Epoch 2775/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4306 - val_loss: 193.2819\n",
      "Epoch 2776/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5666 - val_loss: 194.2679\n",
      "Epoch 2777/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6010 - val_loss: 197.4340\n",
      "Epoch 2778/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6137 - val_loss: 192.9891\n",
      "Epoch 2779/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7805 - val_loss: 193.6916\n",
      "Epoch 2780/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4275 - val_loss: 194.4029\n",
      "Epoch 2781/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6677 - val_loss: 195.7049\n",
      "Epoch 2782/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5387 - val_loss: 197.6565\n",
      "Epoch 2783/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7382 - val_loss: 194.1220\n",
      "Epoch 2784/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4506 - val_loss: 195.8480\n",
      "Epoch 2785/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9037 - val_loss: 195.6545\n",
      "Epoch 2786/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5597 - val_loss: 193.5855\n",
      "Epoch 2787/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7608 - val_loss: 193.5319\n",
      "Epoch 2788/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5402 - val_loss: 194.1017\n",
      "Epoch 2789/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5203 - val_loss: 192.1922\n",
      "Epoch 2790/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8837 - val_loss: 194.1598\n",
      "Epoch 2791/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6542 - val_loss: 194.7422\n",
      "Epoch 2792/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3641 - val_loss: 194.9160\n",
      "Epoch 2793/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7039 - val_loss: 194.1129\n",
      "Epoch 2794/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5262 - val_loss: 192.9617\n",
      "Epoch 2795/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0409 - val_loss: 191.8103\n",
      "Epoch 2796/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4543 - val_loss: 194.1986\n",
      "Epoch 2797/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6527 - val_loss: 192.2313\n",
      "Epoch 2798/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5221 - val_loss: 194.9108\n",
      "Epoch 2799/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3891 - val_loss: 191.6760\n",
      "Epoch 2800/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7358 - val_loss: 193.4826\n",
      "Epoch 2801/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5142 - val_loss: 192.7214\n",
      "Epoch 2802/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7410 - val_loss: 192.5614\n",
      "Epoch 2803/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6692 - val_loss: 194.1788\n",
      "Epoch 2804/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5425 - val_loss: 196.4419\n",
      "Epoch 2805/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6144 - val_loss: 194.1278\n",
      "Epoch 2806/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5612 - val_loss: 194.3685\n",
      "Epoch 2807/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7299 - val_loss: 193.3429\n",
      "Epoch 2808/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6069 - val_loss: 195.3469\n",
      "Epoch 2809/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4099 - val_loss: 191.6641\n",
      "Epoch 2810/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4811 - val_loss: 193.1294\n",
      "Epoch 2811/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6896 - val_loss: 194.4455\n",
      "Epoch 2812/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5139 - val_loss: 196.2958\n",
      "Epoch 2813/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4720 - val_loss: 191.9097\n",
      "Epoch 2814/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7236 - val_loss: 195.6854\n",
      "Epoch 2815/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6045 - val_loss: 194.4463\n",
      "Epoch 2816/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5198 - val_loss: 191.5960\n",
      "Epoch 2817/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5777 - val_loss: 196.0229\n",
      "Epoch 2818/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5935 - val_loss: 195.0927\n",
      "Epoch 2819/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7828 - val_loss: 194.9366\n",
      "Epoch 2820/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3232 - val_loss: 193.6183\n",
      "Epoch 2821/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5294 - val_loss: 198.4513\n",
      "Epoch 2822/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5650 - val_loss: 195.6628\n",
      "Epoch 2823/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7021 - val_loss: 194.0766\n",
      "Epoch 2824/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6930 - val_loss: 192.8579\n",
      "Epoch 2825/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8323 - val_loss: 197.3524\n",
      "Epoch 2826/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5853 - val_loss: 193.1162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2827/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5613 - val_loss: 194.3142\n",
      "Epoch 2828/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6255 - val_loss: 192.5814\n",
      "Epoch 2829/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7083 - val_loss: 191.9696\n",
      "Epoch 2830/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4914 - val_loss: 194.6467\n",
      "Epoch 2831/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6220 - val_loss: 195.7670\n",
      "Epoch 2832/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6164 - val_loss: 191.9945\n",
      "Epoch 2833/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7488 - val_loss: 193.7881\n",
      "Epoch 2834/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6748 - val_loss: 193.7909\n",
      "Epoch 2835/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6240 - val_loss: 195.6779\n",
      "Epoch 2836/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9441 - val_loss: 195.5622\n",
      "Epoch 2837/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6512 - val_loss: 196.4221\n",
      "Epoch 2838/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6602 - val_loss: 196.1096\n",
      "Epoch 2839/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3032 - val_loss: 191.9756\n",
      "Epoch 2840/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4629 - val_loss: 192.4541\n",
      "Epoch 2841/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8750 - val_loss: 195.7397\n",
      "Epoch 2842/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5557 - val_loss: 192.1048\n",
      "Epoch 2843/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4890 - val_loss: 196.9642\n",
      "Epoch 2844/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7191 - val_loss: 196.5550\n",
      "Epoch 2845/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3904 - val_loss: 195.0046\n",
      "Epoch 2846/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5719 - val_loss: 193.2985\n",
      "Epoch 2847/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4780 - val_loss: 196.9473\n",
      "Epoch 2848/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6722 - val_loss: 192.8701\n",
      "Epoch 2849/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4190 - val_loss: 192.5494\n",
      "Epoch 2850/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3618 - val_loss: 194.2393\n",
      "Epoch 2851/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6188 - val_loss: 190.5831\n",
      "Epoch 2852/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4803 - val_loss: 191.2491\n",
      "Epoch 2853/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6015 - val_loss: 194.8283\n",
      "Epoch 2854/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4573 - val_loss: 192.0179\n",
      "Epoch 2855/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4902 - val_loss: 193.8714\n",
      "Epoch 2856/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5196 - val_loss: 193.4824\n",
      "Epoch 2857/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7125 - val_loss: 194.5094\n",
      "Epoch 2858/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0303 - val_loss: 194.7259\n",
      "Epoch 2859/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8490 - val_loss: 195.3812\n",
      "Epoch 2860/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4420 - val_loss: 192.9201\n",
      "Epoch 2861/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7054 - val_loss: 192.7331\n",
      "Epoch 2862/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6595 - val_loss: 196.2816\n",
      "Epoch 2863/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5865 - val_loss: 198.2215\n",
      "Epoch 2864/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4400 - val_loss: 194.7602\n",
      "Epoch 2865/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5054 - val_loss: 195.4434\n",
      "Epoch 2866/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7516 - val_loss: 195.2019\n",
      "Epoch 2867/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4669 - val_loss: 194.2672\n",
      "Epoch 2868/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5187 - val_loss: 194.0083\n",
      "Epoch 2869/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6693 - val_loss: 195.4914\n",
      "Epoch 2870/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6944 - val_loss: 191.8020\n",
      "Epoch 2871/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6169 - val_loss: 195.0133\n",
      "Epoch 2872/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1436 - val_loss: 194.6986\n",
      "Epoch 2873/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6278 - val_loss: 193.2569\n",
      "Epoch 2874/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4944 - val_loss: 196.8773\n",
      "Epoch 2875/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5280 - val_loss: 196.1569\n",
      "Epoch 2876/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5910 - val_loss: 194.4522\n",
      "Epoch 2877/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8412 - val_loss: 196.1645\n",
      "Epoch 2878/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5009 - val_loss: 195.6337\n",
      "Epoch 2879/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7910 - val_loss: 193.1780\n",
      "Epoch 2880/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7346 - val_loss: 195.4634\n",
      "Epoch 2881/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7736 - val_loss: 193.8059\n",
      "Epoch 2882/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7517 - val_loss: 195.9523\n",
      "Epoch 2883/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6260 - val_loss: 195.3474\n",
      "Epoch 2884/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3109 - val_loss: 191.1786\n",
      "Epoch 2885/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6643 - val_loss: 192.1937\n",
      "Epoch 2886/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4650 - val_loss: 195.1321\n",
      "Epoch 2887/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9171 - val_loss: 193.6480\n",
      "Epoch 2888/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6309 - val_loss: 194.1091\n",
      "Epoch 2889/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4648 - val_loss: 194.2696\n",
      "Epoch 2890/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6775 - val_loss: 193.8918\n",
      "Epoch 2891/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5695 - val_loss: 192.5027\n",
      "Epoch 2892/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4025 - val_loss: 194.8296\n",
      "Epoch 2893/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7249 - val_loss: 193.8848\n",
      "Epoch 2894/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5940 - val_loss: 190.7079\n",
      "Epoch 2895/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4822 - val_loss: 192.7161\n",
      "Epoch 2896/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8417 - val_loss: 192.5828\n",
      "Epoch 2897/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6363 - val_loss: 193.9650\n",
      "Epoch 2898/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 71.0160 - val_loss: 191.3975\n",
      "Epoch 2899/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7480 - val_loss: 194.0211\n",
      "Epoch 2900/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7950 - val_loss: 194.1564\n",
      "Epoch 2901/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6058 - val_loss: 192.9743\n",
      "Epoch 2902/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4734 - val_loss: 191.2627\n",
      "Epoch 2903/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6405 - val_loss: 193.4188\n",
      "Epoch 2904/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6032 - val_loss: 193.7384\n",
      "Epoch 2905/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6733 - val_loss: 191.8524\n",
      "Epoch 2906/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6301 - val_loss: 189.3684\n",
      "Epoch 2907/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6914 - val_loss: 193.5228\n",
      "Epoch 2908/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5427 - val_loss: 195.2393\n",
      "Epoch 2909/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5207 - val_loss: 192.7960\n",
      "Epoch 2910/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5058 - val_loss: 191.8200\n",
      "Epoch 2911/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4354 - val_loss: 194.8599\n",
      "Epoch 2912/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5911 - val_loss: 194.0022\n",
      "Epoch 2913/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5235 - val_loss: 193.7167\n",
      "Epoch 2914/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3969 - val_loss: 195.2493\n",
      "Epoch 2915/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6666 - val_loss: 195.3817\n",
      "Epoch 2916/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6780 - val_loss: 197.2161\n",
      "Epoch 2917/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6670 - val_loss: 195.9908\n",
      "Epoch 2918/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5694 - val_loss: 193.4589\n",
      "Epoch 2919/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9508 - val_loss: 194.2088\n",
      "Epoch 2920/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6634 - val_loss: 194.1227\n",
      "Epoch 2921/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7193 - val_loss: 198.5536\n",
      "Epoch 2922/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5367 - val_loss: 195.3891\n",
      "Epoch 2923/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4114 - val_loss: 196.9184\n",
      "Epoch 2924/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5462 - val_loss: 193.1757\n",
      "Epoch 2925/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7259 - val_loss: 195.5643\n",
      "Epoch 2926/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5492 - val_loss: 191.6743\n",
      "Epoch 2927/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4274 - val_loss: 196.1227\n",
      "Epoch 2928/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5503 - val_loss: 194.0909\n",
      "Epoch 2929/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7544 - val_loss: 196.4420\n",
      "Epoch 2930/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4380 - val_loss: 192.6698\n",
      "Epoch 2931/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4627 - val_loss: 191.1522\n",
      "Epoch 2932/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8156 - val_loss: 188.7698\n",
      "Epoch 2933/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7030 - val_loss: 193.3625\n",
      "Epoch 2934/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4524 - val_loss: 195.8461\n",
      "Epoch 2935/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3370 - val_loss: 191.6282\n",
      "Epoch 2936/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6398 - val_loss: 194.1888\n",
      "Epoch 2937/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.1816 - val_loss: 193.2043\n",
      "Epoch 2938/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5710 - val_loss: 193.0003\n",
      "Epoch 2939/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3526 - val_loss: 190.7710\n",
      "Epoch 2940/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4755 - val_loss: 194.3994\n",
      "Epoch 2941/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2977 - val_loss: 195.0740\n",
      "Epoch 2942/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4727 - val_loss: 193.9406\n",
      "Epoch 2943/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6380 - val_loss: 194.5363\n",
      "Epoch 2944/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5190 - val_loss: 193.6365\n",
      "Epoch 2945/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7917 - val_loss: 195.0709\n",
      "Epoch 2946/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5346 - val_loss: 193.2420\n",
      "Epoch 2947/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5144 - val_loss: 197.8839\n",
      "Epoch 2948/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7573 - val_loss: 194.9601\n",
      "Epoch 2949/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4566 - val_loss: 194.0652\n",
      "Epoch 2950/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8914 - val_loss: 198.2389\n",
      "Epoch 2951/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9537 - val_loss: 190.7639\n",
      "Epoch 2952/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5121 - val_loss: 190.8113\n",
      "Epoch 2953/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5625 - val_loss: 191.7290\n",
      "Epoch 2954/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7932 - val_loss: 191.9973\n",
      "Epoch 2955/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8501 - val_loss: 192.5642\n",
      "Epoch 2956/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4815 - val_loss: 191.6439\n",
      "Epoch 2957/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6643 - val_loss: 195.0107\n",
      "Epoch 2958/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4222 - val_loss: 194.5706\n",
      "Epoch 2959/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6693 - val_loss: 194.7906\n",
      "Epoch 2960/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5362 - val_loss: 197.7696\n",
      "Epoch 2961/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6567 - val_loss: 194.7055\n",
      "Epoch 2962/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8830 - val_loss: 197.9987\n",
      "Epoch 2963/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8847 - val_loss: 191.8867\n",
      "Epoch 2964/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5678 - val_loss: 196.7869\n",
      "Epoch 2965/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6090 - val_loss: 197.6751\n",
      "Epoch 2966/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5313 - val_loss: 195.1256\n",
      "Epoch 2967/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7079 - val_loss: 193.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2968/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9088 - val_loss: 193.8368\n",
      "Epoch 2969/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8367 - val_loss: 193.1374\n",
      "Epoch 2970/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3765 - val_loss: 193.4980\n",
      "Epoch 2971/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4640 - val_loss: 195.2481\n",
      "Epoch 2972/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8818 - val_loss: 189.4404\n",
      "Epoch 2973/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1808 - val_loss: 193.1498\n",
      "Epoch 2974/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2383 - val_loss: 194.8987\n",
      "Epoch 2975/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4253 - val_loss: 196.3114\n",
      "Epoch 2976/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5556 - val_loss: 196.3108\n",
      "Epoch 2977/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3395 - val_loss: 196.0438\n",
      "Epoch 2978/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6534 - val_loss: 194.8660\n",
      "Epoch 2979/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4587 - val_loss: 194.2501\n",
      "Epoch 2980/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7157 - val_loss: 193.4293\n",
      "Epoch 2981/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2770 - val_loss: 195.1695\n",
      "Epoch 2982/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5439 - val_loss: 195.4165\n",
      "Epoch 2983/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6086 - val_loss: 193.8461\n",
      "Epoch 2984/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4595 - val_loss: 194.8239\n",
      "Epoch 2985/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7572 - val_loss: 191.6255\n",
      "Epoch 2986/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7336 - val_loss: 194.4355\n",
      "Epoch 2987/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7306 - val_loss: 194.4643\n",
      "Epoch 2988/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5086 - val_loss: 194.3856\n",
      "Epoch 2989/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5101 - val_loss: 196.7366\n",
      "Epoch 2990/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3804 - val_loss: 196.6522\n",
      "Epoch 2991/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3713 - val_loss: 194.7460\n",
      "Epoch 2992/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3270 - val_loss: 194.6159\n",
      "Epoch 2993/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6961 - val_loss: 194.4078\n",
      "Epoch 2994/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4669 - val_loss: 193.6203\n",
      "Epoch 2995/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7190 - val_loss: 194.1606\n",
      "Epoch 2996/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4811 - val_loss: 193.8837\n",
      "Epoch 2997/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5258 - val_loss: 196.4039\n",
      "Epoch 2998/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7436 - val_loss: 195.8929\n",
      "Epoch 2999/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4897 - val_loss: 192.5040\n",
      "Epoch 3000/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.5768 - val_loss: 193.3088\n",
      "Epoch 3001/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8774 - val_loss: 193.2316\n",
      "Epoch 3002/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6312 - val_loss: 193.3630\n",
      "Epoch 3003/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5858 - val_loss: 195.5235\n",
      "Epoch 3004/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5348 - val_loss: 195.7212\n",
      "Epoch 3005/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5152 - val_loss: 192.3921\n",
      "Epoch 3006/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3735 - val_loss: 196.3752\n",
      "Epoch 3007/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7767 - val_loss: 194.5186\n",
      "Epoch 3008/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3949 - val_loss: 196.8522\n",
      "Epoch 3009/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4184 - val_loss: 197.2311\n",
      "Epoch 3010/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3617 - val_loss: 194.3311\n",
      "Epoch 3011/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7019 - val_loss: 193.0553\n",
      "Epoch 3012/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7203 - val_loss: 195.8299\n",
      "Epoch 3013/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2667 - val_loss: 194.9465\n",
      "Epoch 3014/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6709 - val_loss: 191.4898\n",
      "Epoch 3015/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4000 - val_loss: 193.6917\n",
      "Epoch 3016/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6164 - val_loss: 191.7188\n",
      "Epoch 3017/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7272 - val_loss: 195.5580\n",
      "Epoch 3018/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5722 - val_loss: 195.5972\n",
      "Epoch 3019/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.6586 - val_loss: 196.3483\n",
      "Epoch 3020/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5570 - val_loss: 194.7798\n",
      "Epoch 3021/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5792 - val_loss: 194.3538\n",
      "Epoch 3022/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4623 - val_loss: 196.3525\n",
      "Epoch 3023/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5684 - val_loss: 193.7000\n",
      "Epoch 3024/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6009 - val_loss: 193.4689\n",
      "Epoch 3025/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6403 - val_loss: 194.5176\n",
      "Epoch 3026/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6162 - val_loss: 193.2579\n",
      "Epoch 3027/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7165 - val_loss: 194.8919\n",
      "Epoch 3028/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.3285 - val_loss: 193.8053\n",
      "Epoch 3029/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4116 - val_loss: 196.0595\n",
      "Epoch 3030/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4408 - val_loss: 192.5570\n",
      "Epoch 3031/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5466 - val_loss: 192.4339\n",
      "Epoch 3032/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5388 - val_loss: 194.1237\n",
      "Epoch 3033/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5100 - val_loss: 196.6956\n",
      "Epoch 3034/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6538 - val_loss: 194.1697\n",
      "Epoch 3035/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8271 - val_loss: 194.7536\n",
      "Epoch 3036/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2006 - val_loss: 195.4236\n",
      "Epoch 3037/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5465 - val_loss: 196.5786\n",
      "Epoch 3038/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7884 - val_loss: 195.8108\n",
      "Epoch 3039/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5162 - val_loss: 194.1814\n",
      "Epoch 3040/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7608 - val_loss: 194.8481\n",
      "Epoch 3041/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3726 - val_loss: 194.3654\n",
      "Epoch 3042/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6727 - val_loss: 192.9548\n",
      "Epoch 3043/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6701 - val_loss: 194.4064\n",
      "Epoch 3044/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5510 - val_loss: 193.5056\n",
      "Epoch 3045/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6013 - val_loss: 195.3029\n",
      "Epoch 3046/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5290 - val_loss: 193.7197\n",
      "Epoch 3047/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5500 - val_loss: 190.6940\n",
      "Epoch 3048/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3199 - val_loss: 195.5937\n",
      "Epoch 3049/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6940 - val_loss: 192.1880\n",
      "Epoch 3050/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4285 - val_loss: 192.1764\n",
      "Epoch 3051/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4521 - val_loss: 195.9034\n",
      "Epoch 3052/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7197 - val_loss: 194.9592\n",
      "Epoch 3053/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5132 - val_loss: 192.2619\n",
      "Epoch 3054/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.3281 - val_loss: 194.4373\n",
      "Epoch 3055/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6858 - val_loss: 193.0502\n",
      "Epoch 3056/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3889 - val_loss: 196.0777\n",
      "Epoch 3057/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5141 - val_loss: 194.4380\n",
      "Epoch 3058/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4368 - val_loss: 196.3052\n",
      "Epoch 3059/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3452 - val_loss: 194.0146\n",
      "Epoch 3060/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5897 - val_loss: 195.4053\n",
      "Epoch 3061/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7887 - val_loss: 193.2345\n",
      "Epoch 3062/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3584 - val_loss: 195.0104\n",
      "Epoch 3063/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6746 - val_loss: 191.7788\n",
      "Epoch 3064/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3352 - val_loss: 194.7110\n",
      "Epoch 3065/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4413 - val_loss: 192.2756\n",
      "Epoch 3066/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4502 - val_loss: 196.2116\n",
      "Epoch 3067/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3075 - val_loss: 192.8904\n",
      "Epoch 3068/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6252 - val_loss: 195.7724\n",
      "Epoch 3069/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7397 - val_loss: 193.5179\n",
      "Epoch 3070/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6160 - val_loss: 195.6930\n",
      "Epoch 3071/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5200 - val_loss: 196.3476\n",
      "Epoch 3072/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4419 - val_loss: 195.1849\n",
      "Epoch 3073/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6634 - val_loss: 191.5165\n",
      "Epoch 3074/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6822 - val_loss: 195.0863\n",
      "Epoch 3075/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5836 - val_loss: 194.5852\n",
      "Epoch 3076/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6170 - val_loss: 195.0336\n",
      "Epoch 3077/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9449 - val_loss: 188.5572\n",
      "Epoch 3078/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9764 - val_loss: 195.4074\n",
      "Epoch 3079/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4466 - val_loss: 194.6976\n",
      "Epoch 3080/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6484 - val_loss: 194.5811\n",
      "Epoch 3081/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3281 - val_loss: 194.0076\n",
      "Epoch 3082/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4604 - val_loss: 194.0206\n",
      "Epoch 3083/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3866 - val_loss: 195.2364\n",
      "Epoch 3084/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4372 - val_loss: 195.6401\n",
      "Epoch 3085/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4210 - val_loss: 198.0705\n",
      "Epoch 3086/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4706 - val_loss: 196.9855\n",
      "Epoch 3087/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6417 - val_loss: 196.7765\n",
      "Epoch 3088/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3519 - val_loss: 194.0573\n",
      "Epoch 3089/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3473 - val_loss: 195.8856\n",
      "Epoch 3090/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3636 - val_loss: 195.2681\n",
      "Epoch 3091/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5519 - val_loss: 193.6493\n",
      "Epoch 3092/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5470 - val_loss: 195.5751\n",
      "Epoch 3093/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6094 - val_loss: 196.1720\n",
      "Epoch 3094/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6850 - val_loss: 194.8782\n",
      "Epoch 3095/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3740 - val_loss: 192.4223\n",
      "Epoch 3096/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4825 - val_loss: 194.2398\n",
      "Epoch 3097/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7576 - val_loss: 194.2135\n",
      "Epoch 3098/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5636 - val_loss: 194.7262\n",
      "Epoch 3099/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5751 - val_loss: 193.5261\n",
      "Epoch 3100/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2507 - val_loss: 196.0810\n",
      "Epoch 3101/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6997 - val_loss: 196.5763\n",
      "Epoch 3102/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6516 - val_loss: 192.6308\n",
      "Epoch 3103/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9712 - val_loss: 192.0709\n",
      "Epoch 3104/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5689 - val_loss: 192.9276\n",
      "Epoch 3105/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5764 - val_loss: 192.2844\n",
      "Epoch 3106/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5294 - val_loss: 194.4710\n",
      "Epoch 3107/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3751 - val_loss: 193.8896\n",
      "Epoch 3108/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3690 - val_loss: 194.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3109/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8398 - val_loss: 190.6378\n",
      "Epoch 3110/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5819 - val_loss: 194.4052\n",
      "Epoch 3111/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7094 - val_loss: 190.0471\n",
      "Epoch 3112/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4883 - val_loss: 194.7854\n",
      "Epoch 3113/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8503 - val_loss: 194.9008\n",
      "Epoch 3114/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3823 - val_loss: 195.2965\n",
      "Epoch 3115/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6543 - val_loss: 196.8367\n",
      "Epoch 3116/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2447 - val_loss: 197.4762\n",
      "Epoch 3117/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9876 - val_loss: 190.4852\n",
      "Epoch 3118/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4768 - val_loss: 196.3296\n",
      "Epoch 3119/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5748 - val_loss: 192.7896\n",
      "Epoch 3120/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4275 - val_loss: 193.7753\n",
      "Epoch 3121/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9033 - val_loss: 192.2571\n",
      "Epoch 3122/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4337 - val_loss: 194.1960\n",
      "Epoch 3123/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5662 - val_loss: 194.9368\n",
      "Epoch 3124/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3158 - val_loss: 195.1868\n",
      "Epoch 3125/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7015 - val_loss: 196.9919\n",
      "Epoch 3126/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5044 - val_loss: 195.1128\n",
      "Epoch 3127/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5592 - val_loss: 193.6680\n",
      "Epoch 3128/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6956 - val_loss: 194.3809\n",
      "Epoch 3129/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6874 - val_loss: 192.0282\n",
      "Epoch 3130/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5317 - val_loss: 195.1708\n",
      "Epoch 3131/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3650 - val_loss: 194.0457\n",
      "Epoch 3132/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7424 - val_loss: 193.3456\n",
      "Epoch 3133/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6027 - val_loss: 193.7581\n",
      "Epoch 3134/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9443 - val_loss: 193.0868\n",
      "Epoch 3135/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6846 - val_loss: 196.4441\n",
      "Epoch 3136/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6554 - val_loss: 196.2055\n",
      "Epoch 3137/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8323 - val_loss: 196.3028\n",
      "Epoch 3138/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6925 - val_loss: 191.6716\n",
      "Epoch 3139/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3427 - val_loss: 195.6129\n",
      "Epoch 3140/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7869 - val_loss: 195.4255\n",
      "Epoch 3141/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4435 - val_loss: 194.1763\n",
      "Epoch 3142/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7174 - val_loss: 191.1966\n",
      "Epoch 3143/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5670 - val_loss: 192.8541\n",
      "Epoch 3144/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6437 - val_loss: 194.0588\n",
      "Epoch 3145/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6715 - val_loss: 192.7894\n",
      "Epoch 3146/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4913 - val_loss: 190.2461\n",
      "Epoch 3147/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2896 - val_loss: 195.9145\n",
      "Epoch 3148/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6364 - val_loss: 196.8730\n",
      "Epoch 3149/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7477 - val_loss: 194.4226\n",
      "Epoch 3150/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8753 - val_loss: 193.5855\n",
      "Epoch 3151/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4394 - val_loss: 193.2477\n",
      "Epoch 3152/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7923 - val_loss: 194.5084\n",
      "Epoch 3153/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6153 - val_loss: 194.6483\n",
      "Epoch 3154/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3230 - val_loss: 194.4926\n",
      "Epoch 3155/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4747 - val_loss: 192.8836\n",
      "Epoch 3156/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4070 - val_loss: 195.8803\n",
      "Epoch 3157/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7219 - val_loss: 192.2962\n",
      "Epoch 3158/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6686 - val_loss: 195.8171\n",
      "Epoch 3159/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7526 - val_loss: 195.9096\n",
      "Epoch 3160/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5600 - val_loss: 193.1812\n",
      "Epoch 3161/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6184 - val_loss: 193.9103\n",
      "Epoch 3162/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5940 - val_loss: 193.6584\n",
      "Epoch 3163/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6869 - val_loss: 194.8173\n",
      "Epoch 3164/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4638 - val_loss: 192.7158\n",
      "Epoch 3165/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5489 - val_loss: 194.2779\n",
      "Epoch 3166/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2453 - val_loss: 193.9563\n",
      "Epoch 3167/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3995 - val_loss: 197.4859\n",
      "Epoch 3168/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5072 - val_loss: 192.2475\n",
      "Epoch 3169/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4521 - val_loss: 195.3961\n",
      "Epoch 3170/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7578 - val_loss: 193.1667\n",
      "Epoch 3171/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3700 - val_loss: 190.7973\n",
      "Epoch 3172/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6815 - val_loss: 190.9523\n",
      "Epoch 3173/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4262 - val_loss: 194.0757\n",
      "Epoch 3174/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5599 - val_loss: 191.4373\n",
      "Epoch 3175/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5616 - val_loss: 194.5150\n",
      "Epoch 3176/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5070 - val_loss: 195.9013\n",
      "Epoch 3177/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4020 - val_loss: 194.6478\n",
      "Epoch 3178/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4589 - val_loss: 196.1287\n",
      "Epoch 3179/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7618 - val_loss: 196.7746\n",
      "Epoch 3180/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5963 - val_loss: 195.9860\n",
      "Epoch 3181/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7001 - val_loss: 194.1300\n",
      "Epoch 3182/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2732 - val_loss: 194.2228\n",
      "Epoch 3183/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5030 - val_loss: 193.5360\n",
      "Epoch 3184/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6401 - val_loss: 192.2159\n",
      "Epoch 3185/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6619 - val_loss: 195.6803\n",
      "Epoch 3186/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6754 - val_loss: 195.2256\n",
      "Epoch 3187/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7962 - val_loss: 195.9931\n",
      "Epoch 3188/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6406 - val_loss: 195.4119\n",
      "Epoch 3189/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5255 - val_loss: 192.5155\n",
      "Epoch 3190/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5409 - val_loss: 197.3257\n",
      "Epoch 3191/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5834 - val_loss: 196.0814\n",
      "Epoch 3192/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7253 - val_loss: 194.0130\n",
      "Epoch 3193/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2911 - val_loss: 196.0671\n",
      "Epoch 3194/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5964 - val_loss: 195.1165\n",
      "Epoch 3195/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3304 - val_loss: 194.1871\n",
      "Epoch 3196/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5212 - val_loss: 195.9356\n",
      "Epoch 3197/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6145 - val_loss: 196.8188\n",
      "Epoch 3198/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6002 - val_loss: 193.8563\n",
      "Epoch 3199/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4968 - val_loss: 194.6930\n",
      "Epoch 3200/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4664 - val_loss: 194.9847\n",
      "Epoch 3201/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.7064 - val_loss: 195.9974\n",
      "Epoch 3202/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5618 - val_loss: 193.5588\n",
      "Epoch 3203/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5087 - val_loss: 193.3018\n",
      "Epoch 3204/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5817 - val_loss: 196.7456\n",
      "Epoch 3205/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5325 - val_loss: 192.6045\n",
      "Epoch 3206/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5335 - val_loss: 193.8508\n",
      "Epoch 3207/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7076 - val_loss: 192.9372\n",
      "Epoch 3208/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5425 - val_loss: 191.6762\n",
      "Epoch 3209/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6556 - val_loss: 193.8288\n",
      "Epoch 3210/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6038 - val_loss: 194.9976\n",
      "Epoch 3211/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6503 - val_loss: 194.3500\n",
      "Epoch 3212/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4591 - val_loss: 194.5457\n",
      "Epoch 3213/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5055 - val_loss: 193.4915\n",
      "Epoch 3214/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4308 - val_loss: 193.3506\n",
      "Epoch 3215/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5525 - val_loss: 194.6490\n",
      "Epoch 3216/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5029 - val_loss: 195.9922\n",
      "Epoch 3217/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4477 - val_loss: 193.3198\n",
      "Epoch 3218/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8994 - val_loss: 192.9601\n",
      "Epoch 3219/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6591 - val_loss: 192.0536\n",
      "Epoch 3220/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4709 - val_loss: 194.8170\n",
      "Epoch 3221/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6470 - val_loss: 194.1045\n",
      "Epoch 3222/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5206 - val_loss: 193.8747\n",
      "Epoch 3223/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5322 - val_loss: 194.7110\n",
      "Epoch 3224/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5439 - val_loss: 189.4813\n",
      "Epoch 3225/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8854 - val_loss: 192.3546\n",
      "Epoch 3226/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2782 - val_loss: 195.7875\n",
      "Epoch 3227/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3662 - val_loss: 194.3984\n",
      "Epoch 3228/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5952 - val_loss: 193.6626\n",
      "Epoch 3229/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4244 - val_loss: 195.8404\n",
      "Epoch 3230/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8540 - val_loss: 193.7478\n",
      "Epoch 3231/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5695 - val_loss: 193.2628\n",
      "Epoch 3232/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6066 - val_loss: 193.9470\n",
      "Epoch 3233/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4348 - val_loss: 194.7078\n",
      "Epoch 3234/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5238 - val_loss: 194.6060\n",
      "Epoch 3235/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3219 - val_loss: 194.4160\n",
      "Epoch 3236/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5043 - val_loss: 194.1530\n",
      "Epoch 3237/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6365 - val_loss: 194.5164\n",
      "Epoch 3238/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3475 - val_loss: 191.1382\n",
      "Epoch 3239/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7454 - val_loss: 194.3856\n",
      "Epoch 3240/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5715 - val_loss: 197.4522\n",
      "Epoch 3241/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6465 - val_loss: 194.3375\n",
      "Epoch 3242/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2045 - val_loss: 196.6281\n",
      "Epoch 3243/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4148 - val_loss: 196.2594\n",
      "Epoch 3244/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6175 - val_loss: 196.8465\n",
      "Epoch 3245/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4973 - val_loss: 194.2299\n",
      "Epoch 3246/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4663 - val_loss: 194.6700\n",
      "Epoch 3247/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4106 - val_loss: 195.9058\n",
      "Epoch 3248/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1957 - val_loss: 200.1555\n",
      "Epoch 3249/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5712 - val_loss: 193.3591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3250/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5171 - val_loss: 193.7322\n",
      "Epoch 3251/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4948 - val_loss: 196.5891\n",
      "Epoch 3252/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4597 - val_loss: 194.8155\n",
      "Epoch 3253/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5081 - val_loss: 193.9091\n",
      "Epoch 3254/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4455 - val_loss: 196.8665\n",
      "Epoch 3255/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7674 - val_loss: 195.3939\n",
      "Epoch 3256/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4199 - val_loss: 195.4856\n",
      "Epoch 3257/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3388 - val_loss: 195.7491\n",
      "Epoch 3258/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7463 - val_loss: 195.5463\n",
      "Epoch 3259/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4843 - val_loss: 195.5442\n",
      "Epoch 3260/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6865 - val_loss: 198.3224\n",
      "Epoch 3261/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7337 - val_loss: 194.6000\n",
      "Epoch 3262/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5865 - val_loss: 196.1906\n",
      "Epoch 3263/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5265 - val_loss: 194.9039\n",
      "Epoch 3264/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7538 - val_loss: 192.8115\n",
      "Epoch 3265/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6916 - val_loss: 196.6043\n",
      "Epoch 3266/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6011 - val_loss: 195.6993\n",
      "Epoch 3267/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5256 - val_loss: 196.0369\n",
      "Epoch 3268/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6348 - val_loss: 193.1044\n",
      "Epoch 3269/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6517 - val_loss: 193.9509\n",
      "Epoch 3270/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5083 - val_loss: 192.7306\n",
      "Epoch 3271/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7406 - val_loss: 193.9069\n",
      "Epoch 3272/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6506 - val_loss: 193.2560\n",
      "Epoch 3273/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8283 - val_loss: 191.3043\n",
      "Epoch 3274/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4358 - val_loss: 194.5919\n",
      "Epoch 3275/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4857 - val_loss: 195.9157\n",
      "Epoch 3276/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4529 - val_loss: 194.0935\n",
      "Epoch 3277/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5317 - val_loss: 195.3186\n",
      "Epoch 3278/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5577 - val_loss: 191.2370\n",
      "Epoch 3279/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4193 - val_loss: 196.8097\n",
      "Epoch 3280/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7636 - val_loss: 192.8281\n",
      "Epoch 3281/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3672 - val_loss: 197.2905\n",
      "Epoch 3282/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5217 - val_loss: 193.1997\n",
      "Epoch 3283/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3769 - val_loss: 194.3163\n",
      "Epoch 3284/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6250 - val_loss: 192.5094\n",
      "Epoch 3285/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4823 - val_loss: 194.1771\n",
      "Epoch 3286/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5124 - val_loss: 194.2639\n",
      "Epoch 3287/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4027 - val_loss: 197.9289\n",
      "Epoch 3288/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7049 - val_loss: 196.3199\n",
      "Epoch 3289/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7778 - val_loss: 193.5815\n",
      "Epoch 3290/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5858 - val_loss: 194.6809\n",
      "Epoch 3291/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4077 - val_loss: 195.1200\n",
      "Epoch 3292/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5657 - val_loss: 197.5094\n",
      "Epoch 3293/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6412 - val_loss: 195.4999\n",
      "Epoch 3294/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3037 - val_loss: 195.4727\n",
      "Epoch 3295/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3906 - val_loss: 195.0365\n",
      "Epoch 3296/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7141 - val_loss: 193.4131\n",
      "Epoch 3297/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5923 - val_loss: 191.0205\n",
      "Epoch 3298/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7069 - val_loss: 193.0929\n",
      "Epoch 3299/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4699 - val_loss: 196.5147\n",
      "Epoch 3300/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5512 - val_loss: 194.6366\n",
      "Epoch 3301/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3875 - val_loss: 194.8546\n",
      "Epoch 3302/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5025 - val_loss: 191.2821\n",
      "Epoch 3303/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6920 - val_loss: 193.2098\n",
      "Epoch 3304/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5945 - val_loss: 191.0757\n",
      "Epoch 3305/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5531 - val_loss: 192.8927\n",
      "Epoch 3306/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4405 - val_loss: 196.0648\n",
      "Epoch 3307/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5141 - val_loss: 196.5667\n",
      "Epoch 3308/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.4476 - val_loss: 193.1416\n",
      "Epoch 3309/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5997 - val_loss: 197.7797\n",
      "Epoch 3310/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7524 - val_loss: 196.3793\n",
      "Epoch 3311/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4886 - val_loss: 196.3514\n",
      "Epoch 3312/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4510 - val_loss: 197.4723\n",
      "Epoch 3313/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.8448 - val_loss: 194.3947\n",
      "Epoch 3314/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.5187 - val_loss: 194.3903\n",
      "Epoch 3315/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4717 - val_loss: 196.4537\n",
      "Epoch 3316/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4072 - val_loss: 194.2892\n",
      "Epoch 3317/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5506 - val_loss: 193.9904\n",
      "Epoch 3318/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6369 - val_loss: 194.6549\n",
      "Epoch 3319/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4855 - val_loss: 195.6258\n",
      "Epoch 3320/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5690 - val_loss: 194.3410\n",
      "Epoch 3321/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2598 - val_loss: 192.7446\n",
      "Epoch 3322/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5298 - val_loss: 196.5270\n",
      "Epoch 3323/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3355 - val_loss: 195.0475\n",
      "Epoch 3324/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4669 - val_loss: 197.3666\n",
      "Epoch 3325/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4648 - val_loss: 194.6532\n",
      "Epoch 3326/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7032 - val_loss: 198.9220\n",
      "Epoch 3327/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6578 - val_loss: 195.6015\n",
      "Epoch 3328/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3468 - val_loss: 193.9879\n",
      "Epoch 3329/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5027 - val_loss: 192.6236\n",
      "Epoch 3330/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6974 - val_loss: 195.2220\n",
      "Epoch 3331/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3814 - val_loss: 195.0865\n",
      "Epoch 3332/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9795 - val_loss: 195.9864\n",
      "Epoch 3333/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4807 - val_loss: 193.7432\n",
      "Epoch 3334/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5459 - val_loss: 198.0063\n",
      "Epoch 3335/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6046 - val_loss: 195.4168\n",
      "Epoch 3336/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3140 - val_loss: 193.5397\n",
      "Epoch 3337/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9063 - val_loss: 192.7354\n",
      "Epoch 3338/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6009 - val_loss: 195.0678\n",
      "Epoch 3339/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3572 - val_loss: 194.6117\n",
      "Epoch 3340/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4405 - val_loss: 196.3417\n",
      "Epoch 3341/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4320 - val_loss: 195.2673\n",
      "Epoch 3342/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6731 - val_loss: 193.8861\n",
      "Epoch 3343/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5088 - val_loss: 192.5680\n",
      "Epoch 3344/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6789 - val_loss: 195.7377\n",
      "Epoch 3345/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3995 - val_loss: 195.0316\n",
      "Epoch 3346/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2030 - val_loss: 195.3183\n",
      "Epoch 3347/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6994 - val_loss: 195.4730\n",
      "Epoch 3348/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4831 - val_loss: 192.6897\n",
      "Epoch 3349/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5328 - val_loss: 195.2307\n",
      "Epoch 3350/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5457 - val_loss: 196.2409\n",
      "Epoch 3351/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6227 - val_loss: 196.1221\n",
      "Epoch 3352/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6710 - val_loss: 194.3581\n",
      "Epoch 3353/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4998 - val_loss: 193.1510\n",
      "Epoch 3354/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5403 - val_loss: 195.0094\n",
      "Epoch 3355/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.7083 - val_loss: 193.9483\n",
      "Epoch 3356/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.4898 - val_loss: 192.6929\n",
      "Epoch 3357/20000\n",
      "17948/17948 [==============================] - 1s 41us/sample - loss: 70.7245 - val_loss: 192.9681\n",
      "Epoch 3358/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5417 - val_loss: 194.4280\n",
      "Epoch 3359/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.3457 - val_loss: 193.2571\n",
      "Epoch 3360/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.5446 - val_loss: 195.0592\n",
      "Epoch 3361/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6199 - val_loss: 193.0592\n",
      "Epoch 3362/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6429 - val_loss: 193.6178\n",
      "Epoch 3363/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.6377 - val_loss: 194.6614\n",
      "Epoch 3364/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.5277 - val_loss: 194.0254\n",
      "Epoch 3365/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.5437 - val_loss: 189.3767\n",
      "Epoch 3366/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.4310 - val_loss: 191.9084\n",
      "Epoch 3367/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.3343 - val_loss: 195.1800\n",
      "Epoch 3368/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.3671 - val_loss: 195.4754\n",
      "Epoch 3369/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 71.0095 - val_loss: 194.1155\n",
      "Epoch 3370/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3670 - val_loss: 196.1424\n",
      "Epoch 3371/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.7882 - val_loss: 193.9401\n",
      "Epoch 3372/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4393 - val_loss: 194.5658\n",
      "Epoch 3373/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4885 - val_loss: 195.1549\n",
      "Epoch 3374/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5577 - val_loss: 194.8643\n",
      "Epoch 3375/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5015 - val_loss: 193.3438\n",
      "Epoch 3376/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 71.2733 - val_loss: 194.2374\n",
      "Epoch 3377/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.6679 - val_loss: 192.3870\n",
      "Epoch 3378/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5253 - val_loss: 198.1794\n",
      "Epoch 3379/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6187 - val_loss: 198.1688\n",
      "Epoch 3380/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4970 - val_loss: 196.3603\n",
      "Epoch 3381/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.9080 - val_loss: 192.8360\n",
      "Epoch 3382/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7606 - val_loss: 193.9504\n",
      "Epoch 3383/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9167 - val_loss: 196.0851\n",
      "Epoch 3384/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4427 - val_loss: 192.2498\n",
      "Epoch 3385/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4276 - val_loss: 198.8105\n",
      "Epoch 3386/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.9846 - val_loss: 194.5314\n",
      "Epoch 3387/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7481 - val_loss: 194.2621\n",
      "Epoch 3388/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3962 - val_loss: 195.0894\n",
      "Epoch 3389/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5052 - val_loss: 195.2321\n",
      "Epoch 3390/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6967 - val_loss: 196.5783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3391/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6759 - val_loss: 196.3484\n",
      "Epoch 3392/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4911 - val_loss: 194.3866\n",
      "Epoch 3393/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4893 - val_loss: 194.7155\n",
      "Epoch 3394/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4057 - val_loss: 195.9499\n",
      "Epoch 3395/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5442 - val_loss: 197.6435\n",
      "Epoch 3396/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5367 - val_loss: 195.6877\n",
      "Epoch 3397/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4277 - val_loss: 198.9316\n",
      "Epoch 3398/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7147 - val_loss: 192.5331\n",
      "Epoch 3399/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6629 - val_loss: 196.3508\n",
      "Epoch 3400/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5300 - val_loss: 195.8693\n",
      "Epoch 3401/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6291 - val_loss: 193.3796\n",
      "Epoch 3402/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9087 - val_loss: 191.3982\n",
      "Epoch 3403/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5153 - val_loss: 192.6149\n",
      "Epoch 3404/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6544 - val_loss: 197.2934\n",
      "Epoch 3405/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 71.0113 - val_loss: 192.2198\n",
      "Epoch 3406/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6243 - val_loss: 197.1885\n",
      "Epoch 3407/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6476 - val_loss: 196.0319\n",
      "Epoch 3408/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7014 - val_loss: 197.6694\n",
      "Epoch 3409/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7523 - val_loss: 196.2460\n",
      "Epoch 3410/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.4739 - val_loss: 195.1158\n",
      "Epoch 3411/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5010 - val_loss: 193.8724\n",
      "Epoch 3412/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5582 - val_loss: 194.8450\n",
      "Epoch 3413/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9809 - val_loss: 193.7115\n",
      "Epoch 3414/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.3021 - val_loss: 194.5028\n",
      "Epoch 3415/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8755 - val_loss: 192.4167\n",
      "Epoch 3416/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6383 - val_loss: 194.2926\n",
      "Epoch 3417/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3395 - val_loss: 195.9219\n",
      "Epoch 3418/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7008 - val_loss: 195.7555\n",
      "Epoch 3419/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4966 - val_loss: 195.0939\n",
      "Epoch 3420/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4331 - val_loss: 195.4868\n",
      "Epoch 3421/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5124 - val_loss: 199.0289\n",
      "Epoch 3422/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8069 - val_loss: 194.9190\n",
      "Epoch 3423/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7244 - val_loss: 195.1407\n",
      "Epoch 3424/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3995 - val_loss: 196.0371\n",
      "Epoch 3425/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6179 - val_loss: 193.6962\n",
      "Epoch 3426/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6301 - val_loss: 193.3746\n",
      "Epoch 3427/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5104 - val_loss: 197.5339\n",
      "Epoch 3428/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4668 - val_loss: 195.6815\n",
      "Epoch 3429/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3998 - val_loss: 196.1973\n",
      "Epoch 3430/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5769 - val_loss: 195.0774\n",
      "Epoch 3431/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4988 - val_loss: 194.7109\n",
      "Epoch 3432/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5227 - val_loss: 195.7735\n",
      "Epoch 3433/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.7432 - val_loss: 198.1881\n",
      "Epoch 3434/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6532 - val_loss: 194.2746\n",
      "Epoch 3435/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5759 - val_loss: 192.0504\n",
      "Epoch 3436/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6170 - val_loss: 191.8104\n",
      "Epoch 3437/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4779 - val_loss: 195.4327\n",
      "Epoch 3438/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4884 - val_loss: 193.3673\n",
      "Epoch 3439/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3223 - val_loss: 196.1159\n",
      "Epoch 3440/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5933 - val_loss: 198.7690\n",
      "Epoch 3441/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5183 - val_loss: 191.5172\n",
      "Epoch 3442/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3208 - val_loss: 195.4312\n",
      "Epoch 3443/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7570 - val_loss: 192.4646\n",
      "Epoch 3444/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9520 - val_loss: 193.7049\n",
      "Epoch 3445/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7659 - val_loss: 195.0839\n",
      "Epoch 3446/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8146 - val_loss: 194.1296\n",
      "Epoch 3447/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6196 - val_loss: 196.1795\n",
      "Epoch 3448/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6382 - val_loss: 192.2430\n",
      "Epoch 3449/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3307 - val_loss: 195.5018\n",
      "Epoch 3450/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6337 - val_loss: 194.2916\n",
      "Epoch 3451/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6106 - val_loss: 195.0510\n",
      "Epoch 3452/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6382 - val_loss: 197.0014\n",
      "Epoch 3453/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5865 - val_loss: 194.0105\n",
      "Epoch 3454/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2384 - val_loss: 193.4765\n",
      "Epoch 3455/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7303 - val_loss: 195.9673\n",
      "Epoch 3456/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6808 - val_loss: 196.5571\n",
      "Epoch 3457/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4456 - val_loss: 193.2350\n",
      "Epoch 3458/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6791 - val_loss: 193.4404\n",
      "Epoch 3459/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8109 - val_loss: 196.3807\n",
      "Epoch 3460/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4144 - val_loss: 193.3813\n",
      "Epoch 3461/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5430 - val_loss: 193.8155\n",
      "Epoch 3462/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.8561 - val_loss: 193.7677\n",
      "Epoch 3463/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6267 - val_loss: 197.3393\n",
      "Epoch 3464/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2078 - val_loss: 196.0571\n",
      "Epoch 3465/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6227 - val_loss: 195.6001\n",
      "Epoch 3466/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6381 - val_loss: 196.9498\n",
      "Epoch 3467/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8404 - val_loss: 195.6762\n",
      "Epoch 3468/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5578 - val_loss: 193.8849\n",
      "Epoch 3469/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6198 - val_loss: 194.9331\n",
      "Epoch 3470/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4328 - val_loss: 194.8986\n",
      "Epoch 3471/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4648 - val_loss: 194.3468\n",
      "Epoch 3472/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2732 - val_loss: 196.6276\n",
      "Epoch 3473/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5455 - val_loss: 194.0386\n",
      "Epoch 3474/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5062 - val_loss: 195.8369\n",
      "Epoch 3475/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7764 - val_loss: 195.5131\n",
      "Epoch 3476/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.3755 - val_loss: 198.4213\n",
      "Epoch 3477/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7929 - val_loss: 194.1398\n",
      "Epoch 3478/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5016 - val_loss: 193.2057\n",
      "Epoch 3479/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5973 - val_loss: 195.2795\n",
      "Epoch 3480/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4736 - val_loss: 191.9025\n",
      "Epoch 3481/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5750 - val_loss: 195.5755\n",
      "Epoch 3482/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6979 - val_loss: 192.3768\n",
      "Epoch 3483/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4189 - val_loss: 193.5713\n",
      "Epoch 3484/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4849 - val_loss: 195.7770\n",
      "Epoch 3485/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3762 - val_loss: 197.5909\n",
      "Epoch 3486/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4517 - val_loss: 194.7498\n",
      "Epoch 3487/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6952 - val_loss: 193.9791\n",
      "Epoch 3488/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5438 - val_loss: 193.3205\n",
      "Epoch 3489/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3178 - val_loss: 195.5353\n",
      "Epoch 3490/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5590 - val_loss: 195.0973\n",
      "Epoch 3491/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5600 - val_loss: 196.6079\n",
      "Epoch 3492/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4038 - val_loss: 193.5698\n",
      "Epoch 3493/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5836 - val_loss: 192.1006\n",
      "Epoch 3494/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9030 - val_loss: 193.6217\n",
      "Epoch 3495/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9942 - val_loss: 190.4359\n",
      "Epoch 3496/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.8685 - val_loss: 193.5733\n",
      "Epoch 3497/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.3645 - val_loss: 193.5184\n",
      "Epoch 3498/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5980 - val_loss: 197.7503\n",
      "Epoch 3499/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7994 - val_loss: 197.0566\n",
      "Epoch 3500/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5258 - val_loss: 196.2657\n",
      "Epoch 3501/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4304 - val_loss: 196.8702\n",
      "Epoch 3502/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2569 - val_loss: 193.9555\n",
      "Epoch 3503/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8750 - val_loss: 195.4327\n",
      "Epoch 3504/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2920 - val_loss: 194.3568\n",
      "Epoch 3505/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2345 - val_loss: 195.8706\n",
      "Epoch 3506/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.4053 - val_loss: 195.3295\n",
      "Epoch 3507/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.6956 - val_loss: 195.1702\n",
      "Epoch 3508/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4805 - val_loss: 193.3717\n",
      "Epoch 3509/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5789 - val_loss: 191.9561\n",
      "Epoch 3510/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6485 - val_loss: 197.0501\n",
      "Epoch 3511/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3113 - val_loss: 194.8850\n",
      "Epoch 3512/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5521 - val_loss: 192.4163\n",
      "Epoch 3513/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3692 - val_loss: 193.0562\n",
      "Epoch 3514/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7978 - val_loss: 193.8300\n",
      "Epoch 3515/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6698 - val_loss: 193.5396\n",
      "Epoch 3516/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3569 - val_loss: 194.5724\n",
      "Epoch 3517/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5354 - val_loss: 194.8937\n",
      "Epoch 3518/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4789 - val_loss: 195.0152\n",
      "Epoch 3519/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5953 - val_loss: 196.1606\n",
      "Epoch 3520/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5364 - val_loss: 194.5647\n",
      "Epoch 3521/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6168 - val_loss: 196.5363\n",
      "Epoch 3522/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5043 - val_loss: 192.6380\n",
      "Epoch 3523/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3506 - val_loss: 195.2265\n",
      "Epoch 3524/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9162 - val_loss: 194.4709\n",
      "Epoch 3525/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.4593 - val_loss: 193.5150\n",
      "Epoch 3526/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4794 - val_loss: 196.6280\n",
      "Epoch 3527/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5344 - val_loss: 192.7162\n",
      "Epoch 3528/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.3978 - val_loss: 194.2471\n",
      "Epoch 3529/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.3554 - val_loss: 195.4348\n",
      "Epoch 3530/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5635 - val_loss: 194.0126\n",
      "Epoch 3531/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4643 - val_loss: 195.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3532/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7292 - val_loss: 196.7032\n",
      "Epoch 3533/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3283 - val_loss: 196.0373\n",
      "Epoch 3534/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5461 - val_loss: 197.5798\n",
      "Epoch 3535/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7350 - val_loss: 199.3458\n",
      "Epoch 3536/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4796 - val_loss: 195.3638\n",
      "Epoch 3537/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5155 - val_loss: 195.2588\n",
      "Epoch 3538/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7616 - val_loss: 194.8288\n",
      "Epoch 3539/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5013 - val_loss: 195.6514\n",
      "Epoch 3540/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2634 - val_loss: 193.9269\n",
      "Epoch 3541/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5061 - val_loss: 195.7974\n",
      "Epoch 3542/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7847 - val_loss: 193.2648\n",
      "Epoch 3543/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8274 - val_loss: 191.4727\n",
      "Epoch 3544/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5200 - val_loss: 194.4491\n",
      "Epoch 3545/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8035 - val_loss: 198.9244\n",
      "Epoch 3546/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5318 - val_loss: 193.8324\n",
      "Epoch 3547/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0377 - val_loss: 196.1434\n",
      "Epoch 3548/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3139 - val_loss: 194.5530\n",
      "Epoch 3549/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4331 - val_loss: 197.3146\n",
      "Epoch 3550/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6415 - val_loss: 196.0261\n",
      "Epoch 3551/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6545 - val_loss: 192.6116\n",
      "Epoch 3552/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6871 - val_loss: 195.2427\n",
      "Epoch 3553/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4678 - val_loss: 195.4849\n",
      "Epoch 3554/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3283 - val_loss: 193.4116\n",
      "Epoch 3555/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6167 - val_loss: 195.9318\n",
      "Epoch 3556/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7539 - val_loss: 195.1947\n",
      "Epoch 3557/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3275 - val_loss: 194.6894\n",
      "Epoch 3558/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4494 - val_loss: 198.5276\n",
      "Epoch 3559/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4146 - val_loss: 193.9710\n",
      "Epoch 3560/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6125 - val_loss: 197.1821\n",
      "Epoch 3561/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6186 - val_loss: 195.8957\n",
      "Epoch 3562/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6365 - val_loss: 193.2439\n",
      "Epoch 3563/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6873 - val_loss: 193.3215\n",
      "Epoch 3564/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7021 - val_loss: 195.6693\n",
      "Epoch 3565/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4512 - val_loss: 190.4033\n",
      "Epoch 3566/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5968 - val_loss: 193.9725\n",
      "Epoch 3567/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4328 - val_loss: 195.0292\n",
      "Epoch 3568/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2477 - val_loss: 194.4740\n",
      "Epoch 3569/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4906 - val_loss: 196.9377\n",
      "Epoch 3570/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4685 - val_loss: 194.4538\n",
      "Epoch 3571/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5010 - val_loss: 191.8786\n",
      "Epoch 3572/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8680 - val_loss: 194.8059\n",
      "Epoch 3573/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4512 - val_loss: 194.8230\n",
      "Epoch 3574/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4438 - val_loss: 192.0697\n",
      "Epoch 3575/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8797 - val_loss: 194.6487\n",
      "Epoch 3576/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5226 - val_loss: 193.5241\n",
      "Epoch 3577/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5270 - val_loss: 196.2581\n",
      "Epoch 3578/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3836 - val_loss: 193.7068\n",
      "Epoch 3579/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4255 - val_loss: 192.7773\n",
      "Epoch 3580/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6133 - val_loss: 194.4779\n",
      "Epoch 3581/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5710 - val_loss: 196.6567\n",
      "Epoch 3582/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6552 - val_loss: 195.6636\n",
      "Epoch 3583/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3223 - val_loss: 197.5602\n",
      "Epoch 3584/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8464 - val_loss: 193.2961\n",
      "Epoch 3585/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2863 - val_loss: 195.3836\n",
      "Epoch 3586/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4412 - val_loss: 194.3693\n",
      "Epoch 3587/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5468 - val_loss: 198.1583\n",
      "Epoch 3588/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8825 - val_loss: 195.2717\n",
      "Epoch 3589/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4462 - val_loss: 195.5637\n",
      "Epoch 3590/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7478 - val_loss: 194.1801\n",
      "Epoch 3591/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4174 - val_loss: 195.6102\n",
      "Epoch 3592/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4607 - val_loss: 195.0790\n",
      "Epoch 3593/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4862 - val_loss: 194.5177\n",
      "Epoch 3594/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2324 - val_loss: 194.9344\n",
      "Epoch 3595/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4270 - val_loss: 193.7783\n",
      "Epoch 3596/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6056 - val_loss: 192.5745\n",
      "Epoch 3597/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3992 - val_loss: 195.7384\n",
      "Epoch 3598/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6079 - val_loss: 194.4670\n",
      "Epoch 3599/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4110 - val_loss: 192.1365\n",
      "Epoch 3600/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8184 - val_loss: 193.5982\n",
      "Epoch 3601/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6500 - val_loss: 194.9894\n",
      "Epoch 3602/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3834 - val_loss: 195.0668\n",
      "Epoch 3603/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7721 - val_loss: 193.8261\n",
      "Epoch 3604/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4605 - val_loss: 194.5500\n",
      "Epoch 3605/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4059 - val_loss: 194.4831\n",
      "Epoch 3606/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4924 - val_loss: 191.6558\n",
      "Epoch 3607/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5235 - val_loss: 195.3092\n",
      "Epoch 3608/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6548 - val_loss: 196.4743\n",
      "Epoch 3609/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3328 - val_loss: 195.2498\n",
      "Epoch 3610/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5301 - val_loss: 195.0069\n",
      "Epoch 3611/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.6504 - val_loss: 195.7686\n",
      "Epoch 3612/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8424 - val_loss: 198.1612\n",
      "Epoch 3613/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4225 - val_loss: 195.2919\n",
      "Epoch 3614/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7188 - val_loss: 193.6675\n",
      "Epoch 3615/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5332 - val_loss: 195.1199\n",
      "Epoch 3616/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6254 - val_loss: 194.3951\n",
      "Epoch 3617/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8935 - val_loss: 192.6871\n",
      "Epoch 3618/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5351 - val_loss: 191.2206\n",
      "Epoch 3619/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5289 - val_loss: 194.3282\n",
      "Epoch 3620/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4582 - val_loss: 194.6075\n",
      "Epoch 3621/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2587 - val_loss: 194.5937\n",
      "Epoch 3622/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2978 - val_loss: 194.2330\n",
      "Epoch 3623/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5024 - val_loss: 195.2938\n",
      "Epoch 3624/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6133 - val_loss: 196.1069\n",
      "Epoch 3625/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4967 - val_loss: 194.3718\n",
      "Epoch 3626/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5137 - val_loss: 195.4792\n",
      "Epoch 3627/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6680 - val_loss: 198.7371\n",
      "Epoch 3628/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3823 - val_loss: 190.1684\n",
      "Epoch 3629/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7787 - val_loss: 193.7655\n",
      "Epoch 3630/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7339 - val_loss: 195.9786\n",
      "Epoch 3631/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6531 - val_loss: 192.6858\n",
      "Epoch 3632/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2780 - val_loss: 197.7520\n",
      "Epoch 3633/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6653 - val_loss: 195.5629\n",
      "Epoch 3634/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4252 - val_loss: 196.0984\n",
      "Epoch 3635/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5779 - val_loss: 194.8153\n",
      "Epoch 3636/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6269 - val_loss: 196.1420\n",
      "Epoch 3637/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5159 - val_loss: 194.3185\n",
      "Epoch 3638/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3608 - val_loss: 195.1652\n",
      "Epoch 3639/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6065 - val_loss: 194.7398\n",
      "Epoch 3640/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3690 - val_loss: 195.8555\n",
      "Epoch 3641/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6651 - val_loss: 196.9811\n",
      "Epoch 3642/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8243 - val_loss: 192.3881\n",
      "Epoch 3643/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6608 - val_loss: 196.1399\n",
      "Epoch 3644/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4590 - val_loss: 194.9029\n",
      "Epoch 3645/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2975 - val_loss: 197.0072\n",
      "Epoch 3646/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6210 - val_loss: 195.0035\n",
      "Epoch 3647/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4447 - val_loss: 193.2435\n",
      "Epoch 3648/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4177 - val_loss: 196.8976\n",
      "Epoch 3649/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7317 - val_loss: 194.3231\n",
      "Epoch 3650/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4927 - val_loss: 191.2483\n",
      "Epoch 3651/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5624 - val_loss: 194.7384\n",
      "Epoch 3652/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2983 - val_loss: 194.5840\n",
      "Epoch 3653/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4347 - val_loss: 194.1272\n",
      "Epoch 3654/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7911 - val_loss: 196.4090\n",
      "Epoch 3655/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4046 - val_loss: 193.7883\n",
      "Epoch 3656/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3013 - val_loss: 192.2822\n",
      "Epoch 3657/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4113 - val_loss: 197.6746\n",
      "Epoch 3658/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5932 - val_loss: 196.0287\n",
      "Epoch 3659/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3929 - val_loss: 194.7562\n",
      "Epoch 3660/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5130 - val_loss: 192.2710\n",
      "Epoch 3661/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3356 - val_loss: 194.2407\n",
      "Epoch 3662/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3976 - val_loss: 193.8158\n",
      "Epoch 3663/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5712 - val_loss: 196.8878\n",
      "Epoch 3664/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9023 - val_loss: 196.2665\n",
      "Epoch 3665/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6020 - val_loss: 194.2729\n",
      "Epoch 3666/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6137 - val_loss: 194.7666\n",
      "Epoch 3667/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5643 - val_loss: 196.9477\n",
      "Epoch 3668/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5238 - val_loss: 195.0539\n",
      "Epoch 3669/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6424 - val_loss: 192.8428\n",
      "Epoch 3670/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2395 - val_loss: 195.1626\n",
      "Epoch 3671/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4096 - val_loss: 194.8950\n",
      "Epoch 3672/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3208 - val_loss: 196.7567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3673/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8301 - val_loss: 193.7405\n",
      "Epoch 3674/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5038 - val_loss: 195.6703\n",
      "Epoch 3675/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3168 - val_loss: 195.5647\n",
      "Epoch 3676/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5515 - val_loss: 194.4655\n",
      "Epoch 3677/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6101 - val_loss: 197.1586\n",
      "Epoch 3678/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4662 - val_loss: 196.1457\n",
      "Epoch 3679/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6293 - val_loss: 196.1555\n",
      "Epoch 3680/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5152 - val_loss: 193.5602\n",
      "Epoch 3681/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7164 - val_loss: 196.3472\n",
      "Epoch 3682/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5025 - val_loss: 193.4880\n",
      "Epoch 3683/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7719 - val_loss: 195.8913\n",
      "Epoch 3684/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6132 - val_loss: 191.7675\n",
      "Epoch 3685/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6228 - val_loss: 195.4540\n",
      "Epoch 3686/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6115 - val_loss: 195.1379\n",
      "Epoch 3687/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7980 - val_loss: 194.4854\n",
      "Epoch 3688/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5749 - val_loss: 195.0241\n",
      "Epoch 3689/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6192 - val_loss: 193.8772\n",
      "Epoch 3690/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4150 - val_loss: 198.0001\n",
      "Epoch 3691/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8347 - val_loss: 196.2212\n",
      "Epoch 3692/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4584 - val_loss: 195.4676\n",
      "Epoch 3693/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6996 - val_loss: 192.9850\n",
      "Epoch 3694/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6996 - val_loss: 193.6231\n",
      "Epoch 3695/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4367 - val_loss: 196.0495\n",
      "Epoch 3696/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5209 - val_loss: 194.0440\n",
      "Epoch 3697/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5924 - val_loss: 195.8519\n",
      "Epoch 3698/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2624 - val_loss: 194.2036\n",
      "Epoch 3699/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7760 - val_loss: 191.2243\n",
      "Epoch 3700/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4644 - val_loss: 194.7305\n",
      "Epoch 3701/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4430 - val_loss: 193.5104\n",
      "Epoch 3702/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4112 - val_loss: 196.2538\n",
      "Epoch 3703/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3956 - val_loss: 195.0339\n",
      "Epoch 3704/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4675 - val_loss: 194.2739\n",
      "Epoch 3705/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4369 - val_loss: 194.6402\n",
      "Epoch 3706/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6044 - val_loss: 194.9564\n",
      "Epoch 3707/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.6650 - val_loss: 195.8517\n",
      "Epoch 3708/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7030 - val_loss: 192.0012\n",
      "Epoch 3709/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4964 - val_loss: 194.8573\n",
      "Epoch 3710/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3901 - val_loss: 193.5754\n",
      "Epoch 3711/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3332 - val_loss: 194.6784\n",
      "Epoch 3712/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3269 - val_loss: 194.5774\n",
      "Epoch 3713/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6182 - val_loss: 193.5329\n",
      "Epoch 3714/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6714 - val_loss: 196.2420\n",
      "Epoch 3715/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4580 - val_loss: 197.0115\n",
      "Epoch 3716/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4848 - val_loss: 196.1504\n",
      "Epoch 3717/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2515 - val_loss: 193.8012\n",
      "Epoch 3718/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5778 - val_loss: 193.6211\n",
      "Epoch 3719/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5696 - val_loss: 194.2127\n",
      "Epoch 3720/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4697 - val_loss: 195.0692\n",
      "Epoch 3721/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5787 - val_loss: 193.3808\n",
      "Epoch 3722/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3343 - val_loss: 195.8990\n",
      "Epoch 3723/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5165 - val_loss: 195.7359\n",
      "Epoch 3724/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4862 - val_loss: 197.2879\n",
      "Epoch 3725/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7664 - val_loss: 193.7525\n",
      "Epoch 3726/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5015 - val_loss: 195.6962\n",
      "Epoch 3727/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5463 - val_loss: 197.8152\n",
      "Epoch 3728/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7127 - val_loss: 197.3744\n",
      "Epoch 3729/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4076 - val_loss: 196.4436\n",
      "Epoch 3730/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9359 - val_loss: 194.6573\n",
      "Epoch 3731/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6935 - val_loss: 195.1395\n",
      "Epoch 3732/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7265 - val_loss: 196.6342\n",
      "Epoch 3733/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7683 - val_loss: 195.9413\n",
      "Epoch 3734/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4917 - val_loss: 193.8123\n",
      "Epoch 3735/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8207 - val_loss: 196.2101\n",
      "Epoch 3736/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3007 - val_loss: 196.3897\n",
      "Epoch 3737/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5533 - val_loss: 194.3434\n",
      "Epoch 3738/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4230 - val_loss: 196.6111\n",
      "Epoch 3739/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2207 - val_loss: 197.7021\n",
      "Epoch 3740/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5775 - val_loss: 197.2961\n",
      "Epoch 3741/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6532 - val_loss: 192.3133\n",
      "Epoch 3742/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5206 - val_loss: 194.3980\n",
      "Epoch 3743/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2710 - val_loss: 196.2114\n",
      "Epoch 3744/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9979 - val_loss: 185.6826\n",
      "Epoch 3745/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7452 - val_loss: 194.0582\n",
      "Epoch 3746/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6528 - val_loss: 191.1533\n",
      "Epoch 3747/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5226 - val_loss: 195.9164\n",
      "Epoch 3748/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6248 - val_loss: 194.9573\n",
      "Epoch 3749/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4818 - val_loss: 195.2424\n",
      "Epoch 3750/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4295 - val_loss: 190.8965\n",
      "Epoch 3751/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5022 - val_loss: 195.3597\n",
      "Epoch 3752/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6191 - val_loss: 193.0900\n",
      "Epoch 3753/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6403 - val_loss: 192.2792\n",
      "Epoch 3754/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6491 - val_loss: 194.7090\n",
      "Epoch 3755/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.2982 - val_loss: 195.0170\n",
      "Epoch 3756/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4960 - val_loss: 191.8432\n",
      "Epoch 3757/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3978 - val_loss: 193.2660\n",
      "Epoch 3758/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5825 - val_loss: 196.1896\n",
      "Epoch 3759/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7694 - val_loss: 194.2667\n",
      "Epoch 3760/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4430 - val_loss: 195.4389\n",
      "Epoch 3761/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3765 - val_loss: 199.2076\n",
      "Epoch 3762/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6478 - val_loss: 193.5149\n",
      "Epoch 3763/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3138 - val_loss: 195.2783\n",
      "Epoch 3764/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3141 - val_loss: 195.6304\n",
      "Epoch 3765/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4804 - val_loss: 194.2231\n",
      "Epoch 3766/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5517 - val_loss: 197.0006\n",
      "Epoch 3767/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9851 - val_loss: 194.6802\n",
      "Epoch 3768/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2204 - val_loss: 192.9719\n",
      "Epoch 3769/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6521 - val_loss: 194.3636\n",
      "Epoch 3770/20000\n",
      "17948/17948 [==============================] - ETA: 0s - loss: 70.82 - 1s 33us/sample - loss: 70.9402 - val_loss: 191.2948\n",
      "Epoch 3771/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4010 - val_loss: 193.7617\n",
      "Epoch 3772/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3472 - val_loss: 196.5906\n",
      "Epoch 3773/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5441 - val_loss: 194.0834\n",
      "Epoch 3774/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4941 - val_loss: 196.2845\n",
      "Epoch 3775/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4725 - val_loss: 195.5579\n",
      "Epoch 3776/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6935 - val_loss: 196.0659\n",
      "Epoch 3777/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5726 - val_loss: 196.3071\n",
      "Epoch 3778/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5493 - val_loss: 193.4573\n",
      "Epoch 3779/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5831 - val_loss: 194.9270\n",
      "Epoch 3780/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4939 - val_loss: 194.9199\n",
      "Epoch 3781/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3725 - val_loss: 195.9955\n",
      "Epoch 3782/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6473 - val_loss: 194.2880\n",
      "Epoch 3783/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3703 - val_loss: 191.4470\n",
      "Epoch 3784/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7396 - val_loss: 195.2840\n",
      "Epoch 3785/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9189 - val_loss: 194.1539\n",
      "Epoch 3786/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5343 - val_loss: 195.5858\n",
      "Epoch 3787/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6515 - val_loss: 192.3017\n",
      "Epoch 3788/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8898 - val_loss: 195.1229\n",
      "Epoch 3789/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6234 - val_loss: 195.0562\n",
      "Epoch 3790/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5246 - val_loss: 193.4751\n",
      "Epoch 3791/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3532 - val_loss: 197.1754\n",
      "Epoch 3792/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5734 - val_loss: 196.9490\n",
      "Epoch 3793/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3625 - val_loss: 196.1626\n",
      "Epoch 3794/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7491 - val_loss: 198.1148\n",
      "Epoch 3795/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2485 - val_loss: 197.5827\n",
      "Epoch 3796/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5073 - val_loss: 196.0190\n",
      "Epoch 3797/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3878 - val_loss: 194.6256\n",
      "Epoch 3798/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3417 - val_loss: 197.4062\n",
      "Epoch 3799/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3642 - val_loss: 190.5743\n",
      "Epoch 3800/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4092 - val_loss: 197.1701\n",
      "Epoch 3801/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6176 - val_loss: 197.9251\n",
      "Epoch 3802/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5121 - val_loss: 194.0057\n",
      "Epoch 3803/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3903 - val_loss: 199.4536\n",
      "Epoch 3804/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6386 - val_loss: 196.5125\n",
      "Epoch 3805/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9979 - val_loss: 195.6444\n",
      "Epoch 3806/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5863 - val_loss: 192.5189\n",
      "Epoch 3807/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3624 - val_loss: 197.3114\n",
      "Epoch 3808/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4922 - val_loss: 196.6017\n",
      "Epoch 3809/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3660 - val_loss: 198.8098\n",
      "Epoch 3810/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8297 - val_loss: 194.7342\n",
      "Epoch 3811/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5009 - val_loss: 195.8938\n",
      "Epoch 3812/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6278 - val_loss: 192.9711\n",
      "Epoch 3813/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5450 - val_loss: 195.2473\n",
      "Epoch 3814/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5990 - val_loss: 194.4424\n",
      "Epoch 3815/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5626 - val_loss: 193.5624\n",
      "Epoch 3816/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7675 - val_loss: 195.5570\n",
      "Epoch 3817/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6312 - val_loss: 196.5720\n",
      "Epoch 3818/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9148 - val_loss: 194.0095\n",
      "Epoch 3819/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8732 - val_loss: 194.9058\n",
      "Epoch 3820/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5563 - val_loss: 195.3434\n",
      "Epoch 3821/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8879 - val_loss: 194.4905\n",
      "Epoch 3822/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2888 - val_loss: 195.6959\n",
      "Epoch 3823/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7279 - val_loss: 194.3245\n",
      "Epoch 3824/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6473 - val_loss: 194.8522\n",
      "Epoch 3825/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3470 - val_loss: 193.9285\n",
      "Epoch 3826/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2566 - val_loss: 195.5632\n",
      "Epoch 3827/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5067 - val_loss: 197.8364\n",
      "Epoch 3828/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7629 - val_loss: 193.6421\n",
      "Epoch 3829/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4986 - val_loss: 194.7266\n",
      "Epoch 3830/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6100 - val_loss: 194.1719\n",
      "Epoch 3831/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5802 - val_loss: 196.9949\n",
      "Epoch 3832/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6272 - val_loss: 192.2901\n",
      "Epoch 3833/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5894 - val_loss: 193.8805\n",
      "Epoch 3834/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4931 - val_loss: 193.2173\n",
      "Epoch 3835/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6107 - val_loss: 195.4604\n",
      "Epoch 3836/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4686 - val_loss: 195.5414\n",
      "Epoch 3837/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4746 - val_loss: 194.2855\n",
      "Epoch 3838/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6523 - val_loss: 194.1908\n",
      "Epoch 3839/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5668 - val_loss: 194.9353\n",
      "Epoch 3840/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6371 - val_loss: 195.1366\n",
      "Epoch 3841/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7522 - val_loss: 194.9143\n",
      "Epoch 3842/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5911 - val_loss: 194.6227\n",
      "Epoch 3843/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5761 - val_loss: 191.8952\n",
      "Epoch 3844/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5322 - val_loss: 194.7713\n",
      "Epoch 3845/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8240 - val_loss: 196.1284\n",
      "Epoch 3846/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2856 - val_loss: 195.9262\n",
      "Epoch 3847/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5748 - val_loss: 192.8250\n",
      "Epoch 3848/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3837 - val_loss: 195.1522\n",
      "Epoch 3849/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4768 - val_loss: 195.1276\n",
      "Epoch 3850/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5201 - val_loss: 192.3681\n",
      "Epoch 3851/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5463 - val_loss: 195.5331\n",
      "Epoch 3852/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6735 - val_loss: 193.9528\n",
      "Epoch 3853/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4570 - val_loss: 197.0615\n",
      "Epoch 3854/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5331 - val_loss: 192.9145\n",
      "Epoch 3855/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7149 - val_loss: 195.9544\n",
      "Epoch 3856/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6999 - val_loss: 196.1039\n",
      "Epoch 3857/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3885 - val_loss: 199.7358\n",
      "Epoch 3858/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6528 - val_loss: 194.8152\n",
      "Epoch 3859/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5862 - val_loss: 195.6410\n",
      "Epoch 3860/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6791 - val_loss: 192.9190\n",
      "Epoch 3861/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5322 - val_loss: 196.2343\n",
      "Epoch 3862/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3863 - val_loss: 194.6900\n",
      "Epoch 3863/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5470 - val_loss: 193.2520\n",
      "Epoch 3864/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6203 - val_loss: 194.6084\n",
      "Epoch 3865/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7638 - val_loss: 193.8254\n",
      "Epoch 3866/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7467 - val_loss: 196.0527\n",
      "Epoch 3867/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6168 - val_loss: 191.0470\n",
      "Epoch 3868/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3714 - val_loss: 197.3944\n",
      "Epoch 3869/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7133 - val_loss: 194.3790\n",
      "Epoch 3870/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6561 - val_loss: 194.7389\n",
      "Epoch 3871/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6896 - val_loss: 191.9706\n",
      "Epoch 3872/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3685 - val_loss: 188.5913\n",
      "Epoch 3873/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4936 - val_loss: 193.1511\n",
      "Epoch 3874/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4901 - val_loss: 192.9086\n",
      "Epoch 3875/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6027 - val_loss: 195.7869\n",
      "Epoch 3876/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5928 - val_loss: 194.6190\n",
      "Epoch 3877/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3718 - val_loss: 194.1680\n",
      "Epoch 3878/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3013 - val_loss: 193.8351\n",
      "Epoch 3879/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5855 - val_loss: 194.7847\n",
      "Epoch 3880/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8099 - val_loss: 193.4478\n",
      "Epoch 3881/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4711 - val_loss: 191.8891\n",
      "Epoch 3882/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3863 - val_loss: 195.0128\n",
      "Epoch 3883/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2802 - val_loss: 192.6202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3884/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3781 - val_loss: 193.0191\n",
      "Epoch 3885/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4121 - val_loss: 194.2995\n",
      "Epoch 3886/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4859 - val_loss: 195.2983\n",
      "Epoch 3887/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6003 - val_loss: 193.8119\n",
      "Epoch 3888/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9133 - val_loss: 193.9908\n",
      "Epoch 3889/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5980 - val_loss: 195.3257\n",
      "Epoch 3890/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4943 - val_loss: 191.7925\n",
      "Epoch 3891/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5193 - val_loss: 195.9384\n",
      "Epoch 3892/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4358 - val_loss: 194.5532\n",
      "Epoch 3893/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9618 - val_loss: 194.8320\n",
      "Epoch 3894/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5904 - val_loss: 197.3488\n",
      "Epoch 3895/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4548 - val_loss: 193.9316\n",
      "Epoch 3896/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3054 - val_loss: 195.1846\n",
      "Epoch 3897/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7340 - val_loss: 194.3340\n",
      "Epoch 3898/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4720 - val_loss: 195.0827\n",
      "Epoch 3899/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4892 - val_loss: 194.9375\n",
      "Epoch 3900/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5466 - val_loss: 197.1582\n",
      "Epoch 3901/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4647 - val_loss: 196.0031\n",
      "Epoch 3902/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4906 - val_loss: 191.8895\n",
      "Epoch 3903/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5005 - val_loss: 197.2340\n",
      "Epoch 3904/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4827 - val_loss: 196.3450\n",
      "Epoch 3905/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4672 - val_loss: 194.9674\n",
      "Epoch 3906/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5825 - val_loss: 192.7831\n",
      "Epoch 3907/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3496 - val_loss: 195.0155\n",
      "Epoch 3908/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7710 - val_loss: 195.6018\n",
      "Epoch 3909/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1729 - val_loss: 193.5154\n",
      "Epoch 3910/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4531 - val_loss: 194.5764\n",
      "Epoch 3911/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2171 - val_loss: 193.7852\n",
      "Epoch 3912/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6143 - val_loss: 196.0682\n",
      "Epoch 3913/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8011 - val_loss: 195.5298\n",
      "Epoch 3914/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4178 - val_loss: 198.9600\n",
      "Epoch 3915/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6417 - val_loss: 195.1652\n",
      "Epoch 3916/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2802 - val_loss: 198.3985\n",
      "Epoch 3917/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2621 - val_loss: 195.6517\n",
      "Epoch 3918/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5020 - val_loss: 195.7438\n",
      "Epoch 3919/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3759 - val_loss: 197.7773\n",
      "Epoch 3920/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5867 - val_loss: 196.1156\n",
      "Epoch 3921/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5675 - val_loss: 198.7559\n",
      "Epoch 3922/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5636 - val_loss: 195.7636\n",
      "Epoch 3923/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6773 - val_loss: 193.5982\n",
      "Epoch 3924/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2810 - val_loss: 192.3265\n",
      "Epoch 3925/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8059 - val_loss: 193.4288\n",
      "Epoch 3926/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0116 - val_loss: 195.0593\n",
      "Epoch 3927/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6456 - val_loss: 195.7609\n",
      "Epoch 3928/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4418 - val_loss: 195.5890\n",
      "Epoch 3929/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5282 - val_loss: 192.6206\n",
      "Epoch 3930/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5096 - val_loss: 195.0067\n",
      "Epoch 3931/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5377 - val_loss: 198.5342\n",
      "Epoch 3932/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3219 - val_loss: 196.0185\n",
      "Epoch 3933/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7722 - val_loss: 197.0793\n",
      "Epoch 3934/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7463 - val_loss: 194.4260\n",
      "Epoch 3935/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7569 - val_loss: 195.4001\n",
      "Epoch 3936/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3179 - val_loss: 196.7735\n",
      "Epoch 3937/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4304 - val_loss: 195.8034\n",
      "Epoch 3938/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5094 - val_loss: 196.6825\n",
      "Epoch 3939/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5714 - val_loss: 194.3054\n",
      "Epoch 3940/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4660 - val_loss: 194.6659\n",
      "Epoch 3941/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1365 - val_loss: 194.8736\n",
      "Epoch 3942/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5450 - val_loss: 195.2180\n",
      "Epoch 3943/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5802 - val_loss: 195.3304\n",
      "Epoch 3944/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6901 - val_loss: 192.5272\n",
      "Epoch 3945/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2476 - val_loss: 196.3217\n",
      "Epoch 3946/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6748 - val_loss: 196.9551\n",
      "Epoch 3947/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5629 - val_loss: 192.2762\n",
      "Epoch 3948/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3650 - val_loss: 195.2386\n",
      "Epoch 3949/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4814 - val_loss: 194.8867\n",
      "Epoch 3950/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3536 - val_loss: 194.9744\n",
      "Epoch 3951/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6126 - val_loss: 194.9692\n",
      "Epoch 3952/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3286 - val_loss: 197.6788\n",
      "Epoch 3953/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8952 - val_loss: 190.7180\n",
      "Epoch 3954/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4947 - val_loss: 197.4062\n",
      "Epoch 3955/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5472 - val_loss: 195.2434\n",
      "Epoch 3956/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5421 - val_loss: 192.8547\n",
      "Epoch 3957/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4330 - val_loss: 197.3166\n",
      "Epoch 3958/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8267 - val_loss: 194.8548\n",
      "Epoch 3959/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3733 - val_loss: 193.5422\n",
      "Epoch 3960/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6581 - val_loss: 194.2758\n",
      "Epoch 3961/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3724 - val_loss: 194.5392\n",
      "Epoch 3962/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4950 - val_loss: 198.1726\n",
      "Epoch 3963/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2898 - val_loss: 194.7684\n",
      "Epoch 3964/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7180 - val_loss: 194.1741\n",
      "Epoch 3965/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5363 - val_loss: 196.2564\n",
      "Epoch 3966/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8026 - val_loss: 195.7351\n",
      "Epoch 3967/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4706 - val_loss: 196.1981\n",
      "Epoch 3968/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6421 - val_loss: 195.6119\n",
      "Epoch 3969/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3913 - val_loss: 196.0345\n",
      "Epoch 3970/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4606 - val_loss: 194.2352\n",
      "Epoch 3971/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8461 - val_loss: 194.7838\n",
      "Epoch 3972/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2606 - val_loss: 194.1248\n",
      "Epoch 3973/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6019 - val_loss: 194.6883\n",
      "Epoch 3974/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5653 - val_loss: 195.2681\n",
      "Epoch 3975/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4068 - val_loss: 194.9725\n",
      "Epoch 3976/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5141 - val_loss: 192.0273\n",
      "Epoch 3977/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6560 - val_loss: 194.1282\n",
      "Epoch 3978/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1827 - val_loss: 196.8472\n",
      "Epoch 3979/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4940 - val_loss: 196.6371\n",
      "Epoch 3980/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4409 - val_loss: 195.3206\n",
      "Epoch 3981/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4595 - val_loss: 196.4475\n",
      "Epoch 3982/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6257 - val_loss: 194.5666\n",
      "Epoch 3983/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2082 - val_loss: 195.7280\n",
      "Epoch 3984/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6028 - val_loss: 196.4286\n",
      "Epoch 3985/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7146 - val_loss: 195.4500\n",
      "Epoch 3986/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5973 - val_loss: 195.9386\n",
      "Epoch 3987/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4672 - val_loss: 196.9946\n",
      "Epoch 3988/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7977 - val_loss: 196.8627\n",
      "Epoch 3989/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4310 - val_loss: 195.6598\n",
      "Epoch 3990/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2487 - val_loss: 195.9900\n",
      "Epoch 3991/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3826 - val_loss: 195.4516\n",
      "Epoch 3992/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9085 - val_loss: 192.4188\n",
      "Epoch 3993/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7377 - val_loss: 197.3084\n",
      "Epoch 3994/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7794 - val_loss: 197.3724\n",
      "Epoch 3995/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4286 - val_loss: 195.1326\n",
      "Epoch 3996/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4962 - val_loss: 194.7108\n",
      "Epoch 3997/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6517 - val_loss: 195.4056\n",
      "Epoch 3998/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5701 - val_loss: 193.8027\n",
      "Epoch 3999/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3038 - val_loss: 195.0764\n",
      "Epoch 4000/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3325 - val_loss: 195.3011\n",
      "Epoch 4001/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5003 - val_loss: 194.3883\n",
      "Epoch 4002/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2862 - val_loss: 195.2413\n",
      "Epoch 4003/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6713 - val_loss: 196.2912\n",
      "Epoch 4004/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6057 - val_loss: 194.3029\n",
      "Epoch 4005/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4628 - val_loss: 192.8548\n",
      "Epoch 4006/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2835 - val_loss: 192.0188\n",
      "Epoch 4007/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3742 - val_loss: 195.7372\n",
      "Epoch 4008/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5107 - val_loss: 195.8261\n",
      "Epoch 4009/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7228 - val_loss: 194.2511\n",
      "Epoch 4010/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4856 - val_loss: 192.5538\n",
      "Epoch 4011/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6799 - val_loss: 195.2691\n",
      "Epoch 4012/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4459 - val_loss: 192.9940\n",
      "Epoch 4013/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6672 - val_loss: 195.1287\n",
      "Epoch 4014/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5775 - val_loss: 195.2717\n",
      "Epoch 4015/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6868 - val_loss: 196.7134\n",
      "Epoch 4016/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6010 - val_loss: 193.5579\n",
      "Epoch 4017/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7926 - val_loss: 193.7744\n",
      "Epoch 4018/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5992 - val_loss: 194.5978\n",
      "Epoch 4019/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4708 - val_loss: 198.5723\n",
      "Epoch 4020/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5877 - val_loss: 192.3095\n",
      "Epoch 4021/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4879 - val_loss: 194.8393\n",
      "Epoch 4022/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1497 - val_loss: 193.9037\n",
      "Epoch 4023/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6474 - val_loss: 194.2540\n",
      "Epoch 4024/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8476 - val_loss: 197.6522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4025/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7811 - val_loss: 195.4986\n",
      "Epoch 4026/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4840 - val_loss: 193.8896\n",
      "Epoch 4027/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7021 - val_loss: 194.6261\n",
      "Epoch 4028/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4727 - val_loss: 195.5613\n",
      "Epoch 4029/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2858 - val_loss: 193.1022\n",
      "Epoch 4030/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2589 - val_loss: 194.9529\n",
      "Epoch 4031/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7037 - val_loss: 194.8179\n",
      "Epoch 4032/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5258 - val_loss: 195.8289\n",
      "Epoch 4033/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3100 - val_loss: 197.1464\n",
      "Epoch 4034/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6270 - val_loss: 197.8198\n",
      "Epoch 4035/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4948 - val_loss: 195.7924\n",
      "Epoch 4036/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3410 - val_loss: 194.6227\n",
      "Epoch 4037/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3983 - val_loss: 197.9794\n",
      "Epoch 4038/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5986 - val_loss: 194.7299\n",
      "Epoch 4039/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3569 - val_loss: 195.4254\n",
      "Epoch 4040/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4872 - val_loss: 192.0121\n",
      "Epoch 4041/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2576 - val_loss: 192.9896\n",
      "Epoch 4042/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6196 - val_loss: 196.4102\n",
      "Epoch 4043/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6681 - val_loss: 192.3687\n",
      "Epoch 4044/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4385 - val_loss: 195.1234\n",
      "Epoch 4045/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3389 - val_loss: 196.1017\n",
      "Epoch 4046/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3689 - val_loss: 196.4991\n",
      "Epoch 4047/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3482 - val_loss: 194.0087\n",
      "Epoch 4048/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9549 - val_loss: 194.1280\n",
      "Epoch 4049/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4979 - val_loss: 195.5533\n",
      "Epoch 4050/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6156 - val_loss: 196.1929\n",
      "Epoch 4051/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5583 - val_loss: 195.4676\n",
      "Epoch 4052/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4078 - val_loss: 194.5102\n",
      "Epoch 4053/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8259 - val_loss: 189.8109\n",
      "Epoch 4054/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5410 - val_loss: 195.5828\n",
      "Epoch 4055/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7461 - val_loss: 197.2451\n",
      "Epoch 4056/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6083 - val_loss: 196.1501\n",
      "Epoch 4057/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4845 - val_loss: 194.6989\n",
      "Epoch 4058/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5813 - val_loss: 198.2905\n",
      "Epoch 4059/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4014 - val_loss: 195.5067\n",
      "Epoch 4060/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3843 - val_loss: 195.1036\n",
      "Epoch 4061/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5584 - val_loss: 194.4709\n",
      "Epoch 4062/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5086 - val_loss: 194.2724\n",
      "Epoch 4063/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3165 - val_loss: 197.2412\n",
      "Epoch 4064/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4764 - val_loss: 193.9036\n",
      "Epoch 4065/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5502 - val_loss: 195.9370\n",
      "Epoch 4066/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5376 - val_loss: 194.5481\n",
      "Epoch 4067/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4752 - val_loss: 194.9892\n",
      "Epoch 4068/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5151 - val_loss: 197.6743\n",
      "Epoch 4069/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5608 - val_loss: 195.9455\n",
      "Epoch 4070/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3488 - val_loss: 192.4750\n",
      "Epoch 4071/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5892 - val_loss: 194.6256\n",
      "Epoch 4072/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8472 - val_loss: 194.8724\n",
      "Epoch 4073/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4364 - val_loss: 194.2265\n",
      "Epoch 4074/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8600 - val_loss: 194.0427\n",
      "Epoch 4075/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8029 - val_loss: 194.5984\n",
      "Epoch 4076/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5238 - val_loss: 196.7280\n",
      "Epoch 4077/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3789 - val_loss: 193.9207\n",
      "Epoch 4078/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4727 - val_loss: 197.1056\n",
      "Epoch 4079/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7043 - val_loss: 192.8938\n",
      "Epoch 4080/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4364 - val_loss: 196.3335\n",
      "Epoch 4081/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4998 - val_loss: 196.5212\n",
      "Epoch 4082/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5311 - val_loss: 193.8801\n",
      "Epoch 4083/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0788 - val_loss: 191.1031\n",
      "Epoch 4084/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6737 - val_loss: 193.1731\n",
      "Epoch 4085/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5945 - val_loss: 193.4345\n",
      "Epoch 4086/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9981 - val_loss: 190.8885\n",
      "Epoch 4087/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4889 - val_loss: 192.2185\n",
      "Epoch 4088/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5518 - val_loss: 194.2614\n",
      "Epoch 4089/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2779 - val_loss: 193.0031\n",
      "Epoch 4090/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4326 - val_loss: 197.8700\n",
      "Epoch 4091/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3741 - val_loss: 196.3216\n",
      "Epoch 4092/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6037 - val_loss: 194.4719\n",
      "Epoch 4093/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6920 - val_loss: 195.4247\n",
      "Epoch 4094/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4052 - val_loss: 193.3014\n",
      "Epoch 4095/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5288 - val_loss: 192.5032\n",
      "Epoch 4096/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5576 - val_loss: 195.1218\n",
      "Epoch 4097/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7267 - val_loss: 195.5616\n",
      "Epoch 4098/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4914 - val_loss: 198.0004\n",
      "Epoch 4099/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5764 - val_loss: 195.0864\n",
      "Epoch 4100/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3487 - val_loss: 193.4201\n",
      "Epoch 4101/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6647 - val_loss: 196.4151\n",
      "Epoch 4102/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3024 - val_loss: 197.9757\n",
      "Epoch 4103/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6388 - val_loss: 195.8977\n",
      "Epoch 4104/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6642 - val_loss: 192.8923\n",
      "Epoch 4105/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4664 - val_loss: 195.1830\n",
      "Epoch 4106/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4154 - val_loss: 194.0552\n",
      "Epoch 4107/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6628 - val_loss: 193.0011\n",
      "Epoch 4108/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4758 - val_loss: 192.7055\n",
      "Epoch 4109/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3562 - val_loss: 194.1645\n",
      "Epoch 4110/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7582 - val_loss: 195.2365\n",
      "Epoch 4111/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5115 - val_loss: 193.2048\n",
      "Epoch 4112/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2656 - val_loss: 194.3759\n",
      "Epoch 4113/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4522 - val_loss: 194.6200\n",
      "Epoch 4114/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6179 - val_loss: 196.7559\n",
      "Epoch 4115/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4078 - val_loss: 195.9526\n",
      "Epoch 4116/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0586 - val_loss: 193.3047\n",
      "Epoch 4117/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5266 - val_loss: 196.3666\n",
      "Epoch 4118/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3832 - val_loss: 194.5633\n",
      "Epoch 4119/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9266 - val_loss: 194.3627\n",
      "Epoch 4120/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4355 - val_loss: 195.1924\n",
      "Epoch 4121/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6045 - val_loss: 192.3898\n",
      "Epoch 4122/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4477 - val_loss: 191.8636\n",
      "Epoch 4123/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5464 - val_loss: 193.4992\n",
      "Epoch 4124/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3746 - val_loss: 194.2983\n",
      "Epoch 4125/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5029 - val_loss: 195.6603\n",
      "Epoch 4126/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5220 - val_loss: 197.0928\n",
      "Epoch 4127/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7650 - val_loss: 198.0985\n",
      "Epoch 4128/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4675 - val_loss: 193.9972\n",
      "Epoch 4129/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4750 - val_loss: 192.3623\n",
      "Epoch 4130/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6176 - val_loss: 196.7164\n",
      "Epoch 4131/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5263 - val_loss: 196.5163\n",
      "Epoch 4132/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5955 - val_loss: 196.0076\n",
      "Epoch 4133/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3220 - val_loss: 194.7110\n",
      "Epoch 4134/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6755 - val_loss: 196.1644\n",
      "Epoch 4135/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5314 - val_loss: 193.0843\n",
      "Epoch 4136/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5075 - val_loss: 192.5860\n",
      "Epoch 4137/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8957 - val_loss: 194.8715\n",
      "Epoch 4138/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7259 - val_loss: 195.8686\n",
      "Epoch 4139/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4862 - val_loss: 195.7447\n",
      "Epoch 4140/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7317 - val_loss: 195.8976\n",
      "Epoch 4141/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5190 - val_loss: 191.5057\n",
      "Epoch 4142/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4910 - val_loss: 192.1995\n",
      "Epoch 4143/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3635 - val_loss: 194.9269\n",
      "Epoch 4144/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4166 - val_loss: 198.9485\n",
      "Epoch 4145/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6624 - val_loss: 194.4221\n",
      "Epoch 4146/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3522 - val_loss: 195.4769\n",
      "Epoch 4147/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5309 - val_loss: 194.1139\n",
      "Epoch 4148/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3600 - val_loss: 193.7004\n",
      "Epoch 4149/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6739 - val_loss: 194.2305\n",
      "Epoch 4150/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5161 - val_loss: 195.0590\n",
      "Epoch 4151/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4954 - val_loss: 194.0193\n",
      "Epoch 4152/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4204 - val_loss: 196.6422\n",
      "Epoch 4153/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1777 - val_loss: 194.6328\n",
      "Epoch 4154/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5665 - val_loss: 193.7149\n",
      "Epoch 4155/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5921 - val_loss: 193.3790\n",
      "Epoch 4156/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4244 - val_loss: 198.3153\n",
      "Epoch 4157/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5950 - val_loss: 193.2971\n",
      "Epoch 4158/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4228 - val_loss: 196.4143\n",
      "Epoch 4159/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6027 - val_loss: 193.2168\n",
      "Epoch 4160/20000\n",
      "17948/17948 [==============================] - 1s 46us/sample - loss: 70.2227 - val_loss: 192.2267\n",
      "Epoch 4161/20000\n",
      "17948/17948 [==============================] - 1s 43us/sample - loss: 70.3879 - val_loss: 193.5371\n",
      "Epoch 4162/20000\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 70.5800 - val_loss: 196.5377\n",
      "Epoch 4163/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.3882 - val_loss: 195.6921\n",
      "Epoch 4164/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.4231 - val_loss: 196.9393\n",
      "Epoch 4165/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.4215 - val_loss: 194.4895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4166/20000\n",
      "17948/17948 [==============================] - 1s 37us/sample - loss: 70.6480 - val_loss: 191.9454\n",
      "Epoch 4167/20000\n",
      "17948/17948 [==============================] - 1s 40us/sample - loss: 70.7912 - val_loss: 191.8804\n",
      "Epoch 4168/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.7311 - val_loss: 190.1656\n",
      "Epoch 4169/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.8388 - val_loss: 193.3704\n",
      "Epoch 4170/20000\n",
      "17948/17948 [==============================] - 1s 36us/sample - loss: 70.5554 - val_loss: 193.1674\n",
      "Epoch 4171/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.1734 - val_loss: 194.1240\n",
      "Epoch 4172/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6328 - val_loss: 195.2078\n",
      "Epoch 4173/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9688 - val_loss: 190.2062\n",
      "Epoch 4174/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3589 - val_loss: 194.4197\n",
      "Epoch 4175/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4621 - val_loss: 195.5142\n",
      "Epoch 4176/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6146 - val_loss: 194.5517\n",
      "Epoch 4177/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3277 - val_loss: 195.8868\n",
      "Epoch 4178/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8450 - val_loss: 191.6560\n",
      "Epoch 4179/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5094 - val_loss: 194.0949\n",
      "Epoch 4180/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5590 - val_loss: 194.7862\n",
      "Epoch 4181/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4587 - val_loss: 198.3203\n",
      "Epoch 4182/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5785 - val_loss: 197.8869\n",
      "Epoch 4183/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4673 - val_loss: 195.6613\n",
      "Epoch 4184/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5602 - val_loss: 194.9923\n",
      "Epoch 4185/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6918 - val_loss: 196.4942\n",
      "Epoch 4186/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5793 - val_loss: 193.3053\n",
      "Epoch 4187/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5284 - val_loss: 190.9618\n",
      "Epoch 4188/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4971 - val_loss: 197.0647\n",
      "Epoch 4189/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1865 - val_loss: 194.1828\n",
      "Epoch 4190/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7511 - val_loss: 193.2427\n",
      "Epoch 4191/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6252 - val_loss: 195.7823\n",
      "Epoch 4192/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1328 - val_loss: 190.7344\n",
      "Epoch 4193/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6027 - val_loss: 196.3559\n",
      "Epoch 4194/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4191 - val_loss: 195.0493\n",
      "Epoch 4195/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1964 - val_loss: 195.5257\n",
      "Epoch 4196/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6144 - val_loss: 194.3822\n",
      "Epoch 4197/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7620 - val_loss: 197.1525\n",
      "Epoch 4198/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3512 - val_loss: 194.6675\n",
      "Epoch 4199/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6425 - val_loss: 197.6735\n",
      "Epoch 4200/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4377 - val_loss: 196.3549\n",
      "Epoch 4201/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3612 - val_loss: 196.8567\n",
      "Epoch 4202/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6717 - val_loss: 193.2203\n",
      "Epoch 4203/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6300 - val_loss: 195.4090\n",
      "Epoch 4204/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3906 - val_loss: 194.7900\n",
      "Epoch 4205/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4255 - val_loss: 195.6694\n",
      "Epoch 4206/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4004 - val_loss: 194.6706\n",
      "Epoch 4207/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6280 - val_loss: 196.0372\n",
      "Epoch 4208/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5116 - val_loss: 191.2366\n",
      "Epoch 4209/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3581 - val_loss: 196.6085\n",
      "Epoch 4210/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.1201 - val_loss: 192.3765\n",
      "Epoch 4211/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8227 - val_loss: 195.9625\n",
      "Epoch 4212/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3510 - val_loss: 194.2339\n",
      "Epoch 4213/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3286 - val_loss: 198.6198\n",
      "Epoch 4214/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3875 - val_loss: 195.3080\n",
      "Epoch 4215/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3962 - val_loss: 192.7655\n",
      "Epoch 4216/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6920 - val_loss: 194.9608\n",
      "Epoch 4217/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5798 - val_loss: 197.0455\n",
      "Epoch 4218/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6134 - val_loss: 195.7727\n",
      "Epoch 4219/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4182 - val_loss: 194.1973\n",
      "Epoch 4220/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3024 - val_loss: 195.4555\n",
      "Epoch 4221/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8215 - val_loss: 195.8062\n",
      "Epoch 4222/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5664 - val_loss: 196.6588\n",
      "Epoch 4223/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6729 - val_loss: 194.7248\n",
      "Epoch 4224/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4074 - val_loss: 198.0521\n",
      "Epoch 4225/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4578 - val_loss: 193.5232\n",
      "Epoch 4226/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4734 - val_loss: 193.4516\n",
      "Epoch 4227/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4397 - val_loss: 194.5376\n",
      "Epoch 4228/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5281 - val_loss: 194.5530\n",
      "Epoch 4229/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5941 - val_loss: 192.0726\n",
      "Epoch 4230/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7617 - val_loss: 191.5869\n",
      "Epoch 4231/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6907 - val_loss: 197.2625\n",
      "Epoch 4232/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4228 - val_loss: 196.2799\n",
      "Epoch 4233/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6763 - val_loss: 194.5047\n",
      "Epoch 4234/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2142 - val_loss: 195.4462\n",
      "Epoch 4235/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5534 - val_loss: 198.5549\n",
      "Epoch 4236/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5514 - val_loss: 196.6034\n",
      "Epoch 4237/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3355 - val_loss: 193.6794\n",
      "Epoch 4238/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4420 - val_loss: 197.1847\n",
      "Epoch 4239/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3977 - val_loss: 193.4766\n",
      "Epoch 4240/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4789 - val_loss: 195.8296\n",
      "Epoch 4241/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6170 - val_loss: 198.2607\n",
      "Epoch 4242/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5898 - val_loss: 196.1017\n",
      "Epoch 4243/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6356 - val_loss: 195.4739\n",
      "Epoch 4244/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5682 - val_loss: 196.6421\n",
      "Epoch 4245/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5366 - val_loss: 196.7697\n",
      "Epoch 4246/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6844 - val_loss: 193.8329\n",
      "Epoch 4247/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3971 - val_loss: 197.5862\n",
      "Epoch 4248/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5372 - val_loss: 194.3159\n",
      "Epoch 4249/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2876 - val_loss: 195.9986\n",
      "Epoch 4250/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5740 - val_loss: 194.9910\n",
      "Epoch 4251/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5496 - val_loss: 197.6368\n",
      "Epoch 4252/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6164 - val_loss: 194.1039\n",
      "Epoch 4253/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2728 - val_loss: 195.4105\n",
      "Epoch 4254/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4359 - val_loss: 193.9211\n",
      "Epoch 4255/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7281 - val_loss: 196.0166\n",
      "Epoch 4256/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2117 - val_loss: 194.2574\n",
      "Epoch 4257/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3454 - val_loss: 193.0066\n",
      "Epoch 4258/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5379 - val_loss: 192.5159\n",
      "Epoch 4259/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6923 - val_loss: 194.7462\n",
      "Epoch 4260/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4477 - val_loss: 194.5844\n",
      "Epoch 4261/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3836 - val_loss: 196.7522\n",
      "Epoch 4262/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3553 - val_loss: 196.0587\n",
      "Epoch 4263/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2280 - val_loss: 193.6613\n",
      "Epoch 4264/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6029 - val_loss: 193.6685\n",
      "Epoch 4265/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2345 - val_loss: 195.1554\n",
      "Epoch 4266/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7562 - val_loss: 194.9427\n",
      "Epoch 4267/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5474 - val_loss: 197.1065\n",
      "Epoch 4268/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4260 - val_loss: 194.8826\n",
      "Epoch 4269/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2547 - val_loss: 195.7603\n",
      "Epoch 4270/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6659 - val_loss: 197.6088\n",
      "Epoch 4271/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6100 - val_loss: 193.5256\n",
      "Epoch 4272/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3008 - val_loss: 192.6833\n",
      "Epoch 4273/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4853 - val_loss: 193.3076\n",
      "Epoch 4274/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4183 - val_loss: 196.1352\n",
      "Epoch 4275/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5426 - val_loss: 197.6585\n",
      "Epoch 4276/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5247 - val_loss: 193.7286\n",
      "Epoch 4277/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9926 - val_loss: 194.0252\n",
      "Epoch 4278/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3833 - val_loss: 194.4643\n",
      "Epoch 4279/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4669 - val_loss: 193.6209\n",
      "Epoch 4280/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7766 - val_loss: 197.5301\n",
      "Epoch 4281/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2772 - val_loss: 192.9559\n",
      "Epoch 4282/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6012 - val_loss: 192.1508\n",
      "Epoch 4283/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2570 - val_loss: 194.6055\n",
      "Epoch 4284/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3828 - val_loss: 196.0141\n",
      "Epoch 4285/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3596 - val_loss: 197.4268\n",
      "Epoch 4286/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3222 - val_loss: 195.3068\n",
      "Epoch 4287/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6747 - val_loss: 193.4778\n",
      "Epoch 4288/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5882 - val_loss: 196.3238\n",
      "Epoch 4289/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8792 - val_loss: 193.7467\n",
      "Epoch 4290/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0795 - val_loss: 190.2642\n",
      "Epoch 4291/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2974 - val_loss: 195.2016\n",
      "Epoch 4292/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8124 - val_loss: 196.9203\n",
      "Epoch 4293/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3629 - val_loss: 195.9913\n",
      "Epoch 4294/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3495 - val_loss: 194.3749\n",
      "Epoch 4295/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4492 - val_loss: 194.1263\n",
      "Epoch 4296/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3893 - val_loss: 197.3759\n",
      "Epoch 4297/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5198 - val_loss: 193.8746\n",
      "Epoch 4298/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5777 - val_loss: 195.6917\n",
      "Epoch 4299/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6038 - val_loss: 194.9774\n",
      "Epoch 4300/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4521 - val_loss: 194.9987\n",
      "Epoch 4301/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4902 - val_loss: 193.5460\n",
      "Epoch 4302/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4632 - val_loss: 194.1886\n",
      "Epoch 4303/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4532 - val_loss: 195.8307\n",
      "Epoch 4304/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5717 - val_loss: 192.9048\n",
      "Epoch 4305/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3696 - val_loss: 197.2063\n",
      "Epoch 4306/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3247 - val_loss: 195.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4307/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3491 - val_loss: 194.4365\n",
      "Epoch 4308/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4816 - val_loss: 195.6841\n",
      "Epoch 4309/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5334 - val_loss: 194.8840\n",
      "Epoch 4310/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5676 - val_loss: 194.3788\n",
      "Epoch 4311/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2582 - val_loss: 195.6255\n",
      "Epoch 4312/20000\n",
      "17948/17948 [==============================] - 1s 31us/sample - loss: 70.4643 - val_loss: 193.8674\n",
      "Epoch 4313/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5750 - val_loss: 194.6499\n",
      "Epoch 4314/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5636 - val_loss: 192.3054\n",
      "Epoch 4315/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4206 - val_loss: 195.9957\n",
      "Epoch 4316/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3602 - val_loss: 194.5801\n",
      "Epoch 4317/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5523 - val_loss: 195.0593\n",
      "Epoch 4318/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5185 - val_loss: 196.6559\n",
      "Epoch 4319/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6473 - val_loss: 197.5791\n",
      "Epoch 4320/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5436 - val_loss: 195.3716\n",
      "Epoch 4321/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6105 - val_loss: 195.7436\n",
      "Epoch 4322/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5459 - val_loss: 194.8533\n",
      "Epoch 4323/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.9041 - val_loss: 194.5213\n",
      "Epoch 4324/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7795 - val_loss: 194.2170\n",
      "Epoch 4325/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4757 - val_loss: 196.4660\n",
      "Epoch 4326/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5707 - val_loss: 193.7350\n",
      "Epoch 4327/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1665 - val_loss: 193.2470\n",
      "Epoch 4328/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1962 - val_loss: 195.9585\n",
      "Epoch 4329/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5865 - val_loss: 198.0261\n",
      "Epoch 4330/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1292 - val_loss: 194.2242\n",
      "Epoch 4331/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7442 - val_loss: 197.5040\n",
      "Epoch 4332/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4128 - val_loss: 197.3556\n",
      "Epoch 4333/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5542 - val_loss: 197.1323\n",
      "Epoch 4334/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4550 - val_loss: 196.2293\n",
      "Epoch 4335/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5610 - val_loss: 194.7580\n",
      "Epoch 4336/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4381 - val_loss: 195.7051\n",
      "Epoch 4337/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3571 - val_loss: 193.2156\n",
      "Epoch 4338/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7668 - val_loss: 192.9930\n",
      "Epoch 4339/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4914 - val_loss: 193.0071\n",
      "Epoch 4340/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8967 - val_loss: 196.6284\n",
      "Epoch 4341/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3941 - val_loss: 195.6471\n",
      "Epoch 4342/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5933 - val_loss: 196.2575\n",
      "Epoch 4343/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5792 - val_loss: 196.5933\n",
      "Epoch 4344/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4240 - val_loss: 195.6858\n",
      "Epoch 4345/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6202 - val_loss: 196.1085\n",
      "Epoch 4346/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6538 - val_loss: 195.5400\n",
      "Epoch 4347/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6437 - val_loss: 196.1305\n",
      "Epoch 4348/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8376 - val_loss: 193.8781\n",
      "Epoch 4349/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2997 - val_loss: 195.1965\n",
      "Epoch 4350/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5575 - val_loss: 199.2740\n",
      "Epoch 4351/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1273 - val_loss: 194.1393\n",
      "Epoch 4352/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6368 - val_loss: 194.6518\n",
      "Epoch 4353/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3888 - val_loss: 195.0366\n",
      "Epoch 4354/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5861 - val_loss: 194.1999\n",
      "Epoch 4355/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7018 - val_loss: 197.0590\n",
      "Epoch 4356/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4887 - val_loss: 195.5766\n",
      "Epoch 4357/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2522 - val_loss: 197.3729\n",
      "Epoch 4358/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4602 - val_loss: 193.6332\n",
      "Epoch 4359/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5738 - val_loss: 196.4931\n",
      "Epoch 4360/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5177 - val_loss: 194.3244\n",
      "Epoch 4361/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7094 - val_loss: 195.5567\n",
      "Epoch 4362/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5760 - val_loss: 194.6341\n",
      "Epoch 4363/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2679 - val_loss: 196.9229\n",
      "Epoch 4364/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.0498 - val_loss: 197.3814\n",
      "Epoch 4365/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6721 - val_loss: 194.9541\n",
      "Epoch 4366/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4449 - val_loss: 194.0868\n",
      "Epoch 4367/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3974 - val_loss: 193.2234\n",
      "Epoch 4368/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3059 - val_loss: 197.8397\n",
      "Epoch 4369/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5360 - val_loss: 196.5356\n",
      "Epoch 4370/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4828 - val_loss: 193.8876\n",
      "Epoch 4371/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4500 - val_loss: 195.9974\n",
      "Epoch 4372/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6835 - val_loss: 196.0136\n",
      "Epoch 4373/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4909 - val_loss: 193.3529\n",
      "Epoch 4374/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4771 - val_loss: 193.9754\n",
      "Epoch 4375/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5368 - val_loss: 195.7643\n",
      "Epoch 4376/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3563 - val_loss: 193.9320\n",
      "Epoch 4377/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3171 - val_loss: 195.5784\n",
      "Epoch 4378/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5205 - val_loss: 195.1349\n",
      "Epoch 4379/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5026 - val_loss: 193.4635\n",
      "Epoch 4380/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5773 - val_loss: 193.6507\n",
      "Epoch 4381/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4294 - val_loss: 197.0388\n",
      "Epoch 4382/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5472 - val_loss: 197.3930\n",
      "Epoch 4383/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6683 - val_loss: 192.6362\n",
      "Epoch 4384/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4233 - val_loss: 198.7411\n",
      "Epoch 4385/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6904 - val_loss: 194.5994\n",
      "Epoch 4386/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4565 - val_loss: 194.8771\n",
      "Epoch 4387/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4182 - val_loss: 199.0148\n",
      "Epoch 4388/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5990 - val_loss: 199.5728\n",
      "Epoch 4389/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7412 - val_loss: 193.3355\n",
      "Epoch 4390/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7100 - val_loss: 192.7116\n",
      "Epoch 4391/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6111 - val_loss: 194.1358\n",
      "Epoch 4392/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5053 - val_loss: 195.7881\n",
      "Epoch 4393/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4620 - val_loss: 193.9415\n",
      "Epoch 4394/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5372 - val_loss: 195.2042\n",
      "Epoch 4395/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4441 - val_loss: 195.0322\n",
      "Epoch 4396/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4415 - val_loss: 196.6534\n",
      "Epoch 4397/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7553 - val_loss: 195.4471\n",
      "Epoch 4398/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3334 - val_loss: 191.4489\n",
      "Epoch 4399/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5916 - val_loss: 194.2979\n",
      "Epoch 4400/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7495 - val_loss: 195.8098\n",
      "Epoch 4401/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3916 - val_loss: 194.2386\n",
      "Epoch 4402/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2894 - val_loss: 196.8516\n",
      "Epoch 4403/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7801 - val_loss: 196.3227\n",
      "Epoch 4404/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6827 - val_loss: 195.2565\n",
      "Epoch 4405/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3924 - val_loss: 196.8942\n",
      "Epoch 4406/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5075 - val_loss: 197.6284\n",
      "Epoch 4407/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4759 - val_loss: 198.0264\n",
      "Epoch 4408/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2185 - val_loss: 194.0376\n",
      "Epoch 4409/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4564 - val_loss: 195.5779\n",
      "Epoch 4410/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4584 - val_loss: 194.3101\n",
      "Epoch 4411/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5456 - val_loss: 193.6213\n",
      "Epoch 4412/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6059 - val_loss: 192.0247\n",
      "Epoch 4413/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3323 - val_loss: 196.2526\n",
      "Epoch 4414/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3764 - val_loss: 195.9699\n",
      "Epoch 4415/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5027 - val_loss: 193.8125\n",
      "Epoch 4416/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4113 - val_loss: 195.2739\n",
      "Epoch 4417/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3526 - val_loss: 197.1413\n",
      "Epoch 4418/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7065 - val_loss: 195.1185\n",
      "Epoch 4419/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3409 - val_loss: 195.6404\n",
      "Epoch 4420/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5266 - val_loss: 195.4877\n",
      "Epoch 4421/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6788 - val_loss: 196.2976\n",
      "Epoch 4422/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2127 - val_loss: 193.5188\n",
      "Epoch 4423/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3937 - val_loss: 193.9376\n",
      "Epoch 4424/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6643 - val_loss: 194.7264\n",
      "Epoch 4425/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5199 - val_loss: 194.5576\n",
      "Epoch 4426/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3641 - val_loss: 194.4465\n",
      "Epoch 4427/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6202 - val_loss: 197.0760\n",
      "Epoch 4428/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2988 - val_loss: 192.8834\n",
      "Epoch 4429/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1411 - val_loss: 194.3129\n",
      "Epoch 4430/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5345 - val_loss: 195.5214\n",
      "Epoch 4431/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6254 - val_loss: 196.3614\n",
      "Epoch 4432/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4353 - val_loss: 194.1265\n",
      "Epoch 4433/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5822 - val_loss: 194.8436\n",
      "Epoch 4434/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7199 - val_loss: 196.3428\n",
      "Epoch 4435/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2789 - val_loss: 194.1186\n",
      "Epoch 4436/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4262 - val_loss: 195.6764\n",
      "Epoch 4437/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4838 - val_loss: 194.4994\n",
      "Epoch 4438/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4667 - val_loss: 196.4415\n",
      "Epoch 4439/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.2043 - val_loss: 190.7510\n",
      "Epoch 4440/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5909 - val_loss: 195.3112\n",
      "Epoch 4441/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3810 - val_loss: 194.6661\n",
      "Epoch 4442/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4642 - val_loss: 197.1669\n",
      "Epoch 4443/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7291 - val_loss: 193.9243\n",
      "Epoch 4444/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2801 - val_loss: 195.3053\n",
      "Epoch 4445/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8090 - val_loss: 195.1608\n",
      "Epoch 4446/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4904 - val_loss: 194.8749\n",
      "Epoch 4447/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7076 - val_loss: 194.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4448/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5094 - val_loss: 195.4017\n",
      "Epoch 4449/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5886 - val_loss: 196.9694\n",
      "Epoch 4450/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5406 - val_loss: 195.5699\n",
      "Epoch 4451/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6620 - val_loss: 196.9020\n",
      "Epoch 4452/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7384 - val_loss: 193.3068\n",
      "Epoch 4453/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3518 - val_loss: 193.0810\n",
      "Epoch 4454/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4049 - val_loss: 196.7172\n",
      "Epoch 4455/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6077 - val_loss: 195.8990\n",
      "Epoch 4456/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3122 - val_loss: 195.6013\n",
      "Epoch 4457/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4262 - val_loss: 195.8301\n",
      "Epoch 4458/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3803 - val_loss: 194.3367\n",
      "Epoch 4459/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3717 - val_loss: 198.6662\n",
      "Epoch 4460/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3733 - val_loss: 201.0821\n",
      "Epoch 4461/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3758 - val_loss: 192.7856\n",
      "Epoch 4462/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5537 - val_loss: 195.1454\n",
      "Epoch 4463/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0551 - val_loss: 192.9028\n",
      "Epoch 4464/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6866 - val_loss: 192.2286\n",
      "Epoch 4465/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5707 - val_loss: 192.4571\n",
      "Epoch 4466/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4606 - val_loss: 195.3107\n",
      "Epoch 4467/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2914 - val_loss: 200.6562\n",
      "Epoch 4468/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4678 - val_loss: 197.4742\n",
      "Epoch 4469/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2607 - val_loss: 192.2436\n",
      "Epoch 4470/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7610 - val_loss: 192.7037\n",
      "Epoch 4471/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6496 - val_loss: 195.5844\n",
      "Epoch 4472/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4825 - val_loss: 193.3477\n",
      "Epoch 4473/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6791 - val_loss: 196.2217\n",
      "Epoch 4474/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5208 - val_loss: 193.8262\n",
      "Epoch 4475/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3586 - val_loss: 193.8682\n",
      "Epoch 4476/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3192 - val_loss: 194.7067\n",
      "Epoch 4477/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2907 - val_loss: 194.2112\n",
      "Epoch 4478/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4092 - val_loss: 193.7949\n",
      "Epoch 4479/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6405 - val_loss: 196.7195\n",
      "Epoch 4480/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7849 - val_loss: 195.4257\n",
      "Epoch 4481/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3318 - val_loss: 194.1224\n",
      "Epoch 4482/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5002 - val_loss: 192.1261\n",
      "Epoch 4483/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3159 - val_loss: 196.7345\n",
      "Epoch 4484/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3931 - val_loss: 195.4068\n",
      "Epoch 4485/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4095 - val_loss: 197.4920\n",
      "Epoch 4486/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3796 - val_loss: 196.7078\n",
      "Epoch 4487/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5848 - val_loss: 194.3219\n",
      "Epoch 4488/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4349 - val_loss: 196.9298\n",
      "Epoch 4489/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7671 - val_loss: 194.9289\n",
      "Epoch 4490/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4268 - val_loss: 196.3689\n",
      "Epoch 4491/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3894 - val_loss: 196.5629\n",
      "Epoch 4492/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7494 - val_loss: 196.1164\n",
      "Epoch 4493/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7071 - val_loss: 190.9287\n",
      "Epoch 4494/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5219 - val_loss: 194.9319\n",
      "Epoch 4495/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4239 - val_loss: 193.8569\n",
      "Epoch 4496/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5572 - val_loss: 195.5007\n",
      "Epoch 4497/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4486 - val_loss: 194.8037\n",
      "Epoch 4498/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3957 - val_loss: 196.8629\n",
      "Epoch 4499/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5417 - val_loss: 195.3950\n",
      "Epoch 4500/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3677 - val_loss: 195.5727\n",
      "Epoch 4501/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6336 - val_loss: 195.7508\n",
      "Epoch 4502/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7126 - val_loss: 195.6811\n",
      "Epoch 4503/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4302 - val_loss: 198.2798\n",
      "Epoch 4504/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7330 - val_loss: 192.5142\n",
      "Epoch 4505/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5609 - val_loss: 195.6428\n",
      "Epoch 4506/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7126 - val_loss: 192.9642\n",
      "Epoch 4507/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3644 - val_loss: 195.5794\n",
      "Epoch 4508/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5322 - val_loss: 192.1527\n",
      "Epoch 4509/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3592 - val_loss: 193.5631\n",
      "Epoch 4510/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3794 - val_loss: 191.9071\n",
      "Epoch 4511/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4989 - val_loss: 195.3599\n",
      "Epoch 4512/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6271 - val_loss: 193.7079\n",
      "Epoch 4513/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3616 - val_loss: 197.3310\n",
      "Epoch 4514/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1891 - val_loss: 195.3239\n",
      "Epoch 4515/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5500 - val_loss: 199.4679\n",
      "Epoch 4516/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4861 - val_loss: 195.9411\n",
      "Epoch 4517/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4804 - val_loss: 194.6779\n",
      "Epoch 4518/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7981 - val_loss: 195.6396\n",
      "Epoch 4519/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7239 - val_loss: 194.5375\n",
      "Epoch 4520/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5884 - val_loss: 196.6024\n",
      "Epoch 4521/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5962 - val_loss: 194.5750\n",
      "Epoch 4522/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6727 - val_loss: 193.9119\n",
      "Epoch 4523/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5483 - val_loss: 194.3773\n",
      "Epoch 4524/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2995 - val_loss: 196.5440\n",
      "Epoch 4525/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5098 - val_loss: 192.5412\n",
      "Epoch 4526/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5829 - val_loss: 195.0425\n",
      "Epoch 4527/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7278 - val_loss: 196.2296\n",
      "Epoch 4528/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5339 - val_loss: 197.4612\n",
      "Epoch 4529/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5813 - val_loss: 192.5293\n",
      "Epoch 4530/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3018 - val_loss: 195.5077\n",
      "Epoch 4531/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6661 - val_loss: 194.4906\n",
      "Epoch 4532/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1806 - val_loss: 195.1956\n",
      "Epoch 4533/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7319 - val_loss: 193.9869\n",
      "Epoch 4534/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6365 - val_loss: 196.7146\n",
      "Epoch 4535/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4504 - val_loss: 194.5495\n",
      "Epoch 4536/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7217 - val_loss: 195.9751\n",
      "Epoch 4537/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5165 - val_loss: 194.0259\n",
      "Epoch 4538/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4176 - val_loss: 195.0769\n",
      "Epoch 4539/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7087 - val_loss: 192.5173\n",
      "Epoch 4540/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4204 - val_loss: 193.5805\n",
      "Epoch 4541/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6019 - val_loss: 194.6319\n",
      "Epoch 4542/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8064 - val_loss: 194.2459\n",
      "Epoch 4543/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6105 - val_loss: 194.7477\n",
      "Epoch 4544/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4557 - val_loss: 192.6365\n",
      "Epoch 4545/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5700 - val_loss: 197.3881\n",
      "Epoch 4546/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3461 - val_loss: 195.9833\n",
      "Epoch 4547/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3576 - val_loss: 194.2216\n",
      "Epoch 4548/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4825 - val_loss: 193.5075\n",
      "Epoch 4549/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5686 - val_loss: 195.4140\n",
      "Epoch 4550/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4284 - val_loss: 192.8173\n",
      "Epoch 4551/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4898 - val_loss: 197.6628\n",
      "Epoch 4552/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5406 - val_loss: 194.8403\n",
      "Epoch 4553/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5765 - val_loss: 193.9605\n",
      "Epoch 4554/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2929 - val_loss: 195.1476\n",
      "Epoch 4555/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5891 - val_loss: 195.5844\n",
      "Epoch 4556/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4707 - val_loss: 195.2491\n",
      "Epoch 4557/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6192 - val_loss: 197.5986\n",
      "Epoch 4558/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3012 - val_loss: 194.5924\n",
      "Epoch 4559/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2412 - val_loss: 196.5277\n",
      "Epoch 4560/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6213 - val_loss: 197.4576\n",
      "Epoch 4561/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4292 - val_loss: 194.2928\n",
      "Epoch 4562/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6588 - val_loss: 195.4334\n",
      "Epoch 4563/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3213 - val_loss: 194.0028\n",
      "Epoch 4564/20000\n",
      "17948/17948 [==============================] - 1s 39us/sample - loss: 70.7052 - val_loss: 194.9152\n",
      "Epoch 4565/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.4467 - val_loss: 194.8922\n",
      "Epoch 4566/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8229 - val_loss: 193.9916\n",
      "Epoch 4567/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5421 - val_loss: 193.9742\n",
      "Epoch 4568/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4889 - val_loss: 194.5664\n",
      "Epoch 4569/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5812 - val_loss: 199.1576\n",
      "Epoch 4570/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4771 - val_loss: 196.9034\n",
      "Epoch 4571/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3782 - val_loss: 194.0198\n",
      "Epoch 4572/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3747 - val_loss: 195.6325\n",
      "Epoch 4573/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6799 - val_loss: 194.6628\n",
      "Epoch 4574/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4984 - val_loss: 196.7984\n",
      "Epoch 4575/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6823 - val_loss: 192.7347\n",
      "Epoch 4576/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6293 - val_loss: 194.6021\n",
      "Epoch 4577/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6612 - val_loss: 195.6117\n",
      "Epoch 4578/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2351 - val_loss: 193.6471\n",
      "Epoch 4579/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3212 - val_loss: 197.4293\n",
      "Epoch 4580/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5644 - val_loss: 193.7892\n",
      "Epoch 4581/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.1435 - val_loss: 193.4588\n",
      "Epoch 4582/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6046 - val_loss: 195.5234\n",
      "Epoch 4583/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6116 - val_loss: 195.7503\n",
      "Epoch 4584/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2251 - val_loss: 196.2352\n",
      "Epoch 4585/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4951 - val_loss: 195.0728\n",
      "Epoch 4586/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7665 - val_loss: 194.8743\n",
      "Epoch 4587/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4105 - val_loss: 199.8498\n",
      "Epoch 4588/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6877 - val_loss: 194.8177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4589/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4580 - val_loss: 197.8979\n",
      "Epoch 4590/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4362 - val_loss: 196.6593\n",
      "Epoch 4591/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5042 - val_loss: 196.1993\n",
      "Epoch 4592/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5092 - val_loss: 195.3847\n",
      "Epoch 4593/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3431 - val_loss: 193.1024\n",
      "Epoch 4594/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5557 - val_loss: 197.3409\n",
      "Epoch 4595/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5057 - val_loss: 192.3114\n",
      "Epoch 4596/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4351 - val_loss: 191.6258\n",
      "Epoch 4597/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6862 - val_loss: 197.2798\n",
      "Epoch 4598/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3836 - val_loss: 196.5256\n",
      "Epoch 4599/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4026 - val_loss: 192.4859\n",
      "Epoch 4600/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5473 - val_loss: 195.4215\n",
      "Epoch 4601/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4939 - val_loss: 196.6647\n",
      "Epoch 4602/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5947 - val_loss: 194.6322\n",
      "Epoch 4603/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3482 - val_loss: 196.0324\n",
      "Epoch 4604/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3449 - val_loss: 197.0734\n",
      "Epoch 4605/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4525 - val_loss: 194.3794\n",
      "Epoch 4606/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2453 - val_loss: 197.8833\n",
      "Epoch 4607/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9279 - val_loss: 198.6544\n",
      "Epoch 4608/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7073 - val_loss: 195.9043\n",
      "Epoch 4609/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6623 - val_loss: 197.1053\n",
      "Epoch 4610/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2453 - val_loss: 198.2045\n",
      "Epoch 4611/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4583 - val_loss: 194.9393\n",
      "Epoch 4612/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4751 - val_loss: 195.1689\n",
      "Epoch 4613/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2740 - val_loss: 194.7706\n",
      "Epoch 4614/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5662 - val_loss: 192.4952\n",
      "Epoch 4615/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5117 - val_loss: 195.1194\n",
      "Epoch 4616/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6062 - val_loss: 197.4998\n",
      "Epoch 4617/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4147 - val_loss: 194.0663\n",
      "Epoch 4618/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5066 - val_loss: 194.8070\n",
      "Epoch 4619/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2949 - val_loss: 195.3123\n",
      "Epoch 4620/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5749 - val_loss: 195.4263\n",
      "Epoch 4621/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2230 - val_loss: 196.0135\n",
      "Epoch 4622/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5101 - val_loss: 194.4566\n",
      "Epoch 4623/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4576 - val_loss: 196.4283\n",
      "Epoch 4624/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4877 - val_loss: 195.6586\n",
      "Epoch 4625/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5016 - val_loss: 195.4726\n",
      "Epoch 4626/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4102 - val_loss: 194.5585\n",
      "Epoch 4627/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7423 - val_loss: 194.7011\n",
      "Epoch 4628/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5761 - val_loss: 195.5815\n",
      "Epoch 4629/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7612 - val_loss: 191.8695\n",
      "Epoch 4630/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6873 - val_loss: 196.0796\n",
      "Epoch 4631/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3663 - val_loss: 194.8427\n",
      "Epoch 4632/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5349 - val_loss: 194.9288\n",
      "Epoch 4633/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4791 - val_loss: 196.0654\n",
      "Epoch 4634/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4044 - val_loss: 195.6328\n",
      "Epoch 4635/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5471 - val_loss: 192.5331\n",
      "Epoch 4636/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6610 - val_loss: 195.3407\n",
      "Epoch 4637/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4803 - val_loss: 195.5949\n",
      "Epoch 4638/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5398 - val_loss: 195.3507\n",
      "Epoch 4639/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7283 - val_loss: 194.2318\n",
      "Epoch 4640/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8934 - val_loss: 193.5932\n",
      "Epoch 4641/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5382 - val_loss: 196.1080\n",
      "Epoch 4642/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5375 - val_loss: 197.6022\n",
      "Epoch 4643/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4978 - val_loss: 197.0466\n",
      "Epoch 4644/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4518 - val_loss: 194.7428\n",
      "Epoch 4645/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6217 - val_loss: 196.4571\n",
      "Epoch 4646/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4314 - val_loss: 194.2791\n",
      "Epoch 4647/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3139 - val_loss: 196.9502\n",
      "Epoch 4648/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5942 - val_loss: 195.5949\n",
      "Epoch 4649/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2706 - val_loss: 196.2107\n",
      "Epoch 4650/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4242 - val_loss: 197.2309\n",
      "Epoch 4651/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3856 - val_loss: 198.6159\n",
      "Epoch 4652/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5316 - val_loss: 195.8794\n",
      "Epoch 4653/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3332 - val_loss: 192.5422\n",
      "Epoch 4654/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4286 - val_loss: 194.1115\n",
      "Epoch 4655/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4974 - val_loss: 193.7710\n",
      "Epoch 4656/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4644 - val_loss: 195.0480\n",
      "Epoch 4657/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3996 - val_loss: 195.1262\n",
      "Epoch 4658/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1412 - val_loss: 195.1679\n",
      "Epoch 4659/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7558 - val_loss: 196.2481\n",
      "Epoch 4660/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7045 - val_loss: 195.2961\n",
      "Epoch 4661/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5828 - val_loss: 194.7883\n",
      "Epoch 4662/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3839 - val_loss: 197.2670\n",
      "Epoch 4663/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4898 - val_loss: 195.8740\n",
      "Epoch 4664/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6035 - val_loss: 195.8965\n",
      "Epoch 4665/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5666 - val_loss: 194.0446\n",
      "Epoch 4666/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3866 - val_loss: 194.7593\n",
      "Epoch 4667/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1081 - val_loss: 196.9832\n",
      "Epoch 4668/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7405 - val_loss: 196.2009\n",
      "Epoch 4669/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3566 - val_loss: 190.9287\n",
      "Epoch 4670/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5025 - val_loss: 196.2882\n",
      "Epoch 4671/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5476 - val_loss: 197.5963\n",
      "Epoch 4672/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5261 - val_loss: 197.4308\n",
      "Epoch 4673/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5964 - val_loss: 196.7599\n",
      "Epoch 4674/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4584 - val_loss: 194.8143\n",
      "Epoch 4675/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5108 - val_loss: 197.0839\n",
      "Epoch 4676/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4057 - val_loss: 195.9502\n",
      "Epoch 4677/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2527 - val_loss: 199.1200\n",
      "Epoch 4678/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4874 - val_loss: 194.6020\n",
      "Epoch 4679/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4028 - val_loss: 194.5040\n",
      "Epoch 4680/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7349 - val_loss: 195.8517\n",
      "Epoch 4681/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5300 - val_loss: 194.7876\n",
      "Epoch 4682/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3750 - val_loss: 193.7667\n",
      "Epoch 4683/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4458 - val_loss: 195.2802\n",
      "Epoch 4684/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5523 - val_loss: 196.9838\n",
      "Epoch 4685/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6619 - val_loss: 195.2437\n",
      "Epoch 4686/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7174 - val_loss: 192.6717\n",
      "Epoch 4687/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7555 - val_loss: 192.6996\n",
      "Epoch 4688/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6727 - val_loss: 195.6733\n",
      "Epoch 4689/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4167 - val_loss: 194.6267\n",
      "Epoch 4690/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5164 - val_loss: 197.5347\n",
      "Epoch 4691/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3184 - val_loss: 196.1055\n",
      "Epoch 4692/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4298 - val_loss: 195.4554\n",
      "Epoch 4693/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1689 - val_loss: 198.2535\n",
      "Epoch 4694/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3572 - val_loss: 195.8607\n",
      "Epoch 4695/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3251 - val_loss: 195.1662\n",
      "Epoch 4696/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2377 - val_loss: 196.9997\n",
      "Epoch 4697/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3565 - val_loss: 193.9196\n",
      "Epoch 4698/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3375 - val_loss: 193.1306\n",
      "Epoch 4699/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3893 - val_loss: 193.4176\n",
      "Epoch 4700/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4580 - val_loss: 192.7349\n",
      "Epoch 4701/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4936 - val_loss: 194.5193\n",
      "Epoch 4702/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4143 - val_loss: 196.0901\n",
      "Epoch 4703/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8114 - val_loss: 197.9663\n",
      "Epoch 4704/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5853 - val_loss: 194.1218\n",
      "Epoch 4705/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3450 - val_loss: 197.2859\n",
      "Epoch 4706/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4283 - val_loss: 196.8800\n",
      "Epoch 4707/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4835 - val_loss: 192.4009\n",
      "Epoch 4708/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3070 - val_loss: 196.5365\n",
      "Epoch 4709/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4967 - val_loss: 197.2103\n",
      "Epoch 4710/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4245 - val_loss: 193.4369\n",
      "Epoch 4711/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7137 - val_loss: 193.1821\n",
      "Epoch 4712/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2719 - val_loss: 194.2509\n",
      "Epoch 4713/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5950 - val_loss: 197.2854\n",
      "Epoch 4714/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6200 - val_loss: 195.3402\n",
      "Epoch 4715/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4018 - val_loss: 194.4766\n",
      "Epoch 4716/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3335 - val_loss: 194.2500\n",
      "Epoch 4717/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3216 - val_loss: 198.7594\n",
      "Epoch 4718/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6239 - val_loss: 195.7690\n",
      "Epoch 4719/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5173 - val_loss: 193.6860\n",
      "Epoch 4720/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2582 - val_loss: 194.4497\n",
      "Epoch 4721/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4826 - val_loss: 193.4736\n",
      "Epoch 4722/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4487 - val_loss: 197.5838\n",
      "Epoch 4723/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3687 - val_loss: 191.4442\n",
      "Epoch 4724/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5955 - val_loss: 195.6690\n",
      "Epoch 4725/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5189 - val_loss: 197.1223\n",
      "Epoch 4726/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1478 - val_loss: 194.9006\n",
      "Epoch 4727/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3116 - val_loss: 194.2619\n",
      "Epoch 4728/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3836 - val_loss: 198.0842\n",
      "Epoch 4729/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6094 - val_loss: 196.9819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4730/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5951 - val_loss: 196.1676\n",
      "Epoch 4731/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6829 - val_loss: 195.6070\n",
      "Epoch 4732/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2435 - val_loss: 193.7611\n",
      "Epoch 4733/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3444 - val_loss: 197.2803\n",
      "Epoch 4734/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4996 - val_loss: 195.3863\n",
      "Epoch 4735/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6725 - val_loss: 195.7649\n",
      "Epoch 4736/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6275 - val_loss: 195.8878\n",
      "Epoch 4737/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1185 - val_loss: 197.1071\n",
      "Epoch 4738/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5377 - val_loss: 191.3449\n",
      "Epoch 4739/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4489 - val_loss: 194.2051\n",
      "Epoch 4740/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4633 - val_loss: 195.0229\n",
      "Epoch 4741/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5542 - val_loss: 195.8708\n",
      "Epoch 4742/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5483 - val_loss: 191.9267\n",
      "Epoch 4743/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3453 - val_loss: 195.3206\n",
      "Epoch 4744/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6244 - val_loss: 194.5963\n",
      "Epoch 4745/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6753 - val_loss: 193.1209\n",
      "Epoch 4746/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3704 - val_loss: 197.9215\n",
      "Epoch 4747/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3233 - val_loss: 195.6820\n",
      "Epoch 4748/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2929 - val_loss: 196.2396\n",
      "Epoch 4749/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5776 - val_loss: 196.5719\n",
      "Epoch 4750/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4283 - val_loss: 196.2136\n",
      "Epoch 4751/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8266 - val_loss: 192.2115\n",
      "Epoch 4752/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4411 - val_loss: 196.1973\n",
      "Epoch 4753/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2541 - val_loss: 196.2566\n",
      "Epoch 4754/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2306 - val_loss: 195.0535\n",
      "Epoch 4755/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7643 - val_loss: 195.8413\n",
      "Epoch 4756/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6185 - val_loss: 191.9003\n",
      "Epoch 4757/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3980 - val_loss: 198.7660\n",
      "Epoch 4758/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5003 - val_loss: 195.0591\n",
      "Epoch 4759/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4867 - val_loss: 195.1665\n",
      "Epoch 4760/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6436 - val_loss: 196.7555\n",
      "Epoch 4761/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2141 - val_loss: 193.8792\n",
      "Epoch 4762/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4177 - val_loss: 195.0963\n",
      "Epoch 4763/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3044 - val_loss: 195.9628\n",
      "Epoch 4764/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5773 - val_loss: 193.6618\n",
      "Epoch 4765/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2661 - val_loss: 194.5985\n",
      "Epoch 4766/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4184 - val_loss: 194.2615\n",
      "Epoch 4767/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4893 - val_loss: 195.5486\n",
      "Epoch 4768/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4631 - val_loss: 195.6551\n",
      "Epoch 4769/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5804 - val_loss: 193.6574\n",
      "Epoch 4770/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4718 - val_loss: 194.5675\n",
      "Epoch 4771/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6023 - val_loss: 193.4691\n",
      "Epoch 4772/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4349 - val_loss: 193.0848\n",
      "Epoch 4773/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5265 - val_loss: 197.0396\n",
      "Epoch 4774/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1748 - val_loss: 192.7249\n",
      "Epoch 4775/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4200 - val_loss: 192.8321\n",
      "Epoch 4776/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3753 - val_loss: 195.7527\n",
      "Epoch 4777/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2228 - val_loss: 194.5195\n",
      "Epoch 4778/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4010 - val_loss: 194.8180\n",
      "Epoch 4779/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4765 - val_loss: 193.8621\n",
      "Epoch 4780/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7997 - val_loss: 188.0412\n",
      "Epoch 4781/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9198 - val_loss: 191.9744\n",
      "Epoch 4782/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3932 - val_loss: 197.1264\n",
      "Epoch 4783/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2081 - val_loss: 195.8113\n",
      "Epoch 4784/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5065 - val_loss: 198.0820\n",
      "Epoch 4785/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4412 - val_loss: 194.5378\n",
      "Epoch 4786/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4170 - val_loss: 194.8195\n",
      "Epoch 4787/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6329 - val_loss: 194.7646\n",
      "Epoch 4788/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2927 - val_loss: 195.2224\n",
      "Epoch 4789/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3778 - val_loss: 194.8617\n",
      "Epoch 4790/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2449 - val_loss: 194.9055\n",
      "Epoch 4791/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3440 - val_loss: 196.4838\n",
      "Epoch 4792/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4083 - val_loss: 193.4359\n",
      "Epoch 4793/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4596 - val_loss: 195.6847\n",
      "Epoch 4794/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2867 - val_loss: 196.7336\n",
      "Epoch 4795/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5945 - val_loss: 197.1248\n",
      "Epoch 4796/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7928 - val_loss: 196.2792\n",
      "Epoch 4797/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6977 - val_loss: 193.7347\n",
      "Epoch 4798/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2297 - val_loss: 194.5059\n",
      "Epoch 4799/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5912 - val_loss: 195.6074\n",
      "Epoch 4800/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3662 - val_loss: 197.5188\n",
      "Epoch 4801/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4555 - val_loss: 196.4617\n",
      "Epoch 4802/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4978 - val_loss: 196.9110\n",
      "Epoch 4803/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5043 - val_loss: 198.6266\n",
      "Epoch 4804/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8264 - val_loss: 194.6663\n",
      "Epoch 4805/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2948 - val_loss: 194.2250\n",
      "Epoch 4806/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4731 - val_loss: 193.0585\n",
      "Epoch 4807/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4535 - val_loss: 193.6659\n",
      "Epoch 4808/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4506 - val_loss: 195.1961\n",
      "Epoch 4809/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3311 - val_loss: 193.2774\n",
      "Epoch 4810/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5747 - val_loss: 197.6660\n",
      "Epoch 4811/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6548 - val_loss: 195.1376\n",
      "Epoch 4812/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6178 - val_loss: 193.5607\n",
      "Epoch 4813/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3287 - val_loss: 195.3345\n",
      "Epoch 4814/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4069 - val_loss: 196.1688\n",
      "Epoch 4815/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4317 - val_loss: 194.1625\n",
      "Epoch 4816/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4387 - val_loss: 193.2154\n",
      "Epoch 4817/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5871 - val_loss: 194.5517\n",
      "Epoch 4818/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6079 - val_loss: 195.3432\n",
      "Epoch 4819/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6466 - val_loss: 197.8443\n",
      "Epoch 4820/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1653 - val_loss: 195.0723\n",
      "Epoch 4821/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4654 - val_loss: 195.8648\n",
      "Epoch 4822/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6229 - val_loss: 195.5186\n",
      "Epoch 4823/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5228 - val_loss: 195.5567\n",
      "Epoch 4824/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5573 - val_loss: 197.6487\n",
      "Epoch 4825/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2870 - val_loss: 193.2720\n",
      "Epoch 4826/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5112 - val_loss: 197.3441\n",
      "Epoch 4827/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1854 - val_loss: 194.0221\n",
      "Epoch 4828/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6538 - val_loss: 194.0181\n",
      "Epoch 4829/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4256 - val_loss: 196.0663\n",
      "Epoch 4830/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4401 - val_loss: 196.0970\n",
      "Epoch 4831/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2938 - val_loss: 194.8692\n",
      "Epoch 4832/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3867 - val_loss: 195.2174\n",
      "Epoch 4833/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5462 - val_loss: 195.4359\n",
      "Epoch 4834/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2005 - val_loss: 193.6104\n",
      "Epoch 4835/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4737 - val_loss: 195.7863\n",
      "Epoch 4836/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2282 - val_loss: 195.6991\n",
      "Epoch 4837/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4131 - val_loss: 194.8970\n",
      "Epoch 4838/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7195 - val_loss: 193.4114\n",
      "Epoch 4839/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5251 - val_loss: 195.7246\n",
      "Epoch 4840/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2411 - val_loss: 192.2709\n",
      "Epoch 4841/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5932 - val_loss: 194.8935\n",
      "Epoch 4842/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2382 - val_loss: 193.5742\n",
      "Epoch 4843/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3598 - val_loss: 194.2117\n",
      "Epoch 4844/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3421 - val_loss: 196.3955\n",
      "Epoch 4845/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2967 - val_loss: 195.0350\n",
      "Epoch 4846/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1573 - val_loss: 195.2332\n",
      "Epoch 4847/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2581 - val_loss: 194.6140\n",
      "Epoch 4848/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.2906 - val_loss: 194.8238\n",
      "Epoch 4849/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4138 - val_loss: 192.7182\n",
      "Epoch 4850/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3260 - val_loss: 195.5719\n",
      "Epoch 4851/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5161 - val_loss: 196.2205\n",
      "Epoch 4852/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6533 - val_loss: 195.6924\n",
      "Epoch 4853/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4377 - val_loss: 194.7785\n",
      "Epoch 4854/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7166 - val_loss: 196.3126\n",
      "Epoch 4855/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6213 - val_loss: 197.6454\n",
      "Epoch 4856/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5516 - val_loss: 193.6299\n",
      "Epoch 4857/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4565 - val_loss: 196.1222\n",
      "Epoch 4858/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5132 - val_loss: 195.8570\n",
      "Epoch 4859/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2635 - val_loss: 195.4747\n",
      "Epoch 4860/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5610 - val_loss: 195.5686\n",
      "Epoch 4861/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3692 - val_loss: 194.8306\n",
      "Epoch 4862/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3007 - val_loss: 194.7966\n",
      "Epoch 4863/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2241 - val_loss: 195.1176\n",
      "Epoch 4864/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4608 - val_loss: 194.3247\n",
      "Epoch 4865/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5668 - val_loss: 195.4365\n",
      "Epoch 4866/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2240 - val_loss: 193.9114\n",
      "Epoch 4867/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3160 - val_loss: 195.6793\n",
      "Epoch 4868/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3140 - val_loss: 193.0592\n",
      "Epoch 4869/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2859 - val_loss: 191.9380\n",
      "Epoch 4870/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6370 - val_loss: 194.6720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4871/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1844 - val_loss: 193.3580\n",
      "Epoch 4872/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6225 - val_loss: 194.6460\n",
      "Epoch 4873/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4617 - val_loss: 196.1569\n",
      "Epoch 4874/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3788 - val_loss: 196.4442\n",
      "Epoch 4875/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3946 - val_loss: 195.3129\n",
      "Epoch 4876/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2986 - val_loss: 196.6678\n",
      "Epoch 4877/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3536 - val_loss: 196.7680\n",
      "Epoch 4878/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5836 - val_loss: 195.4903\n",
      "Epoch 4879/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4932 - val_loss: 193.7751\n",
      "Epoch 4880/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3701 - val_loss: 196.6067\n",
      "Epoch 4881/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5566 - val_loss: 195.2313\n",
      "Epoch 4882/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3943 - val_loss: 197.7220\n",
      "Epoch 4883/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4343 - val_loss: 194.6825\n",
      "Epoch 4884/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7327 - val_loss: 193.4504\n",
      "Epoch 4885/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6234 - val_loss: 195.8915\n",
      "Epoch 4886/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3850 - val_loss: 194.4837\n",
      "Epoch 4887/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6048 - val_loss: 188.6450\n",
      "Epoch 4888/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5757 - val_loss: 195.4712\n",
      "Epoch 4889/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7038 - val_loss: 196.5116\n",
      "Epoch 4890/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4183 - val_loss: 196.4802\n",
      "Epoch 4891/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7159 - val_loss: 191.4811\n",
      "Epoch 4892/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2714 - val_loss: 197.6143\n",
      "Epoch 4893/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6207 - val_loss: 197.7901\n",
      "Epoch 4894/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2163 - val_loss: 196.9544\n",
      "Epoch 4895/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3545 - val_loss: 192.6342\n",
      "Epoch 4896/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5598 - val_loss: 197.8880\n",
      "Epoch 4897/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5292 - val_loss: 198.1617\n",
      "Epoch 4898/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5466 - val_loss: 198.1571\n",
      "Epoch 4899/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3428 - val_loss: 196.1874\n",
      "Epoch 4900/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4442 - val_loss: 198.8137\n",
      "Epoch 4901/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3792 - val_loss: 196.3178\n",
      "Epoch 4902/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4147 - val_loss: 195.3855\n",
      "Epoch 4903/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4702 - val_loss: 194.2413\n",
      "Epoch 4904/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4490 - val_loss: 194.2775\n",
      "Epoch 4905/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3683 - val_loss: 199.2682\n",
      "Epoch 4906/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6780 - val_loss: 195.9104\n",
      "Epoch 4907/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6662 - val_loss: 197.2322\n",
      "Epoch 4908/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4755 - val_loss: 192.1542\n",
      "Epoch 4909/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2959 - val_loss: 194.9990\n",
      "Epoch 4910/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6162 - val_loss: 195.9392\n",
      "Epoch 4911/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.8047 - val_loss: 194.2600\n",
      "Epoch 4912/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4224 - val_loss: 200.1018\n",
      "Epoch 4913/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4191 - val_loss: 195.9811\n",
      "Epoch 4914/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3252 - val_loss: 196.0378\n",
      "Epoch 4915/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4044 - val_loss: 197.6729\n",
      "Epoch 4916/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2620 - val_loss: 194.8873\n",
      "Epoch 4917/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3655 - val_loss: 195.1857\n",
      "Epoch 4918/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4507 - val_loss: 196.4337\n",
      "Epoch 4919/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5719 - val_loss: 195.4389\n",
      "Epoch 4920/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4143 - val_loss: 197.0514\n",
      "Epoch 4921/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4518 - val_loss: 199.1010\n",
      "Epoch 4922/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4224 - val_loss: 193.9523\n",
      "Epoch 4923/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.8178 - val_loss: 192.1622\n",
      "Epoch 4924/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3197 - val_loss: 195.6040\n",
      "Epoch 4925/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4497 - val_loss: 197.0862\n",
      "Epoch 4926/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6249 - val_loss: 194.1599\n",
      "Epoch 4927/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1692 - val_loss: 196.2681\n",
      "Epoch 4928/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4663 - val_loss: 196.8282\n",
      "Epoch 4929/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1979 - val_loss: 195.4999\n",
      "Epoch 4930/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5757 - val_loss: 196.9625\n",
      "Epoch 4931/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 71.0497 - val_loss: 197.9410\n",
      "Epoch 4932/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3882 - val_loss: 196.1744\n",
      "Epoch 4933/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3769 - val_loss: 196.1893\n",
      "Epoch 4934/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4015 - val_loss: 195.6862\n",
      "Epoch 4935/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4769 - val_loss: 193.0796\n",
      "Epoch 4936/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3757 - val_loss: 198.8075\n",
      "Epoch 4937/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2522 - val_loss: 197.6264\n",
      "Epoch 4938/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2195 - val_loss: 195.0210\n",
      "Epoch 4939/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3444 - val_loss: 194.8508\n",
      "Epoch 4940/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2862 - val_loss: 195.4100\n",
      "Epoch 4941/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3859 - val_loss: 193.8249\n",
      "Epoch 4942/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4687 - val_loss: 194.8240\n",
      "Epoch 4943/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4209 - val_loss: 194.6937\n",
      "Epoch 4944/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4784 - val_loss: 194.8837\n",
      "Epoch 4945/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1671 - val_loss: 194.6686\n",
      "Epoch 4946/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4366 - val_loss: 196.2438\n",
      "Epoch 4947/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5686 - val_loss: 197.0951\n",
      "Epoch 4948/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2555 - val_loss: 194.6514\n",
      "Epoch 4949/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7454 - val_loss: 196.5910\n",
      "Epoch 4950/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6723 - val_loss: 195.2524\n",
      "Epoch 4951/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4474 - val_loss: 195.8128\n",
      "Epoch 4952/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5004 - val_loss: 196.6325\n",
      "Epoch 4953/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3554 - val_loss: 196.0040\n",
      "Epoch 4954/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3416 - val_loss: 195.8479\n",
      "Epoch 4955/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3496 - val_loss: 194.6436\n",
      "Epoch 4956/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5265 - val_loss: 192.4926\n",
      "Epoch 4957/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3237 - val_loss: 193.0947\n",
      "Epoch 4958/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4271 - val_loss: 197.1145\n",
      "Epoch 4959/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4404 - val_loss: 197.4766\n",
      "Epoch 4960/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5178 - val_loss: 197.0005\n",
      "Epoch 4961/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4000 - val_loss: 195.3268\n",
      "Epoch 4962/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3114 - val_loss: 194.8355\n",
      "Epoch 4963/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5451 - val_loss: 195.6458\n",
      "Epoch 4964/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3590 - val_loss: 192.5412\n",
      "Epoch 4965/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6627 - val_loss: 193.9353\n",
      "Epoch 4966/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6424 - val_loss: 196.6341\n",
      "Epoch 4967/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3187 - val_loss: 196.6140\n",
      "Epoch 4968/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3137 - val_loss: 194.7657\n",
      "Epoch 4969/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3648 - val_loss: 198.5443\n",
      "Epoch 4970/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4932 - val_loss: 196.0643\n",
      "Epoch 4971/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4489 - val_loss: 192.3814\n",
      "Epoch 4972/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5867 - val_loss: 196.4942\n",
      "Epoch 4973/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3230 - val_loss: 196.2174\n",
      "Epoch 4974/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4203 - val_loss: 191.7682\n",
      "Epoch 4975/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5165 - val_loss: 195.9447\n",
      "Epoch 4976/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2625 - val_loss: 197.7408\n",
      "Epoch 4977/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2447 - val_loss: 195.8864\n",
      "Epoch 4978/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6176 - val_loss: 194.1017\n",
      "Epoch 4979/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4076 - val_loss: 197.0109\n",
      "Epoch 4980/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4944 - val_loss: 197.5294\n",
      "Epoch 4981/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4130 - val_loss: 198.3781\n",
      "Epoch 4982/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3535 - val_loss: 196.2868\n",
      "Epoch 4983/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4002 - val_loss: 195.8454\n",
      "Epoch 4984/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4779 - val_loss: 195.9614\n",
      "Epoch 4985/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7197 - val_loss: 194.1200\n",
      "Epoch 4986/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6164 - val_loss: 194.8713\n",
      "Epoch 4987/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4553 - val_loss: 197.3306\n",
      "Epoch 4988/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7201 - val_loss: 195.0696\n",
      "Epoch 4989/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4462 - val_loss: 195.6328\n",
      "Epoch 4990/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4632 - val_loss: 194.7198\n",
      "Epoch 4991/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4310 - val_loss: 193.1757\n",
      "Epoch 4992/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4625 - val_loss: 195.3304\n",
      "Epoch 4993/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.4835 - val_loss: 198.4374\n",
      "Epoch 4994/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.6527 - val_loss: 194.2210\n",
      "Epoch 4995/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3703 - val_loss: 197.1087\n",
      "Epoch 4996/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.7026 - val_loss: 197.0788\n",
      "Epoch 4997/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2539 - val_loss: 194.3724\n",
      "Epoch 4998/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4848 - val_loss: 195.7696\n",
      "Epoch 4999/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2039 - val_loss: 194.0327\n",
      "Epoch 5000/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5435 - val_loss: 195.8792\n",
      "Epoch 5001/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5388 - val_loss: 196.4554\n",
      "Epoch 5002/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4743 - val_loss: 194.7926\n",
      "Epoch 5003/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5397 - val_loss: 194.9976\n",
      "Epoch 5004/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5338 - val_loss: 194.8443\n",
      "Epoch 5005/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6207 - val_loss: 197.7363\n",
      "Epoch 5006/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5206 - val_loss: 199.5648\n",
      "Epoch 5007/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4497 - val_loss: 193.9353\n",
      "Epoch 5008/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4666 - val_loss: 194.8765\n",
      "Epoch 5009/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3508 - val_loss: 194.9758\n",
      "Epoch 5010/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5552 - val_loss: 194.6532\n",
      "Epoch 5011/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5139 - val_loss: 193.2714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5012/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4639 - val_loss: 199.2951\n",
      "Epoch 5013/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4284 - val_loss: 196.6043\n",
      "Epoch 5014/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 71.0471 - val_loss: 195.4408\n",
      "Epoch 5015/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6883 - val_loss: 193.2162\n",
      "Epoch 5016/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3459 - val_loss: 194.0514\n",
      "Epoch 5017/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4319 - val_loss: 196.4729\n",
      "Epoch 5018/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1123 - val_loss: 195.1516\n",
      "Epoch 5019/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4861 - val_loss: 193.0721\n",
      "Epoch 5020/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4264 - val_loss: 198.7583\n",
      "Epoch 5021/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3951 - val_loss: 193.7396\n",
      "Epoch 5022/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2195 - val_loss: 194.0499\n",
      "Epoch 5023/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5735 - val_loss: 198.4331\n",
      "Epoch 5024/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2864 - val_loss: 194.5626\n",
      "Epoch 5025/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7109 - val_loss: 196.5704\n",
      "Epoch 5026/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4769 - val_loss: 193.8740\n",
      "Epoch 5027/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5017 - val_loss: 193.6322\n",
      "Epoch 5028/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4046 - val_loss: 194.7143\n",
      "Epoch 5029/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4937 - val_loss: 196.4786\n",
      "Epoch 5030/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3409 - val_loss: 195.4167\n",
      "Epoch 5031/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4897 - val_loss: 195.0281\n",
      "Epoch 5032/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4733 - val_loss: 196.1969\n",
      "Epoch 5033/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4876 - val_loss: 197.0391\n",
      "Epoch 5034/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3397 - val_loss: 196.9330\n",
      "Epoch 5035/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3990 - val_loss: 193.0619\n",
      "Epoch 5036/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7770 - val_loss: 195.8852\n",
      "Epoch 5037/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4088 - val_loss: 194.5604\n",
      "Epoch 5038/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7725 - val_loss: 197.5395\n",
      "Epoch 5039/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2838 - val_loss: 194.0681\n",
      "Epoch 5040/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3983 - val_loss: 194.5145\n",
      "Epoch 5041/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2788 - val_loss: 193.8296\n",
      "Epoch 5042/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4234 - val_loss: 195.4931\n",
      "Epoch 5043/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6463 - val_loss: 194.6565\n",
      "Epoch 5044/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5987 - val_loss: 191.5682\n",
      "Epoch 5045/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4800 - val_loss: 193.6126\n",
      "Epoch 5046/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3575 - val_loss: 192.9023\n",
      "Epoch 5047/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3613 - val_loss: 194.6336\n",
      "Epoch 5048/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4001 - val_loss: 196.7451\n",
      "Epoch 5049/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1407 - val_loss: 194.6769\n",
      "Epoch 5050/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5534 - val_loss: 195.3300\n",
      "Epoch 5051/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3346 - val_loss: 193.9787\n",
      "Epoch 5052/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5658 - val_loss: 192.2486\n",
      "Epoch 5053/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6294 - val_loss: 195.5847\n",
      "Epoch 5054/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5397 - val_loss: 194.6682\n",
      "Epoch 5055/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1710 - val_loss: 195.7207\n",
      "Epoch 5056/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3847 - val_loss: 195.5933\n",
      "Epoch 5057/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4430 - val_loss: 196.7647\n",
      "Epoch 5058/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6351 - val_loss: 194.0922\n",
      "Epoch 5059/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2901 - val_loss: 194.6119\n",
      "Epoch 5060/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4689 - val_loss: 196.7272\n",
      "Epoch 5061/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2985 - val_loss: 194.9642\n",
      "Epoch 5062/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7359 - val_loss: 194.3689\n",
      "Epoch 5063/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5945 - val_loss: 194.9852\n",
      "Epoch 5064/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2824 - val_loss: 194.4721\n",
      "Epoch 5065/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2589 - val_loss: 197.5522\n",
      "Epoch 5066/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.9264 - val_loss: 193.7738\n",
      "Epoch 5067/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4586 - val_loss: 197.4877\n",
      "Epoch 5068/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.1992 - val_loss: 196.1947\n",
      "Epoch 5069/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5120 - val_loss: 195.6701\n",
      "Epoch 5070/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5348 - val_loss: 195.7101\n",
      "Epoch 5071/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5549 - val_loss: 194.3856\n",
      "Epoch 5072/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5662 - val_loss: 193.7206\n",
      "Epoch 5073/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3976 - val_loss: 193.6285\n",
      "Epoch 5074/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6975 - val_loss: 195.7934\n",
      "Epoch 5075/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3394 - val_loss: 195.6453\n",
      "Epoch 5076/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4246 - val_loss: 195.5416\n",
      "Epoch 5077/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4360 - val_loss: 193.8230\n",
      "Epoch 5078/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.5316 - val_loss: 193.7176\n",
      "Epoch 5079/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5708 - val_loss: 193.8927\n",
      "Epoch 5080/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6038 - val_loss: 197.6056\n",
      "Epoch 5081/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3417 - val_loss: 192.9970\n",
      "Epoch 5082/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2816 - val_loss: 195.4010\n",
      "Epoch 5083/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4094 - val_loss: 198.1637\n",
      "Epoch 5084/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2094 - val_loss: 196.3614\n",
      "Epoch 5085/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1791 - val_loss: 198.0996\n",
      "Epoch 5086/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5004 - val_loss: 194.9387\n",
      "Epoch 5087/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3432 - val_loss: 195.5902\n",
      "Epoch 5088/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3161 - val_loss: 197.3438\n",
      "Epoch 5089/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6501 - val_loss: 196.0097\n",
      "Epoch 5090/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3452 - val_loss: 194.1190\n",
      "Epoch 5091/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7067 - val_loss: 194.4071\n",
      "Epoch 5092/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3764 - val_loss: 196.4051\n",
      "Epoch 5093/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4834 - val_loss: 195.6038\n",
      "Epoch 5094/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.6330 - val_loss: 195.4380\n",
      "Epoch 5095/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4282 - val_loss: 196.7112\n",
      "Epoch 5096/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4498 - val_loss: 197.6109\n",
      "Epoch 5097/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4083 - val_loss: 193.7129\n",
      "Epoch 5098/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5554 - val_loss: 196.3417\n",
      "Epoch 5099/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.3893 - val_loss: 195.7818\n",
      "Epoch 5100/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.1872 - val_loss: 195.2614\n",
      "Epoch 5101/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4823 - val_loss: 192.6286\n",
      "Epoch 5102/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4174 - val_loss: 194.6884\n",
      "Epoch 5103/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.2920 - val_loss: 193.8554\n",
      "Epoch 5104/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4855 - val_loss: 197.0712\n",
      "Epoch 5105/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.7320 - val_loss: 193.9402\n",
      "Epoch 5106/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6975 - val_loss: 193.5774\n",
      "Epoch 5107/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.4097 - val_loss: 191.9195\n",
      "Epoch 5108/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6549 - val_loss: 195.4164\n",
      "Epoch 5109/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.4233 - val_loss: 194.5434\n",
      "Epoch 5110/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5095 - val_loss: 195.0870\n",
      "Epoch 5111/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2341 - val_loss: 194.0858\n",
      "Epoch 5112/20000\n",
      "17948/17948 [==============================] - 1s 47us/sample - loss: 70.4336 - val_loss: 195.6717\n",
      "Epoch 5113/20000\n",
      "17948/17948 [==============================] - 1s 44us/sample - loss: 70.5121 - val_loss: 193.7502\n",
      "Epoch 5114/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.2793 - val_loss: 196.5307\n",
      "Epoch 5115/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3055 - val_loss: 202.0006\n",
      "Epoch 5116/20000\n",
      "17948/17948 [==============================] - 1s 38us/sample - loss: 70.7721 - val_loss: 194.5896\n",
      "Epoch 5117/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.2878 - val_loss: 195.9180\n",
      "Epoch 5118/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6330 - val_loss: 194.1666\n",
      "Epoch 5119/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3237 - val_loss: 196.2749\n",
      "Epoch 5120/20000\n",
      "17948/17948 [==============================] - 1s 32us/sample - loss: 70.5869 - val_loss: 192.4921\n",
      "Epoch 5121/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.7130 - val_loss: 194.7880\n",
      "Epoch 5122/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.6139 - val_loss: 194.7082\n",
      "Epoch 5123/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.2262 - val_loss: 195.1834\n",
      "Epoch 5124/20000\n",
      "17948/17948 [==============================] - 1s 35us/sample - loss: 70.5270 - val_loss: 196.8508\n",
      "Epoch 5125/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.5599 - val_loss: 195.8442\n",
      "Epoch 5126/20000\n",
      "17948/17948 [==============================] - 1s 34us/sample - loss: 70.3169 - val_loss: 196.4224\n",
      "Epoch 5127/20000\n",
      "17948/17948 [==============================] - 1s 33us/sample - loss: 70.3861 - val_loss: 197.3985\n",
      "Epoch 5128/20000\n",
      "   64/17948 [..............................] - ETA: 0s - loss: 82.7623WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-91152180c201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m hist = model.fit(X_train, y_train,validation_split=0.15,\n\u001b[0;32m      2\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m           batch_size=64, epochs=epochs,shuffle=True)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,validation_split=0.15,\n",
    "            callbacks=[model_checkpoint],\n",
    "          batch_size=64, epochs=epochs,shuffle=True)\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f1d1a663c8>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 0\n",
    "N = 2900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2900, 1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value = model.predict(X_test[S:N])\n",
    "predicted_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 500 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 700 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3000 Epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10000 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 46000 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50000 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(N-S),y_test[S:N]) # ground truth\n",
    "plt.plot(range(N-S),predicted_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
